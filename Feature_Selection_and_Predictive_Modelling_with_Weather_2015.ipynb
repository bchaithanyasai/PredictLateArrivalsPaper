{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Selection and Predictive Modelling with Weather 2015",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOPdoQkbycFZd+DpmH1Iw2D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bchaithanyasai/PredictLateArrivalsPaper/blob/master/Feature_Selection_and_Predictive_Modelling_with_Weather_2015.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zk626ZMKEedL",
        "outputId": "256d02a0-56d3-4ac5-9777-493674bba5c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4mJaM6qcFABM",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data=pd.read_csv(\"/content/drive/My Drive/train_data_with_weather_2015.csv\")\n",
        "test_data=pd.read_csv(\"/content/drive/My Drive/test_data_with_weather_2015.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mQQWbYz2gMIN",
        "outputId": "fe47a0eb-4e78-4109-b95d-e6105e811405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_data.OUTCOME.mean(),test_data.OUTCOME.mean())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5 0.3042416430008652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8nFtnzW2ZDo_",
        "outputId": "9b546e6a-e3a1-479d-d4ec-b27f6fd1be01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "train_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>SCHEDULED_DEPARTURE</th>\n",
              "      <th>DEPARTURE_TIME</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>SCHEDULED_ARRIVAL</th>\n",
              "      <th>ARRIVAL_TIME</th>\n",
              "      <th>ARRIVAL_DELAY</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>ELAPSED_TIME</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>WHEELS_OFF</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>pressure</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.257109</td>\n",
              "      <td>821.000000</td>\n",
              "      <td>822.000000</td>\n",
              "      <td>0.174887</td>\n",
              "      <td>830.000000</td>\n",
              "      <td>832.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>838.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>290.470333</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>346.000000</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.308900</td>\n",
              "      <td>0.285001</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2358.000000</td>\n",
              "      <td>0.078960</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>741.000000</td>\n",
              "      <td>-27.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>283.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>2296.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>263.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>295.501763</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1023.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>27.00000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>2028.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.297450</td>\n",
              "      <td>907.000000</td>\n",
              "      <td>912.000000</td>\n",
              "      <td>0.275508</td>\n",
              "      <td>1117.000000</td>\n",
              "      <td>1106.000000</td>\n",
              "      <td>-11.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>922.000000</td>\n",
              "      <td>794.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>292.250000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1017.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>343.000000</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>11.0</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.289338</td>\n",
              "      <td>1415.000000</td>\n",
              "      <td>1423.000000</td>\n",
              "      <td>0.376994</td>\n",
              "      <td>1704.000000</td>\n",
              "      <td>1721.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>1450.000000</td>\n",
              "      <td>578.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>279.088667</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1033.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>115.00000</td>\n",
              "      <td>430.000000</td>\n",
              "      <td>1554.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.327223</td>\n",
              "      <td>1620.000000</td>\n",
              "      <td>1617.000000</td>\n",
              "      <td>0.099516</td>\n",
              "      <td>1905.000000</td>\n",
              "      <td>1847.000000</td>\n",
              "      <td>-18.000000</td>\n",
              "      <td>285.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1630.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>251.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>270.075667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1038.000000</td>\n",
              "      <td>239.000000</td>\n",
              "      <td>270.00000</td>\n",
              "      <td>1095.000000</td>\n",
              "      <td>1626.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>16.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>19.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350795</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.506379</td>\n",
              "      <td>22.948966</td>\n",
              "      <td>3.012758</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.277645</td>\n",
              "      <td>1344.974483</td>\n",
              "      <td>1343.987242</td>\n",
              "      <td>0.132491</td>\n",
              "      <td>1439.493621</td>\n",
              "      <td>1448.455346</td>\n",
              "      <td>8.961725</td>\n",
              "      <td>114.519138</td>\n",
              "      <td>124.468104</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1400.987242</td>\n",
              "      <td>591.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>102.961725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>268.289824</td>\n",
              "      <td>66.366037</td>\n",
              "      <td>3.012758</td>\n",
              "      <td>1035.595688</td>\n",
              "      <td>303.748789</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>43.987242</td>\n",
              "      <td>13.0</td>\n",
              "      <td>44.974483</td>\n",
              "      <td>14.0</td>\n",
              "      <td>39.493621</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.987242</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350796</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>6.831457</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.328222</td>\n",
              "      <td>0.315815</td>\n",
              "      <td>25.353123</td>\n",
              "      <td>28.070625</td>\n",
              "      <td>0.243565</td>\n",
              "      <td>819.282498</td>\n",
              "      <td>827.690208</td>\n",
              "      <td>8.407710</td>\n",
              "      <td>293.929375</td>\n",
              "      <td>299.619584</td>\n",
              "      <td>22.619584</td>\n",
              "      <td>50.690208</td>\n",
              "      <td>2342.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>257.646877</td>\n",
              "      <td>1.548959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.407710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>296.870758</td>\n",
              "      <td>54.054587</td>\n",
              "      <td>3.690208</td>\n",
              "      <td>1014.000000</td>\n",
              "      <td>242.423748</td>\n",
              "      <td>13.00000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>1093.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.070625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.353123</td>\n",
              "      <td>8.0</td>\n",
              "      <td>19.282498</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.690208</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350797</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>7.578120</td>\n",
              "      <td>4.375042</td>\n",
              "      <td>5.296866</td>\n",
              "      <td>0.293531</td>\n",
              "      <td>0.262450</td>\n",
              "      <td>1714.218802</td>\n",
              "      <td>2265.718858</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1826.406267</td>\n",
              "      <td>8.968774</td>\n",
              "      <td>342.562507</td>\n",
              "      <td>72.187465</td>\n",
              "      <td>68.874986</td>\n",
              "      <td>13.562507</td>\n",
              "      <td>2313.656295</td>\n",
              "      <td>377.937214</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.171852</td>\n",
              "      <td>0.984387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>341.578120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>304.561649</td>\n",
              "      <td>46.718858</td>\n",
              "      <td>3.281253</td>\n",
              "      <td>1016.125014</td>\n",
              "      <td>334.671685</td>\n",
              "      <td>277.42188</td>\n",
              "      <td>1130.156351</td>\n",
              "      <td>237.656630</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.140627</td>\n",
              "      <td>51.656184</td>\n",
              "      <td>17.0</td>\n",
              "      <td>14.218802</td>\n",
              "      <td>18.0</td>\n",
              "      <td>26.406267</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>13.656295</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350798</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.122429</td>\n",
              "      <td>2.843879</td>\n",
              "      <td>0.324190</td>\n",
              "      <td>0.325316</td>\n",
              "      <td>1938.438785</td>\n",
              "      <td>2120.434672</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2217.658178</td>\n",
              "      <td>2338.185700</td>\n",
              "      <td>80.527522</td>\n",
              "      <td>279.219393</td>\n",
              "      <td>257.751028</td>\n",
              "      <td>8.843879</td>\n",
              "      <td>2129.278551</td>\n",
              "      <td>1843.063271</td>\n",
              "      <td>0.0</td>\n",
              "      <td>242.751028</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.029579</td>\n",
              "      <td>2.497943</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>287.798401</td>\n",
              "      <td>73.751028</td>\n",
              "      <td>1.936729</td>\n",
              "      <td>1030.438785</td>\n",
              "      <td>98.738689</td>\n",
              "      <td>290.00000</td>\n",
              "      <td>1153.590794</td>\n",
              "      <td>1280.434672</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>20.434672</td>\n",
              "      <td>19.0</td>\n",
              "      <td>38.438785</td>\n",
              "      <td>22.0</td>\n",
              "      <td>17.658178</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>29.278551</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350799</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.523548</td>\n",
              "      <td>20.141288</td>\n",
              "      <td>3.382260</td>\n",
              "      <td>0.331816</td>\n",
              "      <td>0.287352</td>\n",
              "      <td>1230.000000</td>\n",
              "      <td>1234.711932</td>\n",
              "      <td>0.291612</td>\n",
              "      <td>1514.717424</td>\n",
              "      <td>1526.811616</td>\n",
              "      <td>12.094192</td>\n",
              "      <td>104.717424</td>\n",
              "      <td>112.099684</td>\n",
              "      <td>18.711932</td>\n",
              "      <td>1274.365783</td>\n",
              "      <td>582.806124</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.864205</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>265.676510</td>\n",
              "      <td>63.083207</td>\n",
              "      <td>2.905808</td>\n",
              "      <td>1045.423864</td>\n",
              "      <td>257.069066</td>\n",
              "      <td>104.00000</td>\n",
              "      <td>424.628725</td>\n",
              "      <td>474.817109</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>34.711932</td>\n",
              "      <td>12.0</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.717424</td>\n",
              "      <td>12.523548</td>\n",
              "      <td>22.010985</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3350800 rows × 60 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR      MONTH  ...  WHEELS_OFF_MINUTE  OUTCOME\n",
              "0        2015.0   5.000000  ...          38.000000        0\n",
              "1        2015.0   8.000000  ...          13.000000        0\n",
              "2        2015.0   9.000000  ...          22.000000        0\n",
              "3        2015.0   4.000000  ...          50.000000        1\n",
              "4        2015.0   1.000000  ...          30.000000        0\n",
              "...         ...        ...  ...                ...      ...\n",
              "3350795  2015.0   1.506379  ...           0.987242        1\n",
              "3350796  2015.0  11.000000  ...          50.690208        1\n",
              "3350797  2015.0   7.578120  ...          13.656295        1\n",
              "3350798  2015.0   5.000000  ...          29.278551        1\n",
              "3350799  2015.0   1.523548  ...          22.010985        1\n",
              "\n",
              "[3350800 rows x 60 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vvUpEEFbZGZ9",
        "outputId": "3cebd7c7-a8ad-4103-b44d-1315a988e677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "test_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>SCHEDULED_DEPARTURE</th>\n",
              "      <th>DEPARTURE_TIME</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>SCHEDULED_ARRIVAL</th>\n",
              "      <th>ARRIVAL_TIME</th>\n",
              "      <th>ARRIVAL_DELAY</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>ELAPSED_TIME</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>WHEELS_OFF</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>pressure</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>converted_DEPARTURE_TIME</th>\n",
              "      <th>converted_SCHEDULED_DEPARTURE</th>\n",
              "      <th>converted_SCHEDULED_ARRIVAL</th>\n",
              "      <th>converted_WHEELS_OFF</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>9</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.327277</td>\n",
              "      <td>1725</td>\n",
              "      <td>1722.0</td>\n",
              "      <td>0.099516</td>\n",
              "      <td>1832</td>\n",
              "      <td>1913.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1751.0</td>\n",
              "      <td>689</td>\n",
              "      <td>0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>295.420000</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>99</td>\n",
              "      <td>440</td>\n",
              "      <td>101</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17:22:00</td>\n",
              "      <td>17:25:00</td>\n",
              "      <td>18:32:00</td>\n",
              "      <td>17:51:00</td>\n",
              "      <td>17</td>\n",
              "      <td>22</td>\n",
              "      <td>17</td>\n",
              "      <td>25</td>\n",
              "      <td>18</td>\n",
              "      <td>32</td>\n",
              "      <td>17</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>0.328222</td>\n",
              "      <td>0.302174</td>\n",
              "      <td>1110</td>\n",
              "      <td>1120.0</td>\n",
              "      <td>0.455724</td>\n",
              "      <td>1222</td>\n",
              "      <td>1237.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1152.0</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>275.140522</td>\n",
              "      <td>57.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1029.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>82</td>\n",
              "      <td>276</td>\n",
              "      <td>1087</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11:20:00</td>\n",
              "      <td>11:10:00</td>\n",
              "      <td>12:22:00</td>\n",
              "      <td>11:52:00</td>\n",
              "      <td>11</td>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>11</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>0.283660</td>\n",
              "      <td>0.277645</td>\n",
              "      <td>1545</td>\n",
              "      <td>1550.0</td>\n",
              "      <td>0.275508</td>\n",
              "      <td>1710</td>\n",
              "      <td>1708.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1600.0</td>\n",
              "      <td>395</td>\n",
              "      <td>0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>291.892000</td>\n",
              "      <td>92.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>277</td>\n",
              "      <td>1144</td>\n",
              "      <td>220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15:50:00</td>\n",
              "      <td>15:45:00</td>\n",
              "      <td>17:10:00</td>\n",
              "      <td>16:00:00</td>\n",
              "      <td>15</td>\n",
              "      <td>50</td>\n",
              "      <td>15</td>\n",
              "      <td>45</td>\n",
              "      <td>17</td>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.268674</td>\n",
              "      <td>1950</td>\n",
              "      <td>1946.0</td>\n",
              "      <td>0.092683</td>\n",
              "      <td>2229</td>\n",
              "      <td>2224.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>279.0</td>\n",
              "      <td>278.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>1739</td>\n",
              "      <td>0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>288.610673</td>\n",
              "      <td>62.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>998.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>228</td>\n",
              "      <td>969</td>\n",
              "      <td>1602</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19:46:00</td>\n",
              "      <td>19:50:00</td>\n",
              "      <td>22:29:00</td>\n",
              "      <td>20:09:00</td>\n",
              "      <td>19</td>\n",
              "      <td>46</td>\n",
              "      <td>19</td>\n",
              "      <td>50</td>\n",
              "      <td>22</td>\n",
              "      <td>29</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.269565</td>\n",
              "      <td>1400</td>\n",
              "      <td>1351.0</td>\n",
              "      <td>0.070576</td>\n",
              "      <td>1546</td>\n",
              "      <td>1550.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>1422.0</td>\n",
              "      <td>534</td>\n",
              "      <td>0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>277.037667</td>\n",
              "      <td>95.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1025.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>99</td>\n",
              "      <td>439</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13:51:00</td>\n",
              "      <td>14:00:00</td>\n",
              "      <td>15:46:00</td>\n",
              "      <td>14:22:00</td>\n",
              "      <td>13</td>\n",
              "      <td>51</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>46</td>\n",
              "      <td>14</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802137</th>\n",
              "      <td>2015</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.336873</td>\n",
              "      <td>931</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.080515</td>\n",
              "      <td>1139</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>945.0</td>\n",
              "      <td>1118</td>\n",
              "      <td>0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>281.810000</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>228</td>\n",
              "      <td>903</td>\n",
              "      <td>1487</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>09:25:00</td>\n",
              "      <td>09:31:00</td>\n",
              "      <td>11:39:00</td>\n",
              "      <td>09:45:00</td>\n",
              "      <td>9</td>\n",
              "      <td>25</td>\n",
              "      <td>9</td>\n",
              "      <td>31</td>\n",
              "      <td>11</td>\n",
              "      <td>39</td>\n",
              "      <td>9</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802138</th>\n",
              "      <td>2015</td>\n",
              "      <td>10</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>0.328222</td>\n",
              "      <td>0.407928</td>\n",
              "      <td>940</td>\n",
              "      <td>931.0</td>\n",
              "      <td>0.070576</td>\n",
              "      <td>1240</td>\n",
              "      <td>1219.0</td>\n",
              "      <td>-21.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>348.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>940.0</td>\n",
              "      <td>2556</td>\n",
              "      <td>0</td>\n",
              "      <td>335.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>283.930000</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1027.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>144</td>\n",
              "      <td>583</td>\n",
              "      <td>1077</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>09:31:00</td>\n",
              "      <td>09:40:00</td>\n",
              "      <td>12:40:00</td>\n",
              "      <td>09:40:00</td>\n",
              "      <td>9</td>\n",
              "      <td>31</td>\n",
              "      <td>9</td>\n",
              "      <td>40</td>\n",
              "      <td>12</td>\n",
              "      <td>40</td>\n",
              "      <td>9</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802139</th>\n",
              "      <td>2015</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.331816</td>\n",
              "      <td>0.341802</td>\n",
              "      <td>1003</td>\n",
              "      <td>1003.0</td>\n",
              "      <td>0.154482</td>\n",
              "      <td>1314</td>\n",
              "      <td>1304.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>775</td>\n",
              "      <td>0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>280.991333</td>\n",
              "      <td>45.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1021.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>216</td>\n",
              "      <td>908</td>\n",
              "      <td>432</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10:03:00</td>\n",
              "      <td>10:03:00</td>\n",
              "      <td>13:14:00</td>\n",
              "      <td>10:17:00</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802140</th>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0.308362</td>\n",
              "      <td>0.279126</td>\n",
              "      <td>2150</td>\n",
              "      <td>2150.0</td>\n",
              "      <td>0.154482</td>\n",
              "      <td>2325</td>\n",
              "      <td>2303.0</td>\n",
              "      <td>-22.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2208.0</td>\n",
              "      <td>301</td>\n",
              "      <td>0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>273.539500</td>\n",
              "      <td>74.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1037.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>55</td>\n",
              "      <td>147</td>\n",
              "      <td>912</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21:50:00</td>\n",
              "      <td>21:50:00</td>\n",
              "      <td>23:25:00</td>\n",
              "      <td>22:08:00</td>\n",
              "      <td>21</td>\n",
              "      <td>50</td>\n",
              "      <td>21</td>\n",
              "      <td>50</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802141</th>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>0.336319</td>\n",
              "      <td>0.354764</td>\n",
              "      <td>850</td>\n",
              "      <td>859.0</td>\n",
              "      <td>0.416406</td>\n",
              "      <td>1310</td>\n",
              "      <td>1302.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>908.0</td>\n",
              "      <td>1428</td>\n",
              "      <td>0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>288.740000</td>\n",
              "      <td>93.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>283</td>\n",
              "      <td>1139</td>\n",
              "      <td>706</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>08:59:00</td>\n",
              "      <td>08:50:00</td>\n",
              "      <td>13:10:00</td>\n",
              "      <td>09:08:00</td>\n",
              "      <td>8</td>\n",
              "      <td>59</td>\n",
              "      <td>8</td>\n",
              "      <td>50</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>802142 rows × 64 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        YEAR  MONTH  DAY  ...  WHEELS_OFF_HOUR  WHEELS_OFF_MINUTE  OUTCOME\n",
              "0       2015      9   28  ...               17                 51        1\n",
              "1       2015     12   17  ...               11                 52        1\n",
              "2       2015      4   19  ...               16                  0        0\n",
              "3       2015     11   18  ...               20                  9        0\n",
              "4       2015      1   24  ...               14                 22        0\n",
              "...      ...    ...  ...  ...              ...                ...      ...\n",
              "802137  2015     10   15  ...                9                 45        0\n",
              "802138  2015     10   24  ...                9                 40        0\n",
              "802139  2015      6    3  ...               10                 17        0\n",
              "802140  2015      3   23  ...               22                  8        0\n",
              "802141  2015     12   24  ...                9                  8        0\n",
              "\n",
              "[802142 rows x 64 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aigROTKhFYB6",
        "colab": {}
      },
      "source": [
        "drop_cols=['SCHEDULED_DEPARTURE','DEPARTURE_TIME']\n",
        "init_cols=['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT',\n",
        "       'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'SCHEDULED_TIME',\n",
        "       'DISTANCE', 'AIR_TIME', 'DIVERTED', 'AIR_SYSTEM_DELAY',\n",
        "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
        "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
        "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
        "       'AA', 'AS', 'B6', 'DL', 'EV', 'F9', 'HA', 'MQ', 'NK', 'OO', 'UA', 'US',\n",
        "       'VX', 'WN', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR',\n",
        "       'SCHEDULED_ARRIVAL_HOUR', 'DEPARTURE_TIME_MINUTE',\n",
        "       'SCHEDULED_DEPARTURE_MINUTE', 'SCHEDULED_ARRIVAL_MINUTE',\n",
        "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
        "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
        "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing','temperature','humidity','wind_speed','wind_direction','pressure']\n",
        "Y_train=pd.DataFrame(train_data['OUTCOME'])\n",
        "X_train=train_data[init_cols]\n",
        "\n",
        "Y_test=pd.DataFrame(test_data['OUTCOME'])\n",
        "X_test=test_data[init_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T6ZfhIrJFoAo",
        "outputId": "e5d00504-89c8-403f-e7ae-d1e914747deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>pressure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.257109</td>\n",
              "      <td>0.174887</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>290.470333</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>346.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.308900</td>\n",
              "      <td>0.285001</td>\n",
              "      <td>0.078960</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>2296.000000</td>\n",
              "      <td>263.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.00000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>2028.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>295.501763</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>1023.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.297450</td>\n",
              "      <td>0.275508</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>794.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>343.000000</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>292.250000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1017.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.289338</td>\n",
              "      <td>0.376994</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>578.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.00000</td>\n",
              "      <td>430.000000</td>\n",
              "      <td>1554.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>279.088667</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>1033.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.327223</td>\n",
              "      <td>0.099516</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>285.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>251.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>270.00000</td>\n",
              "      <td>1095.000000</td>\n",
              "      <td>1626.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>270.075667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>239.000000</td>\n",
              "      <td>1038.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350795</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.506379</td>\n",
              "      <td>22.948966</td>\n",
              "      <td>3.012758</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.277645</td>\n",
              "      <td>0.132491</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>114.519138</td>\n",
              "      <td>591.000000</td>\n",
              "      <td>102.961725</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>43.987242</td>\n",
              "      <td>44.974483</td>\n",
              "      <td>39.493621</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.987242</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>268.289824</td>\n",
              "      <td>66.366037</td>\n",
              "      <td>3.012758</td>\n",
              "      <td>303.748789</td>\n",
              "      <td>1035.595688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350796</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>6.831457</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.328222</td>\n",
              "      <td>0.315815</td>\n",
              "      <td>0.243565</td>\n",
              "      <td>22.619584</td>\n",
              "      <td>293.929375</td>\n",
              "      <td>2342.000000</td>\n",
              "      <td>257.646877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.548959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.407710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.00000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>1093.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>28.070625</td>\n",
              "      <td>25.353123</td>\n",
              "      <td>19.282498</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>296.870758</td>\n",
              "      <td>54.054587</td>\n",
              "      <td>3.690208</td>\n",
              "      <td>242.423748</td>\n",
              "      <td>1014.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350797</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>7.578120</td>\n",
              "      <td>4.375042</td>\n",
              "      <td>5.296866</td>\n",
              "      <td>0.293531</td>\n",
              "      <td>0.262450</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.562507</td>\n",
              "      <td>72.187465</td>\n",
              "      <td>377.937214</td>\n",
              "      <td>52.171852</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.984387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>341.578120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>277.42188</td>\n",
              "      <td>1130.156351</td>\n",
              "      <td>237.656630</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.140627</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>51.656184</td>\n",
              "      <td>14.218802</td>\n",
              "      <td>26.406267</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>13.656295</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>304.561649</td>\n",
              "      <td>46.718858</td>\n",
              "      <td>3.281253</td>\n",
              "      <td>334.671685</td>\n",
              "      <td>1016.125014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350798</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.122429</td>\n",
              "      <td>2.843879</td>\n",
              "      <td>0.324190</td>\n",
              "      <td>0.325316</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.843879</td>\n",
              "      <td>279.219393</td>\n",
              "      <td>1843.063271</td>\n",
              "      <td>242.751028</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.029579</td>\n",
              "      <td>2.497943</td>\n",
              "      <td>0.0</td>\n",
              "      <td>290.00000</td>\n",
              "      <td>1153.590794</td>\n",
              "      <td>1280.434672</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>19.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>20.434672</td>\n",
              "      <td>38.438785</td>\n",
              "      <td>17.658178</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>29.278551</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>287.798401</td>\n",
              "      <td>73.751028</td>\n",
              "      <td>1.936729</td>\n",
              "      <td>98.738689</td>\n",
              "      <td>1030.438785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350799</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.523548</td>\n",
              "      <td>20.141288</td>\n",
              "      <td>3.382260</td>\n",
              "      <td>0.331816</td>\n",
              "      <td>0.287352</td>\n",
              "      <td>0.291612</td>\n",
              "      <td>18.711932</td>\n",
              "      <td>104.717424</td>\n",
              "      <td>582.806124</td>\n",
              "      <td>87.864205</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>104.00000</td>\n",
              "      <td>424.628725</td>\n",
              "      <td>474.817109</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>34.711932</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>14.717424</td>\n",
              "      <td>12.523548</td>\n",
              "      <td>22.010985</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>265.676510</td>\n",
              "      <td>63.083207</td>\n",
              "      <td>2.905808</td>\n",
              "      <td>257.069066</td>\n",
              "      <td>1045.423864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3350800 rows × 52 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR      MONTH        DAY  ...  wind_speed  wind_direction     pressure\n",
              "0        2015.0   5.000000  22.000000  ...    3.000000      346.000000  1032.000000\n",
              "1        2015.0   8.000000  29.000000  ...    4.000000      275.000000  1023.000000\n",
              "2        2015.0   9.000000  22.000000  ...    3.000000       30.000000  1017.000000\n",
              "3        2015.0   4.000000  16.000000  ...    3.000000       58.000000  1033.000000\n",
              "4        2015.0   1.000000  31.000000  ...    4.000000      239.000000  1038.000000\n",
              "...         ...        ...        ...  ...         ...             ...          ...\n",
              "3350795  2015.0   1.506379  22.948966  ...    3.012758      303.748789  1035.595688\n",
              "3350796  2015.0  11.000000   6.831457  ...    3.690208      242.423748  1014.000000\n",
              "3350797  2015.0   7.578120   4.375042  ...    3.281253      334.671685  1016.125014\n",
              "3350798  2015.0   5.000000   9.122429  ...    1.936729       98.738689  1030.438785\n",
              "3350799  2015.0   1.523548  20.141288  ...    2.905808      257.069066  1045.423864\n",
              "\n",
              "[3350800 rows x 52 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RIeo9LwFZl6W",
        "outputId": "1b0fe095-7165-49a0-edb5-4fbcd4b76c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_train[:2406600]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>pressure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.257109</td>\n",
              "      <td>0.174887</td>\n",
              "      <td>16.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>351.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>290.470333</td>\n",
              "      <td>65.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>346.0</td>\n",
              "      <td>1032.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.308900</td>\n",
              "      <td>0.285001</td>\n",
              "      <td>0.078960</td>\n",
              "      <td>15.0</td>\n",
              "      <td>303.0</td>\n",
              "      <td>2296.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2028.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>295.501763</td>\n",
              "      <td>66.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>275.0</td>\n",
              "      <td>1023.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.297450</td>\n",
              "      <td>0.275508</td>\n",
              "      <td>10.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>794.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>343.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>292.250000</td>\n",
              "      <td>88.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1017.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.289338</td>\n",
              "      <td>0.376994</td>\n",
              "      <td>27.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>578.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>430.0</td>\n",
              "      <td>1554.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>279.088667</td>\n",
              "      <td>86.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>1033.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.327223</td>\n",
              "      <td>0.099516</td>\n",
              "      <td>13.0</td>\n",
              "      <td>285.0</td>\n",
              "      <td>1846.0</td>\n",
              "      <td>251.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>1095.0</td>\n",
              "      <td>1626.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>270.075667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>1038.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406595</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.297972</td>\n",
              "      <td>0.347496</td>\n",
              "      <td>0.128038</td>\n",
              "      <td>12.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>954.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>1978.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>282.650000</td>\n",
              "      <td>62.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1016.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406596</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.267691</td>\n",
              "      <td>0.327277</td>\n",
              "      <td>0.109931</td>\n",
              "      <td>21.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>1075.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>941.0</td>\n",
              "      <td>616.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>277.259667</td>\n",
              "      <td>76.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>1034.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406597</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.308900</td>\n",
              "      <td>0.298923</td>\n",
              "      <td>0.084287</td>\n",
              "      <td>22.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>837.0</td>\n",
              "      <td>2059.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>289.166667</td>\n",
              "      <td>79.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1034.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406598</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.308362</td>\n",
              "      <td>0.332620</td>\n",
              "      <td>0.072696</td>\n",
              "      <td>16.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>1069.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>278.351000</td>\n",
              "      <td>97.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>1015.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406599</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.329166</td>\n",
              "      <td>0.315249</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>517.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>359.0</td>\n",
              "      <td>734.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>296.945667</td>\n",
              "      <td>99.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>1024.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2406600 rows × 52 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR  MONTH   DAY  ...  wind_speed  wind_direction  pressure\n",
              "0        2015.0    5.0  22.0  ...         3.0           346.0    1032.0\n",
              "1        2015.0    8.0  29.0  ...         4.0           275.0    1023.0\n",
              "2        2015.0    9.0  22.0  ...         3.0            30.0    1017.0\n",
              "3        2015.0    4.0  16.0  ...         3.0            58.0    1033.0\n",
              "4        2015.0    1.0  31.0  ...         4.0           239.0    1038.0\n",
              "...         ...    ...   ...  ...         ...             ...       ...\n",
              "2406595  2015.0   10.0   4.0  ...         5.0            40.0    1016.0\n",
              "2406596  2015.0    4.0   6.0  ...         4.0           111.0    1034.0\n",
              "2406597  2015.0    1.0  24.0  ...         2.0            50.0    1034.0\n",
              "2406598  2015.0    3.0  11.0  ...         2.0           241.0    1015.0\n",
              "2406599  2015.0    6.0  15.0  ...         5.0            57.0    1024.0\n",
              "\n",
              "[2406600 rows x 52 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XDNQRu46FrIu",
        "outputId": "b8340a8b-ea1a-42f9-b5ed-cb4e390b8370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "Y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350795</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350796</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350797</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350798</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350799</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3350800 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         OUTCOME\n",
              "0              0\n",
              "1              0\n",
              "2              0\n",
              "3              1\n",
              "4              0\n",
              "...          ...\n",
              "3350795        1\n",
              "3350796        1\n",
              "3350797        1\n",
              "3350798        1\n",
              "3350799        1\n",
              "\n",
              "[3350800 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B5vXc6IeFrS4",
        "outputId": "39bdabaf-f8db-43a8-b176-ac78b74439ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>pressure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>9</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.327277</td>\n",
              "      <td>0.099516</td>\n",
              "      <td>29.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>689</td>\n",
              "      <td>136.0</td>\n",
              "      <td>0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99</td>\n",
              "      <td>440</td>\n",
              "      <td>101</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>25</td>\n",
              "      <td>32</td>\n",
              "      <td>17</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>295.420000</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1017.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>0.328222</td>\n",
              "      <td>0.302174</td>\n",
              "      <td>0.455724</td>\n",
              "      <td>32.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>236</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82</td>\n",
              "      <td>276</td>\n",
              "      <td>1087</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>22</td>\n",
              "      <td>11</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>275.140522</td>\n",
              "      <td>57.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1029.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>0.283660</td>\n",
              "      <td>0.277645</td>\n",
              "      <td>0.275508</td>\n",
              "      <td>10.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>395</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>277</td>\n",
              "      <td>1144</td>\n",
              "      <td>220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>50</td>\n",
              "      <td>45</td>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>291.892000</td>\n",
              "      <td>92.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>1019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.268674</td>\n",
              "      <td>0.092683</td>\n",
              "      <td>23.0</td>\n",
              "      <td>279.0</td>\n",
              "      <td>1739</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228</td>\n",
              "      <td>969</td>\n",
              "      <td>1602</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>22</td>\n",
              "      <td>46</td>\n",
              "      <td>50</td>\n",
              "      <td>29</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>288.610673</td>\n",
              "      <td>62.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>998.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.269565</td>\n",
              "      <td>0.070576</td>\n",
              "      <td>31.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>534</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99</td>\n",
              "      <td>439</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>14</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>277.037667</td>\n",
              "      <td>95.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>1025.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802137</th>\n",
              "      <td>2015</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.336873</td>\n",
              "      <td>0.080515</td>\n",
              "      <td>20.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>1118</td>\n",
              "      <td>158.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228</td>\n",
              "      <td>903</td>\n",
              "      <td>1487</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>25</td>\n",
              "      <td>31</td>\n",
              "      <td>39</td>\n",
              "      <td>9</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>281.810000</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>1016.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802138</th>\n",
              "      <td>2015</td>\n",
              "      <td>10</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>0.328222</td>\n",
              "      <td>0.407928</td>\n",
              "      <td>0.070576</td>\n",
              "      <td>9.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>2556</td>\n",
              "      <td>335.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>144</td>\n",
              "      <td>583</td>\n",
              "      <td>1077</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>9</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>283.930000</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1027.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802139</th>\n",
              "      <td>2015</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.331816</td>\n",
              "      <td>0.341802</td>\n",
              "      <td>0.154482</td>\n",
              "      <td>14.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>775</td>\n",
              "      <td>101.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216</td>\n",
              "      <td>908</td>\n",
              "      <td>432</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>280.991333</td>\n",
              "      <td>45.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1021.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802140</th>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0.308362</td>\n",
              "      <td>0.279126</td>\n",
              "      <td>0.154482</td>\n",
              "      <td>18.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>301</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55</td>\n",
              "      <td>147</td>\n",
              "      <td>912</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>25</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>273.539500</td>\n",
              "      <td>74.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>1037.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802141</th>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>0.336319</td>\n",
              "      <td>0.354764</td>\n",
              "      <td>0.416406</td>\n",
              "      <td>9.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>1428</td>\n",
              "      <td>169.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>283</td>\n",
              "      <td>1139</td>\n",
              "      <td>706</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>59</td>\n",
              "      <td>50</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>288.740000</td>\n",
              "      <td>93.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>1007.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>802142 rows × 52 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        YEAR  MONTH  DAY  ...  wind_speed  wind_direction  pressure\n",
              "0       2015      9   28  ...         1.0            50.0    1017.0\n",
              "1       2015     12   17  ...         1.0            27.0    1029.0\n",
              "2       2015      4   19  ...         3.0           180.0    1019.0\n",
              "3       2015     11   18  ...        10.0           204.0     998.0\n",
              "4       2015      1   24  ...         5.0           306.0    1025.0\n",
              "...      ...    ...  ...  ...         ...             ...       ...\n",
              "802137  2015     10   15  ...         3.0           240.0    1016.0\n",
              "802138  2015     10   24  ...         0.0            21.0    1027.0\n",
              "802139  2015      6    3  ...         2.0           262.0    1021.0\n",
              "802140  2015      3   23  ...         2.0           322.0    1037.0\n",
              "802141  2015     12   24  ...         1.0           180.0    1007.0\n",
              "\n",
              "[802142 rows x 52 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KrZdDvSZFrcm",
        "outputId": "498222c5-4902-4351-b7c0-b3b25af11f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802137</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802138</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802139</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802140</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802141</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>802142 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        OUTCOME\n",
              "0             1\n",
              "1             1\n",
              "2             0\n",
              "3             0\n",
              "4             0\n",
              "...         ...\n",
              "802137        0\n",
              "802138        0\n",
              "802139        0\n",
              "802140        0\n",
              "802141        0\n",
              "\n",
              "[802142 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FO3YyADUn0UN",
        "colab": {}
      },
      "source": [
        "####Unused as it would be used for regression problems\n",
        "from sklearn.feature_selection import SelectPercentile, f_regression                      \n",
        "Selector_f = SelectPercentile(f_regression, percentile=25)\n",
        "Selector_f.fit(X,y)\n",
        "for n,s in zip(Unhandled_data.feature_names,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s \" % (s,n))\n",
        "Selector_f.get_support(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SpVyYrOyGYoH",
        "outputId": "7d364f04-0dc5-4e6f-9b8c-6c53c27d7e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "X_train.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT',\n",
              "       'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'SCHEDULED_TIME',\n",
              "       'DISTANCE', 'AIR_TIME', 'DIVERTED', 'AIR_SYSTEM_DELAY',\n",
              "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
              "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
              "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
              "       'AA', 'AS', 'B6', 'DL', 'EV', 'F9', 'HA', 'MQ', 'NK', 'OO', 'UA', 'US',\n",
              "       'VX', 'WN', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR',\n",
              "       'SCHEDULED_ARRIVAL_HOUR', 'DEPARTURE_TIME_MINUTE',\n",
              "       'SCHEDULED_DEPARTURE_MINUTE', 'SCHEDULED_ARRIVAL_MINUTE',\n",
              "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
              "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
              "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing',\n",
              "       'temperature', 'humidity', 'wind_speed', 'wind_direction', 'pressure'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ubU8RqqzAvk",
        "colab_type": "code",
        "outputId": "cf538723-59a8-40f8-a6cc-0e886e34b819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=25)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 11172.31t for feature MONTH\n",
            "F-score: 412.38t for feature DAY\n",
            "F-score: 925.27t for feature DAY_OF_WEEK\n",
            "F-score: 19959.62t for feature ORIGIN_AIRPORT\n",
            "F-score: 16025.41t for feature DESTINATION_AIRPORT\n",
            "F-score: 2883925.81t for feature DEPARTURE_DELAY\n",
            "F-score: 264740.81t for feature TAXI_OUT\n",
            "F-score: 33.57t for feature SCHEDULED_TIME\n",
            "F-score: 20.21t for feature DISTANCE\n",
            "F-score: 2815.93t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 248117.44t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 1616.56t for feature SECURITY_DELAY\n",
            "F-score: 191010.50t for feature AIRLINE_DELAY\n",
            "F-score: 285923.89t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 21812.68t for feature WEATHER_DELAY\n",
            "F-score: 8267.40t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 8874.31t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 533.54t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 341.90t for feature AA\n",
            "F-score: 1586.34t for feature AS\n",
            "F-score: 596.83t for feature B6\n",
            "F-score: 19972.64t for feature DL\n",
            "F-score: 77.72t for feature EV\n",
            "F-score: 2411.50t for feature F9\n",
            "F-score: 474.76t for feature HA\n",
            "F-score: 1.31t for feature MQ\n",
            "F-score: 7479.44t for feature NK\n",
            "F-score: 1198.12t for feature OO\n",
            "F-score: 255.37t for feature UA\n",
            "F-score: 296.68t for feature US\n",
            "F-score: 192.40t for feature VX\n",
            "F-score: 1874.12t for feature WN\n",
            "F-score: 99191.76t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 63770.78t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 43615.31t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 3711.86t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 699.64t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 1.43t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 98112.89t for feature WHEELS_OFF_HOUR\n",
            "F-score: 3036.30t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 3185073.83t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature WEATHER_DELAY_is_missing\n",
            "F-score: 643.03t for feature temperature\n",
            "F-score: 74.19t for feature humidity\n",
            "F-score: 16365.36t for feature wind_speed\n",
            "F-score: 453.96t for feature wind_direction\n",
            "F-score: 191.50t for feature pressure\n",
            "Index(['DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'WHEELS_OFF_HOUR',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
            "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
            "       'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DMVewQKgHfpC",
        "outputId": "00c52f48-e322-4642-a721-daf0a2e35a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=50)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 11172.31t for feature MONTH\n",
            "F-score: 412.38t for feature DAY\n",
            "F-score: 925.27t for feature DAY_OF_WEEK\n",
            "F-score: 19959.62t for feature ORIGIN_AIRPORT\n",
            "F-score: 16025.41t for feature DESTINATION_AIRPORT\n",
            "F-score: 2883925.81t for feature DEPARTURE_DELAY\n",
            "F-score: 264740.81t for feature TAXI_OUT\n",
            "F-score: 33.57t for feature SCHEDULED_TIME\n",
            "F-score: 20.21t for feature DISTANCE\n",
            "F-score: 2815.93t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 248117.44t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 1616.56t for feature SECURITY_DELAY\n",
            "F-score: 191010.50t for feature AIRLINE_DELAY\n",
            "F-score: 285923.89t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 21812.68t for feature WEATHER_DELAY\n",
            "F-score: 8267.40t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 8874.31t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 533.54t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 341.90t for feature AA\n",
            "F-score: 1586.34t for feature AS\n",
            "F-score: 596.83t for feature B6\n",
            "F-score: 19972.64t for feature DL\n",
            "F-score: 77.72t for feature EV\n",
            "F-score: 2411.50t for feature F9\n",
            "F-score: 474.76t for feature HA\n",
            "F-score: 1.31t for feature MQ\n",
            "F-score: 7479.44t for feature NK\n",
            "F-score: 1198.12t for feature OO\n",
            "F-score: 255.37t for feature UA\n",
            "F-score: 296.68t for feature US\n",
            "F-score: 192.40t for feature VX\n",
            "F-score: 1874.12t for feature WN\n",
            "F-score: 99191.76t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 63770.78t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 43615.31t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 3711.86t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 699.64t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 1.43t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 98112.89t for feature WHEELS_OFF_HOUR\n",
            "F-score: 3036.30t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 3185073.83t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature WEATHER_DELAY_is_missing\n",
            "F-score: 643.03t for feature temperature\n",
            "F-score: 74.19t for feature humidity\n",
            "F-score: 16365.36t for feature wind_speed\n",
            "F-score: 453.96t for feature wind_direction\n",
            "F-score: 191.50t for feature pressure\n",
            "Index(['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
            "       'TAXI_OUT', 'AIR_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'DL', 'NK', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR',\n",
            "       'DEPARTURE_TIME_MINUTE', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
            "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
            "       'WEATHER_DELAY_is_missing', 'wind_speed'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TyOUNz2dgJAq",
        "outputId": "494e58b1-f4f0-4f9b-9caf-848126a8876c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=75)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 11172.31t for feature MONTH\n",
            "F-score: 412.38t for feature DAY\n",
            "F-score: 925.27t for feature DAY_OF_WEEK\n",
            "F-score: 19959.62t for feature ORIGIN_AIRPORT\n",
            "F-score: 16025.41t for feature DESTINATION_AIRPORT\n",
            "F-score: 2883925.81t for feature DEPARTURE_DELAY\n",
            "F-score: 264740.81t for feature TAXI_OUT\n",
            "F-score: 33.57t for feature SCHEDULED_TIME\n",
            "F-score: 20.21t for feature DISTANCE\n",
            "F-score: 2815.93t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 248117.44t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 1616.56t for feature SECURITY_DELAY\n",
            "F-score: 191010.50t for feature AIRLINE_DELAY\n",
            "F-score: 285923.89t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 21812.68t for feature WEATHER_DELAY\n",
            "F-score: 8267.40t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 8874.31t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 533.54t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 341.90t for feature AA\n",
            "F-score: 1586.34t for feature AS\n",
            "F-score: 596.83t for feature B6\n",
            "F-score: 19972.64t for feature DL\n",
            "F-score: 77.72t for feature EV\n",
            "F-score: 2411.50t for feature F9\n",
            "F-score: 474.76t for feature HA\n",
            "F-score: 1.31t for feature MQ\n",
            "F-score: 7479.44t for feature NK\n",
            "F-score: 1198.12t for feature OO\n",
            "F-score: 255.37t for feature UA\n",
            "F-score: 296.68t for feature US\n",
            "F-score: 192.40t for feature VX\n",
            "F-score: 1874.12t for feature WN\n",
            "F-score: 99191.76t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 63770.78t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 43615.31t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 3711.86t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 699.64t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 1.43t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 98112.89t for feature WHEELS_OFF_HOUR\n",
            "F-score: 3036.30t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 3185073.83t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature WEATHER_DELAY_is_missing\n",
            "F-score: 643.03t for feature temperature\n",
            "F-score: 74.19t for feature humidity\n",
            "F-score: 16365.36t for feature wind_speed\n",
            "F-score: 453.96t for feature wind_direction\n",
            "F-score: 191.50t for feature pressure\n",
            "Index(['MONTH', 'DAY', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
            "       'AS', 'B6', 'DL', 'F9', 'HA', 'NK', 'OO', 'WN', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR',\n",
            "       'DEPARTURE_TIME_MINUTE', 'SCHEDULED_DEPARTURE_MINUTE',\n",
            "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
            "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing',\n",
            "       'temperature', 'wind_speed', 'wind_direction'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H3DVM-Qtu-Fo",
        "outputId": "132a48cc-1487-4067-f92c-e1f56bc006d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=25)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 18491.77t for feature MONTH \n",
            "F-score: 1842.31t for feature DAY \n",
            "F-score: 842.75t for feature DAY_OF_WEEK \n",
            "F-score: 65.10t for feature ORIGIN_AIRPORT \n",
            "F-score: 42.02t for feature DESTINATION_AIRPORT \n",
            "F-score: 511058.32t for feature DEPARTURE_DELAY \n",
            "F-score: 1384872.97t for feature TAXI_OUT \n",
            "F-score: 1361.31t for feature SCHEDULED_TIME \n",
            "F-score: 9074.91t for feature DISTANCE \n",
            "F-score: 132363.42t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 13101204.35t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 75910.10t for feature SECURITY_DELAY \n",
            "F-score: 19648072.50t for feature AIRLINE_DELAY \n",
            "F-score: 23331639.14t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 2747154.72t for feature WEATHER_DELAY \n",
            "F-score: 500380.35t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 2374411.18t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 198660.70t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 298.42t for feature AA \n",
            "F-score: 1532.33t for feature AS \n",
            "F-score: 569.50t for feature B6 \n",
            "F-score: 16421.09t for feature DL \n",
            "F-score: 71.66t for feature EV \n",
            "F-score: 2350.49t for feature F9 \n",
            "F-score: 473.39t for feature HA \n",
            "F-score: 1.27t for feature MQ \n",
            "F-score: 7249.78t for feature NK \n",
            "F-score: 1083.69t for feature OO \n",
            "F-score: 226.97t for feature UA \n",
            "F-score: 281.72t for feature US \n",
            "F-score: 186.88t for feature VX \n",
            "F-score: 1461.13t for feature WN \n",
            "F-score: 178632.38t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 107465.63t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 76724.22t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 37323.69t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 8353.07t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 14.77t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 176288.53t for feature WHEELS_OFF_HOUR \n",
            "F-score: 29034.75t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 486202.29t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 486202.29t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 486202.29t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 486202.29t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 486202.29t for feature WEATHER_DELAY_is_missing \n",
            "F-score: 255.44t for feature temperature \n",
            "F-score: 476.78t for feature humidity \n",
            "F-score: 20602.03t for feature wind_speed \n",
            "F-score: 23504.41t for feature wind_direction \n",
            "F-score: 20.25t for feature pressure \n",
            "Index(['DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
            "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iZMAvNE7E9NS",
        "outputId": "3bc1eaca-d243-490f-b6b1-51dee97ad5f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=50)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 18491.77t for feature MONTH \n",
            "F-score: 1842.31t for feature DAY \n",
            "F-score: 842.75t for feature DAY_OF_WEEK \n",
            "F-score: 65.10t for feature ORIGIN_AIRPORT \n",
            "F-score: 42.02t for feature DESTINATION_AIRPORT \n",
            "F-score: 511058.32t for feature DEPARTURE_DELAY \n",
            "F-score: 1384872.97t for feature TAXI_OUT \n",
            "F-score: 1361.31t for feature SCHEDULED_TIME \n",
            "F-score: 9074.91t for feature DISTANCE \n",
            "F-score: 132363.42t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 13101204.35t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 75910.10t for feature SECURITY_DELAY \n",
            "F-score: 19648072.50t for feature AIRLINE_DELAY \n",
            "F-score: 23331639.14t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 2747154.72t for feature WEATHER_DELAY \n",
            "F-score: 500380.35t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 2374411.18t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 198660.70t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 298.42t for feature AA \n",
            "F-score: 1532.33t for feature AS \n",
            "F-score: 569.50t for feature B6 \n",
            "F-score: 16421.09t for feature DL \n",
            "F-score: 71.66t for feature EV \n",
            "F-score: 2350.49t for feature F9 \n",
            "F-score: 473.39t for feature HA \n",
            "F-score: 1.27t for feature MQ \n",
            "F-score: 7249.78t for feature NK \n",
            "F-score: 1083.69t for feature OO \n",
            "F-score: 226.97t for feature UA \n",
            "F-score: 281.72t for feature US \n",
            "F-score: 186.88t for feature VX \n",
            "F-score: 1461.13t for feature WN \n",
            "F-score: 178632.38t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 107465.63t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 76724.22t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 37323.69t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 8353.07t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 14.77t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 176288.53t for feature WHEELS_OFF_HOUR \n",
            "F-score: 29034.75t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 486202.29t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 486202.29t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 486202.29t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 486202.29t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 486202.29t for feature WEATHER_DELAY_is_missing \n",
            "F-score: 255.44t for feature temperature \n",
            "F-score: 476.78t for feature humidity \n",
            "F-score: 20602.03t for feature wind_speed \n",
            "F-score: 23504.41t for feature wind_direction \n",
            "F-score: 20.25t for feature pressure \n",
            "Index(['MONTH', 'DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
            "       'DL', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR',\n",
            "       'SCHEDULED_ARRIVAL_HOUR', 'DEPARTURE_TIME_MINUTE', 'WHEELS_OFF_HOUR',\n",
            "       'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
            "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing',\n",
            "       'wind_speed', 'wind_direction'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5E3V06WmE_4l",
        "outputId": "a4890da0-7733-487d-c0a9-d957d36e3ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=75)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 18491.77t for feature MONTH \n",
            "F-score: 1842.31t for feature DAY \n",
            "F-score: 842.75t for feature DAY_OF_WEEK \n",
            "F-score: 65.10t for feature ORIGIN_AIRPORT \n",
            "F-score: 42.02t for feature DESTINATION_AIRPORT \n",
            "F-score: 511058.32t for feature DEPARTURE_DELAY \n",
            "F-score: 1384872.97t for feature TAXI_OUT \n",
            "F-score: 1361.31t for feature SCHEDULED_TIME \n",
            "F-score: 9074.91t for feature DISTANCE \n",
            "F-score: 132363.42t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 13101204.35t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 75910.10t for feature SECURITY_DELAY \n",
            "F-score: 19648072.50t for feature AIRLINE_DELAY \n",
            "F-score: 23331639.14t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 2747154.72t for feature WEATHER_DELAY \n",
            "F-score: 500380.35t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 2374411.18t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 198660.70t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 298.42t for feature AA \n",
            "F-score: 1532.33t for feature AS \n",
            "F-score: 569.50t for feature B6 \n",
            "F-score: 16421.09t for feature DL \n",
            "F-score: 71.66t for feature EV \n",
            "F-score: 2350.49t for feature F9 \n",
            "F-score: 473.39t for feature HA \n",
            "F-score: 1.27t for feature MQ \n",
            "F-score: 7249.78t for feature NK \n",
            "F-score: 1083.69t for feature OO \n",
            "F-score: 226.97t for feature UA \n",
            "F-score: 281.72t for feature US \n",
            "F-score: 186.88t for feature VX \n",
            "F-score: 1461.13t for feature WN \n",
            "F-score: 178632.38t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 107465.63t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 76724.22t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 37323.69t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 8353.07t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 14.77t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 176288.53t for feature WHEELS_OFF_HOUR \n",
            "F-score: 29034.75t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 486202.29t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 486202.29t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 486202.29t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 486202.29t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 486202.29t for feature WEATHER_DELAY_is_missing \n",
            "F-score: 255.44t for feature temperature \n",
            "F-score: 476.78t for feature humidity \n",
            "F-score: 20602.03t for feature wind_speed \n",
            "F-score: 23504.41t for feature wind_direction \n",
            "F-score: 20.25t for feature pressure \n",
            "Index(['MONTH', 'DAY', 'DAY_OF_WEEK', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'SCHEDULED_TIME', 'DISTANCE', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
            "       'AS', 'B6', 'DL', 'F9', 'HA', 'NK', 'OO', 'WN', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR',\n",
            "       'DEPARTURE_TIME_MINUTE', 'SCHEDULED_DEPARTURE_MINUTE',\n",
            "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
            "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing',\n",
            "       'humidity', 'wind_speed', 'wind_direction'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nnPzt_pvDJs6",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "val_df, test_df = train_test_split(test_data, test_size=0.333, random_state=0)\n",
        "\n",
        "#Y_train=pd.DataFrame(train_data['OUTCOME'])\n",
        "#X_train=train_data.drop(\"OUTCOME\",axis=1)\n",
        "\n",
        "Y_test=pd.DataFrame(test_df['OUTCOME'])\n",
        "X_test=test_df.drop(\"OUTCOME\",axis=1)\n",
        "\n",
        "Y_valid=pd.DataFrame(val_df['OUTCOME'])\n",
        "X_valid=val_df.drop(\"OUTCOME\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s_vLx-nobFzs",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer,accuracy_score,roc_auc_score\n",
        "from sklearn import metrics\n",
        "\n",
        "def cross_validation(model,X,y):\n",
        "  scores = cross_validate(model, X, y, scoring={'accuracy':make_scorer(accuracy_score),'roc_auc':make_scorer(roc_auc_score)},cv=5)\n",
        "  print(\"Cross-validated scores:\", scores)\n",
        "  print(\"cross for accuracy\",scores['test_accuracy'])\n",
        "  print(\"cross for roc-auc\",scores['test_roc_auc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZIBZy8h6bUmh",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "def report(Y_test,pred):\n",
        "  score1=metrics.roc_auc_score(Y_test,pred)\n",
        "  score2=metrics.accuracy_score(Y_test,pred)\n",
        "\n",
        "  print(f\"Test ROC AUC score: {score1}\")\n",
        "  print(f\"Test accuracy score: {score2}\")\n",
        "  print(\"Confusion matrix is \",metrics.confusion_matrix(Y_test,pred))\n",
        "  print(\"Classification report is \\n\",metrics.classification_report(Y_test,pred))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "REAFrlKudcHT",
        "colab": {}
      },
      "source": [
        "from math import log\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def calculate_aic(n, mse, num_params):\n",
        "\taic = n * log(mse) + 2 * num_params\n",
        "\treturn aic\n",
        "\n",
        "def calculate_bic(n, mse, num_params):\n",
        "\tbic = n * log(mse) + num_params * log(n)\n",
        "\treturn bic\n",
        "  \n",
        "def aic_and_bic(Y_test,pred,num_params):\n",
        "  mse=mean_squared_error(Y_test,pred)\n",
        "  print(pred)\n",
        "  print('Number of parameters: %d' % (num_params))\n",
        "  aic=calculate_aic(len(Y_train), mse, num_params)\n",
        "  print('AIC: %.3f' % aic)\n",
        "  bic = calculate_bic(len(y), mse, num_params)\n",
        "  print('BIC: %.3f' % bic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0jLcuAH-cSKo",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.svm import *\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iePhsaLZ50Im",
        "colab_type": "code",
        "outputId": "c4976228-d1d3-44e0-bdc3-fbe8b6701e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "cols=['MONTH','ORIGIN_AIRPORT','DESTINATION_AIRPORT','DEPARTURE_DELAY','TAXI_OUT','DISTANCE','SCHEDULED_TIME',\n",
        "'AIR_SYSTEM_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY','SECURITY_DELAY','AIRLINE_ORIGIN_AIRPORT','AIRLINE_DESTINATION_AIRPORT',\n",
        "'DEPARTURE_TIME_HOUR','SCHEDULED_DEPARTURE_HOUR','SCHEDULED_ARRIVAL_HOUR','WHEELS_OFF_HOUR','WHEELS_OFF_MINUTE',\n",
        "'AIR_SYSTEM_DELAY_is_missing','SECURITY_DELAY_is_missing','AIRLINE_DELAY_is_missing','LATE_AIRCRAFT_DELAY_is_missing','WEATHER_DELAY_is_missing',\n",
        "'temperature','humidity','pressure','wind_speed','wind_direction']\n",
        "print(cols)\n",
        "print(len(cols))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n",
            "29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Qio4-8g6aQJ",
        "outputId": "f75726d7-537c-4978-85e5-0cd50676c61b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "selected_X_train=X_train[cols]\n",
        "print(selected_X_train)\n",
        "\n",
        "lgbmclassifier=LGBMClassifier()\n",
        "selector = RFECV(estimator=lgbmclassifier, cv=5,scoring='accuracy',n_jobs=1)\n",
        "selector.fit(selected_X_train,Y_train)\n",
        "print(\"Optimal number of features: %d\" % selector.n_features_)\n",
        "print(selected_X_train.columns[selector.support_])\n",
        "print(selector.ranking_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             MONTH  ORIGIN_AIRPORT  ...  wind_speed  wind_direction\n",
            "0         5.000000        0.254655  ...    3.000000      346.000000\n",
            "1         8.000000        0.308900  ...    4.000000      275.000000\n",
            "2         9.000000        0.254655  ...    3.000000       30.000000\n",
            "3         4.000000        0.336164  ...    3.000000       58.000000\n",
            "4         1.000000        0.336164  ...    4.000000      239.000000\n",
            "...            ...             ...  ...         ...             ...\n",
            "3350795   1.506379        0.254655  ...    3.012758      303.748789\n",
            "3350796  11.000000        0.328222  ...    3.690208      242.423748\n",
            "3350797   7.578120        0.293531  ...    3.281253      334.671685\n",
            "3350798   5.000000        0.324190  ...    1.936729       98.738689\n",
            "3350799   1.523548        0.331816  ...    2.905808      257.069066\n",
            "\n",
            "[3350800 rows x 29 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimal number of features: 13\n",
            "Index(['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
            "       'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'WHEELS_OFF_HOUR',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'pressure', 'wind_speed'],\n",
            "      dtype='object')\n",
            "[ 1  1  1  1  1  1  1 10 16 12  9  8  1  1  7  6  3  1 11  1 13 14 15 17\n",
            "  5  2  1  1  4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "raZFbf_bIrHa",
        "outputId": "e8844b78-4d6d-4a3e-c1fc-b2e92a8077ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "selected_X_train=X_train[cols]\n",
        "print(selected_X_train)\n",
        "\n",
        "model = LGBMClassifier()\n",
        "model.fit(selected_X_train,Y_train)\n",
        "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "#plot graph of feature importances for better visualization\n",
        "feat_importances = pd.Series(model.feature_importances_, index=selected_X_train.columns)\n",
        "feat_importances.nlargest(24).plot(kind='barh')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             MONTH  ORIGIN_AIRPORT  ...  wind_speed  wind_direction\n",
            "0         5.000000        0.254655  ...    3.000000      346.000000\n",
            "1         8.000000        0.308900  ...    4.000000      275.000000\n",
            "2         9.000000        0.254655  ...    3.000000       30.000000\n",
            "3         4.000000        0.336164  ...    3.000000       58.000000\n",
            "4         1.000000        0.336164  ...    4.000000      239.000000\n",
            "...            ...             ...  ...         ...             ...\n",
            "3350795   1.506379        0.254655  ...    3.012758      303.748789\n",
            "3350796  11.000000        0.328222  ...    3.690208      242.423748\n",
            "3350797   7.578120        0.293531  ...    3.281253      334.671685\n",
            "3350798   5.000000        0.324190  ...    1.936729       98.738689\n",
            "3350799   1.523548        0.331816  ...    2.905808      257.069066\n",
            "\n",
            "[3350800 rows x 29 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[180 184  48 668 669 347 396   0   0   0   0   0 173  60   4   5  13  16\n",
            "   0  81   0   0   0   0  11  17  25  93  10]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEoNAdnTL873",
        "colab_type": "code",
        "outputId": "ed1ea99c-bbdc-45a0-84c3-746766d08d6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cols_after_removing_recursive=['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
        "       'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT',\n",
        "       'AIRLINE_DESTINATION_AIRPORT', 'WHEELS_OFF_HOUR',\n",
        "       'AIR_SYSTEM_DELAY_is_missing', 'pressure', 'wind_speed']\n",
        "print(len(cols_after_removing_recursive))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5pi4gQReHbqt",
        "outputId": "64750816-5e89-4463-fcef-8c950687bd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpBernoulliNBModel():\n",
        "  model = BernoulliNB()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpBernoulliNBModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 1 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8190005941527178\n",
            "Test accuracy score: 0.8898648867656849\n",
            "Confusion matrix is  [[558097      0]\n",
            " [ 88344 155701]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.93    558097\n",
            "           1       1.00      0.64      0.78    244045\n",
            "\n",
            "    accuracy                           0.89    802142\n",
            "   macro avg       0.93      0.82      0.85    802142\n",
            "weighted avg       0.90      0.89      0.88    802142\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([1.99183226, 1.68242741, 1.68979955, 1.68275881, 1.64707398]), 'score_time': array([0.52345419, 0.51428699, 0.50859761, 0.50866985, 0.51663709]), 'test_accuracy': array([0.89028888, 0.8898479 , 0.88969502, 0.88931169, 0.89015003]), 'test_roc_auc': array([0.81951458, 0.81878912, 0.81853791, 0.8179073 , 0.81928644])}\n",
            "cross for accuracy [0.89028888 0.8898479  0.88969502 0.88931169 0.89015003]\n",
            "cross for roc-auc [0.81951458 0.81878912 0.81853791 0.8179073  0.81928644]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y5T6_ef4OO_u",
        "outputId": "1e734af0-f100-43ff-b089-f9f076028c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpLinearSVCModel():\n",
        "  model = LinearSVC(random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpLinearSVCModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 1 1 ... 0 0 1]\n",
            "Test ROC AUC score: 0.8532021829072994\n",
            "Test accuracy score: 0.8392765869384723\n",
            "Confusion matrix is  [[456319 101778]\n",
            " [ 27145 216900]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.82      0.88    558097\n",
            "           1       0.68      0.89      0.77    244045\n",
            "\n",
            "    accuracy                           0.84    802142\n",
            "   macro avg       0.81      0.85      0.82    802142\n",
            "weighted avg       0.86      0.84      0.84    802142\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([1105.7853179 , 1066.17519736, 1083.73204374, 1068.52170157,\n",
            "       1077.35190964]), 'score_time': array([0.31255555, 0.29819727, 0.30377221, 0.30368543, 0.35512972]), 'test_accuracy': array([0.91505869, 0.90330643, 0.88857932, 0.90523227, 0.90484427]), 'test_roc_auc': array([0.87770274, 0.85350383, 0.81671113, 0.84768683, 0.86107398])}\n",
            "cross for accuracy [0.91505869 0.90330643 0.88857932 0.90523227 0.90484427]\n",
            "cross for roc-auc [0.87770274 0.85350383 0.81671113 0.84768683 0.86107398]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Pfvps8ZPgE2",
        "outputId": "6e510ca8-f77e-4aea-b501-5c2f31e2d84c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpLGBMClassifierModel():\n",
        "  model = LGBMClassifier(random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 1 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8845391049674239\n",
            "Test accuracy score: 0.918338648269259\n",
            "Confusion matrix is  [[541839  16258]\n",
            " [ 49246 194799]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94    558097\n",
            "           1       0.92      0.80      0.86    244045\n",
            "\n",
            "    accuracy                           0.92    802142\n",
            "   macro avg       0.92      0.88      0.90    802142\n",
            "weighted avg       0.92      0.92      0.92    802142\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([25.23069263, 24.96907282, 24.75366282, 24.65447116, 24.66877818]), 'score_time': array([1.90155363, 1.8838675 , 1.89056301, 1.91990399, 1.86559558]), 'test_accuracy': array([0.92016817, 0.91927841, 0.91990314, 0.91903676, 0.92039866]), 'test_roc_auc': array([0.88350887, 0.88232963, 0.88296908, 0.88171276, 0.88378426])}\n",
            "cross for accuracy [0.92016817 0.91927841 0.91990314 0.91903676 0.92039866]\n",
            "cross for roc-auc [0.88350887 0.88232963 0.88296908 0.88171276 0.88378426]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W-dq1z4DYbE7",
        "outputId": "05b286ee-a410-43ba-ca6e-012821a846b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpDecisionTreeModel():\n",
        "  tree = DecisionTreeClassifier(random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  tree.fit(sel_X_train, Y_train)\n",
        "  pred=tree.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(tree,X,y)\n",
        "\n",
        "runexpDecisionTreeModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n",
            "predictions are  [1 1 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.851275491724302\n",
            "Test accuracy score: 0.870556584744347\n",
            "Confusion matrix is  [[502579  55518]\n",
            " [ 48314 195731]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.90      0.91    558097\n",
            "           1       0.78      0.80      0.79    244045\n",
            "\n",
            "    accuracy                           0.87    802142\n",
            "   macro avg       0.85      0.85      0.85    802142\n",
            "weighted avg       0.87      0.87      0.87    802142\n",
            "\n",
            "\n",
            "\n",
            "Cross-validated scores: {'fit_time': array([57.73596835, 59.87269878, 62.59960961, 62.24434638, 61.83911896]), 'score_time': array([0.57207656, 0.60427189, 0.58401871, 0.61215806, 0.60062242]), 'test_accuracy': array([0.87345676, 0.87294098, 0.87355161, 0.87298285, 0.87349552]), 'test_roc_auc': array([0.85450118, 0.85370611, 0.85423576, 0.85327987, 0.85442797])}\n",
            "cross for accuracy [0.87345676 0.87294098 0.87355161 0.87298285 0.87349552]\n",
            "cross for roc-auc [0.85450118 0.85370611 0.85423576 0.85327987 0.85442797]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1T8qD_h5S9mU",
        "outputId": "b5ea8b09-dbb3-4642-e28c-916dcba669d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpRandomForestModel():\n",
        "  forest = RandomForestClassifier(max_features=16,max_depth=25,min_samples_leaf=10,random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  forest.fit(sel_X_train, Y_train)\n",
        "  pred=forest.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)                                         #91.87\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(forest,X,y)\n",
        "\n",
        "runexpRandomForestModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 1 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.884233096460892\n",
            "Test accuracy score: 0.9185032076614864\n",
            "Confusion matrix is  [[542339  15758]\n",
            " [ 49614 194431]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94    558097\n",
            "           1       0.93      0.80      0.86    244045\n",
            "\n",
            "    accuracy                           0.92    802142\n",
            "   macro avg       0.92      0.88      0.90    802142\n",
            "weighted avg       0.92      0.92      0.92    802142\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([3403.81328917, 3719.38586807, 3639.58003139, 3608.16589308,\n",
            "       3486.36436272]), 'score_time': array([21.14107108, 21.52273655, 21.34525776, 21.43328524, 21.51010394]), 'test_accuracy': array([0.92085223, 0.92012453, 0.92050151, 0.91981588, 0.92069784]), 'test_roc_auc': array([0.88378508, 0.88273813, 0.88327615, 0.88206591, 0.88371901])}\n",
            "cross for accuracy [0.92085223 0.92012453 0.92050151 0.91981588 0.92069784]\n",
            "cross for roc-auc [0.88378508 0.88273813 0.88327615 0.88206591 0.88371901]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "guOphXVvu15j",
        "outputId": "e7fcc0f3-afb9-429d-9f26-8bbe40face18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLogisticRegressionModel():\n",
        "  lrmodel=LogisticRegression()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  lrmodel.fit(sel_X_train, Y_train)\n",
        "  pred=lrmodel.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(lrmodel,X,y)\n",
        "  num_params = len(lrmodel.coef_) + 1\n",
        "  aic_and_bic(Y_test,pred,num_params)\n",
        "\n",
        "runLogisticRegressionModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 1 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.832182929436141\n",
            "Test accuracy score: 0.87796923736695\n",
            "Confusion matrix is  [[529706  28391]\n",
            " [ 69495 174550]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.92    558097\n",
            "           1       0.86      0.72      0.78    244045\n",
            "\n",
            "    accuracy                           0.88    802142\n",
            "   macro avg       0.87      0.83      0.85    802142\n",
            "weighted avg       0.88      0.88      0.87    802142\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([49.19567943, 51.90481377, 49.79476285, 49.16554546, 48.39933252]), 'score_time': array([0.30513763, 0.30113983, 0.29529834, 0.31178641, 0.29704785]), 'test_accuracy': array([0.89242835, 0.89225227, 0.89157738, 0.89162101, 0.89215081]), 'test_roc_auc': array([0.82717889, 0.82827271, 0.82688689, 0.82675504, 0.82686411])}\n",
            "cross for accuracy [0.89242835 0.89225227 0.89157738 0.89162101 0.89215081]\n",
            "cross for roc-auc [0.82717889 0.82827271 0.82688689 0.82675504 0.82686411]\n",
            "[1 1 0 ... 0 0 0]\n",
            "Number of parameters: 2\n",
            "AIC: -7048343.865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-345415a34426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0maic_and_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrunLogisticRegressionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-345415a34426>\u001b[0m in \u001b[0;36mrunLogisticRegressionModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mnum_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0maic_and_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mrunLogisticRegressionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-15c7f88bee80>\u001b[0m in \u001b[0;36maic_and_bic\u001b[0;34m(Y_test, pred, num_params)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0maic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalculate_aic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AIC: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mbic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BIC: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBxc3eE0YXL8",
        "colab_type": "code",
        "outputId": "a551363f-12fd-41cf-8721-c3fbac67abf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runXGBClassifierModel():\n",
        "  model=XGBClassifier(random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runXGBClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 1 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8782494601127837\n",
            "Test accuracy score: 0.9076373011262345\n",
            "Confusion matrix is  [[532040  26057]\n",
            " [ 48031 196014]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93    558097\n",
            "           1       0.88      0.80      0.84    244045\n",
            "\n",
            "    accuracy                           0.91    802142\n",
            "   macro avg       0.90      0.88      0.89    802142\n",
            "weighted avg       0.91      0.91      0.91    802142\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([358.30549622, 376.62025023, 378.89813113, 353.74644017,\n",
            "       347.60844684]), 'score_time': array([2.09779072, 2.05529618, 2.09760857, 2.0885725 , 2.3814919 ]), 'test_accuracy': array([0.91282729, 0.91252811, 0.91268068, 0.9119187 , 0.9130718 ]), 'test_roc_auc': array([0.86973411, 0.86934446, 0.86911765, 0.86779913, 0.86949969])}\n",
            "cross for accuracy [0.91282729 0.91252811 0.91268068 0.9119187  0.9130718 ]\n",
            "cross for roc-auc [0.86973411 0.86934446 0.86911765 0.86779913 0.86949969]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VEX6VSX0SbJT",
        "outputId": "99a64b10-8712-4014-b823-6768491fd7e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(max_bin=175,num_leaves=150,lambda_l1=2,lambda_l2=2,max_depth=100)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 1 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8877866362797967\n",
            "Test accuracy score: 0.9216335760999923\n",
            "Confusion matrix is  [[543719  14378]\n",
            " [ 48483 195562]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95    558097\n",
            "           1       0.93      0.80      0.86    244045\n",
            "\n",
            "    accuracy                           0.92    802142\n",
            "   macro avg       0.92      0.89      0.90    802142\n",
            "weighted avg       0.92      0.92      0.92    802142\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([37.8203609 , 37.49869943, 37.40242887, 37.41205502, 36.49961042]), 'score_time': array([2.39751124, 2.41896319, 2.457232  , 2.36873388, 2.4288168 ]), 'test_accuracy': array([0.9225663 , 0.92210662, 0.92226076, 0.92152683, 0.92288406]), 'test_roc_auc': array([0.88767932, 0.88700975, 0.88714942, 0.88592903, 0.88815891])}\n",
            "cross for accuracy [0.9225663  0.92210662 0.92226076 0.92152683 0.92288406]\n",
            "cross for roc-auc [0.88767932 0.88700975 0.88714942 0.88592903 0.88815891]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E9wkWA2b1USV",
        "outputId": "80b5e1e1-5dd7-4e6a-fc9c-2297f5c5931e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(max_bin=150,num_leaves=150,lambda_l1=5,lambda_l2=5,max_depth=90,bagging_fraction=0.8)#decrease bagging_fraction\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 1 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8881567560626986\n",
            "Test accuracy score: 0.921773202250973\n",
            "Confusion matrix is  [[543597  14500]\n",
            " [ 48249 195796]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95    558097\n",
            "           1       0.93      0.80      0.86    244045\n",
            "\n",
            "    accuracy                           0.92    802142\n",
            "   macro avg       0.92      0.89      0.90    802142\n",
            "weighted avg       0.92      0.92      0.92    802142\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([37.35544038, 37.51785493, 37.36953092, 37.44501877, 37.41005707]), 'score_time': array([2.4088316 , 2.41800952, 2.40239143, 2.38714266, 2.4321475 ]), 'test_accuracy': array([0.92266291, 0.92173576, 0.9222109 , 0.92150034, 0.92268928]), 'test_roc_auc': array([0.88784547, 0.88665959, 0.88700529, 0.88607463, 0.88802478])}\n",
            "cross for accuracy [0.92266291 0.92173576 0.9222109  0.92150034 0.92268928]\n",
            "cross for roc-auc [0.88784547 0.88665959 0.88700529 0.88607463 0.88802478]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OQQEenwR-EHf",
        "outputId": "1f3b08a1-1778-4a19-8986-1877388fb1a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(learning_rate=0.2,max_bin=150,num_leaves=250,min_data_in_leaf=300,lambda_l1=4,lambda_l2=4,max_depth=80,bagging_fraction=0.7)#decrease bagging_fraction\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 1 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.891201867748537\n",
            "Test accuracy score: 0.9239025010534294\n",
            "Confusion matrix is  [[543991  14106]\n",
            " [ 46935 197110]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95    558097\n",
            "           1       0.93      0.81      0.87    244045\n",
            "\n",
            "    accuracy                           0.92    802142\n",
            "   macro avg       0.93      0.89      0.91    802142\n",
            "weighted avg       0.92      0.92      0.92    802142\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([42.68389559, 42.08827353, 41.54794574, 41.1907568 , 41.56853223]), 'score_time': array([2.78917003, 2.80365586, 2.74148059, 2.69501591, 2.82870674]), 'test_accuracy': array([0.92470421, 0.92359941, 0.92407456, 0.92345749, 0.92462462]), 'test_roc_auc': array([0.89175527, 0.89028437, 0.8907947 , 0.88968714, 0.8917357 ])}\n",
            "cross for accuracy [0.92470421 0.92359941 0.92407456 0.92345749 0.92462462]\n",
            "cross for roc-auc [0.89175527 0.89028437 0.8907947  0.88968714 0.8917357 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ixe9qVM6_pj5",
        "outputId": "36c77bbd-8602-408b-ecd0-8d2f796be594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'max_bin':(125,150),#               #'learning_rate':(0.2,0.3),\n",
        "     'feature_fraction':(0.6,0.7),\n",
        "     'num_leaves':(250,300),#\n",
        "     'min_data_in_leaf':(300,400),\n",
        "     'lambda_l1':(1,2),#--6                    #'lambda_l2':(2,4,6),     #'max_depth':(60,80,90),\n",
        "     'bagging_fraction':(0.4,0.5)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=-1,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n",
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  4.2min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  6.5min\n",
            "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  8.3min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  8.5min\n",
            "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  8.8min\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 10.5min\n",
            "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed: 10.6min\n",
            "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed: 10.7min\n",
            "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed: 10.9min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 12.7min\n",
            "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed: 12.7min\n",
            "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed: 12.9min\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 13.1min\n",
            "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed: 14.8min\n",
            "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed: 15.1min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 15.1min\n",
            "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed: 16.7min\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed: 17.0min\n",
            "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed: 17.1min\n",
            "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed: 17.2min\n",
            "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 18.9min\n",
            "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 19.0min\n",
            "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed: 19.2min\n",
            "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed: 19.4min\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 20.9min\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed: 21.2min\n",
            "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed: 21.4min\n",
            "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed: 21.4min\n",
            "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed: 23.0min\n",
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 23.4min\n",
            "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed: 23.4min\n",
            "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed: 23.6min\n",
            "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 25.2min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 25.4min\n",
            "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed: 25.6min\n",
            "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed: 25.8min\n",
            "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed: 27.2min\n",
            "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed: 27.6min\n",
            "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed: 27.9min\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed: 28.0min\n",
            "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 29.5min\n",
            "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed: 30.0min\n",
            "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed: 30.0min\n",
            "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 30.2min\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed: 31.8min\n",
            "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed: 32.2min\n",
            "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed: 32.3min\n",
            "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed: 32.6min\n",
            "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed: 33.9min\n",
            "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed: 34.4min\n",
            "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed: 34.6min\n",
            "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 34.7min\n",
            "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed: 36.1min\n",
            "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed: 36.8min\n",
            "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed: 36.8min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 37.0min\n",
            "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 38.4min\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed: 39.0min\n",
            "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed: 39.1min\n",
            "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed: 39.3min\n",
            "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed: 40.4min\n",
            "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed: 41.2min\n",
            "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed: 41.3min\n",
            "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed: 41.5min\n",
            "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 42.7min\n",
            "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed: 43.4min\n",
            "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed: 43.4min\n",
            "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed: 43.7min\n",
            "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 44.9min\n",
            "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 45.6min\n",
            "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed: 45.7min\n",
            "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed: 46.0min\n",
            "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed: 46.9min\n",
            "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed: 47.7min\n",
            "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed: 47.9min\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed: 48.2min\n",
            "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed: 49.1min\n",
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 50.0min\n",
            "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed: 50.1min\n",
            "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed: 50.4min\n",
            "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed: 51.4min\n",
            "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 52.2min\n",
            "[Parallel(n_jobs=-1)]: Done  95 tasks      | elapsed: 52.4min\n",
            "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed: 52.7min\n",
            "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed: 53.3min\n",
            "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed: 54.4min\n",
            "[Parallel(n_jobs=-1)]: Done  99 tasks      | elapsed: 54.7min\n",
            "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed: 54.8min\n",
            "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed: 55.6min\n",
            "[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed: 56.6min\n",
            "[Parallel(n_jobs=-1)]: Done 103 tasks      | elapsed: 56.6min\n",
            "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed: 56.9min\n",
            "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 57.7min\n",
            "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed: 58.7min\n",
            "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed: 58.9min\n",
            "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed: 59.2min\n",
            "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed: 59.8min\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed: 60.8min\n",
            "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed: 61.1min\n",
            "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 61.3min\n",
            "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed: 61.9min\n",
            "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed: 63.1min\n",
            "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed: 63.1min\n",
            "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed: 63.4min\n",
            "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed: 64.1min\n",
            "[Parallel(n_jobs=-1)]: Done 118 tasks      | elapsed: 65.2min\n",
            "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed: 65.3min\n",
            "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 65.7min\n",
            "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed: 66.0min\n",
            "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed: 67.3min\n",
            "[Parallel(n_jobs=-1)]: Done 123 tasks      | elapsed: 67.5min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed: 67.7min\n",
            "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed: 68.2min\n",
            "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed: 69.4min\n",
            "[Parallel(n_jobs=-1)]: Done 127 tasks      | elapsed: 69.6min\n",
            "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed: 69.8min\n",
            "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed: 70.3min\n",
            "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed: 71.5min\n",
            "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed: 71.8min\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed: 72.1min\n",
            "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed: 72.3min\n",
            "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed: 73.6min\n",
            "[Parallel(n_jobs=-1)]: Done 135 tasks      | elapsed: 74.0min\n",
            "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed: 74.2min\n",
            "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 74.5min\n",
            "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 75.9min\n",
            "[Parallel(n_jobs=-1)]: Done 139 tasks      | elapsed: 76.0min\n",
            "[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed: 76.4min\n",
            "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed: 76.8min\n",
            "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed: 78.0min\n",
            "[Parallel(n_jobs=-1)]: Done 143 tasks      | elapsed: 78.3min\n",
            "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed: 78.7min\n",
            "[Parallel(n_jobs=-1)]: Done 145 tasks      | elapsed: 78.8min\n",
            "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 80.2min\n",
            "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed: 80.6min\n",
            "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed: 80.9min\n",
            "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed: 81.2min\n",
            "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed: 82.6min\n",
            "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed: 82.7min\n",
            "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed: 83.1min\n",
            "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed: 83.5min\n",
            "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 84.9min\n",
            "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed: 85.1min\n",
            "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed: 85.6min\n",
            "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed: 85.6min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 87.1min\n",
            "[Parallel(n_jobs=-1)]: Done 159 tasks      | elapsed: 87.4min\n",
            "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed: 87.8min\n",
            "[Parallel(n_jobs=-1)]: Done 161 tasks      | elapsed: 88.0min\n",
            "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed: 89.6min\n",
            "[Parallel(n_jobs=-1)]: Done 163 tasks      | elapsed: 89.7min\n",
            "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed: 90.2min\n",
            "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 90.4min\n",
            "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed: 91.9min\n",
            "[Parallel(n_jobs=-1)]: Done 167 tasks      | elapsed: 92.1min\n",
            "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 92.5min\n",
            "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed: 92.6min\n",
            "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed: 94.2min\n",
            "[Parallel(n_jobs=-1)]: Done 171 tasks      | elapsed: 94.4min\n",
            "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed: 94.8min\n",
            "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 95.0min\n",
            "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed: 96.6min\n",
            "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed: 96.6min\n",
            "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 97.0min\n",
            "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed: 97.3min\n",
            "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed: 98.8min\n",
            "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed: 99.0min\n",
            "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed: 99.4min\n",
            "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed: 99.5min\n",
            "[Parallel(n_jobs=-1)]: Done 182 tasks      | elapsed: 101.0min\n",
            "[Parallel(n_jobs=-1)]: Done 183 tasks      | elapsed: 101.3min\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 101.6min\n",
            "[Parallel(n_jobs=-1)]: Done 185 tasks      | elapsed: 101.8min\n",
            "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed: 103.5min\n",
            "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed: 103.5min\n",
            "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed: 104.0min\n",
            "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed: 104.2min\n",
            "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 106.0min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split',\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=90,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_state=None, reg_...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'bagging_fraction': (0.4, 0.5),\n",
            "                         'feature_fraction': (0.6, 0.7), 'lambda_l1': (1, 2),\n",
            "                         'max_bin': (125, 150), 'min_data_in_leaf': (300, 400),\n",
            "                         'num_leaves': (250, 300)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9317422912202974\n",
            "{'bagging_fraction': 0.4, 'feature_fraction': 0.7, 'lambda_l1': 1, 'max_bin': 150, 'min_data_in_leaf': 400, 'num_leaves': 300}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, learning_rate=0.1,\n",
            "               max_bin=150, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=400, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=90, num_leaves=300,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "52sUc9Uswc1x",
        "outputId": "3d6e0c12-7139-46e0-d171-06f77888e29e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'max_bin':(150,175),#               #'learning_rate':(0.2,0.3),\n",
        "     'feature_fraction':(0.7,0.8),\n",
        "     'num_leaves':(300,350),#\n",
        "     'min_data_in_leaf':(400,450),#                    #'lambda_l2':(2,4,6),     #'max_depth':(60,80,90),\n",
        "     'bagging_fraction':(0.3,0.4)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=-1,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=100,lambda_l1=1)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n",
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  5.3min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  5.4min\n",
            "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  8.1min\n",
            "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  8.2min\n",
            "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  8.4min\n",
            "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  8.5min\n",
            "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed: 10.8min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 10.9min\n",
            "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed: 11.2min\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 11.2min\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 13.6min\n",
            "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed: 13.8min\n",
            "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed: 13.9min\n",
            "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed: 13.9min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 16.4min\n",
            "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed: 16.4min\n",
            "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed: 16.7min\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 16.8min\n",
            "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 19.1min\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed: 19.3min\n",
            "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed: 19.6min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 19.6min\n",
            "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed: 22.0min\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed: 22.3min\n",
            "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed: 22.3min\n",
            "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed: 22.4min\n",
            "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 24.8min\n",
            "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 25.2min\n",
            "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed: 25.3min\n",
            "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed: 25.4min\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 27.6min\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed: 28.0min\n",
            "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed: 28.1min\n",
            "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed: 28.2min\n",
            "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed: 30.4min\n",
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 30.8min\n",
            "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed: 31.1min\n",
            "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 33.3min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 33.7min\n",
            "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed: 33.9min\n",
            "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed: 34.0min\n",
            "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed: 35.9min\n",
            "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed: 36.4min\n",
            "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed: 36.7min\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed: 36.7min\n",
            "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 38.7min\n",
            "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed: 39.2min\n",
            "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed: 39.3min\n",
            "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 39.4min\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed: 41.4min\n",
            "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed: 41.9min\n",
            "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed: 42.1min\n",
            "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed: 42.3min\n",
            "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed: 43.9min\n",
            "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed: 44.6min\n",
            "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed: 44.8min\n",
            "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 44.9min\n",
            "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed: 46.7min\n",
            "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed: 47.4min\n",
            "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed: 47.5min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 47.7min\n",
            "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 49.4min\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed: 50.0min\n",
            "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed: 50.3min\n",
            "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed: 50.5min\n",
            "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed: 52.1min\n",
            "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed: 52.8min\n",
            "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed: 53.2min\n",
            "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed: 53.4min\n",
            "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 55.0min\n",
            "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed: 55.7min\n",
            "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed: 55.8min\n",
            "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed: 56.1min\n",
            "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 57.7min\n",
            "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 58.5min\n",
            "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed: 58.8min\n",
            "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed: 59.2min\n",
            "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed: 60.5min\n",
            "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed: 61.3min\n",
            "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed: 61.7min\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed: 62.0min\n",
            "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed: 63.4min\n",
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 64.3min\n",
            "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed: 64.4min\n",
            "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed: 64.9min\n",
            "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed: 66.3min\n",
            "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed: 67.6min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=100,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_st...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'bagging_fraction': (0.3, 0.4),\n",
            "                         'feature_fraction': (0.7, 0.8), 'max_bin': (150, 175),\n",
            "                         'min_data_in_leaf': (400, 450),\n",
            "                         'num_leaves': (300, 350)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.93258895431105\n",
            "{'bagging_fraction': 0.3, 'feature_fraction': 0.8, 'max_bin': 175, 'min_data_in_leaf': 450, 'num_leaves': 350}\n",
            "LGBMClassifier(bagging_fraction=0.3, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.8,\n",
            "               importance_type='split', lambda_l1=1, learning_rate=0.1,\n",
            "               max_bin=175, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=450, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=100, num_leaves=350,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsyQkDeOaMmH",
        "colab_type": "code",
        "outputId": "cc086954-31f5-44c3-9874-b1de9488857d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'max_bin':(175,200),#  -->             #'learning_rate':(0.2,0.3),\n",
        "     'feature_fraction':(0.8,0.9),#-->\n",
        "     'num_leaves':(350,400),#-->\n",
        "     'min_data_in_leaf':(450,500),# -->           #'lambda_l2':(2,4,6),     #'max_depth':(60,80,90),\n",
        "     'bagging_fraction':(0.2,0.3)#<--\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=-1,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=100,lambda_l1=1)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n",
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  5.8min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  8.8min\n",
            "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  8.8min\n",
            "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  9.0min\n",
            "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  9.1min\n",
            "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed: 11.5min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 11.7min\n",
            "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed: 11.9min\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 12.0min\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed: 14.8min\n",
            "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed: 14.9min\n",
            "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed: 14.9min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 17.6min\n",
            "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed: 17.9min\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 18.0min\n",
            "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 20.6min\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed: 20.9min\n",
            "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed: 21.0min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 21.2min\n",
            "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed: 23.8min\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed: 24.0min\n",
            "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed: 24.2min\n",
            "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed: 24.2min\n",
            "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 27.0min\n",
            "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 27.1min\n",
            "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed: 27.4min\n",
            "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed: 27.5min\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 29.9min\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed: 30.1min\n",
            "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed: 30.5min\n",
            "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed: 30.5min\n",
            "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed: 33.2min\n",
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 33.5min\n",
            "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed: 33.5min\n",
            "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed: 33.7min\n",
            "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 36.3min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 36.6min\n",
            "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed: 36.7min\n",
            "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed: 37.0min\n",
            "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed: 39.1min\n",
            "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed: 39.5min\n",
            "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed: 39.7min\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed: 39.9min\n",
            "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 42.1min\n",
            "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed: 42.4min\n",
            "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed: 42.6min\n",
            "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 42.7min\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed: 45.0min\n",
            "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed: 45.3min\n",
            "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed: 45.6min\n",
            "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed: 45.8min\n",
            "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed: 47.8min\n",
            "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed: 48.2min\n",
            "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed: 48.4min\n",
            "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 48.6min\n",
            "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed: 50.7min\n",
            "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed: 51.3min\n",
            "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed: 51.3min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 51.6min\n",
            "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 53.7min\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed: 54.2min\n",
            "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed: 54.3min\n",
            "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed: 54.6min\n",
            "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed: 56.5min\n",
            "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed: 57.3min\n",
            "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed: 57.5min\n",
            "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed: 57.7min\n",
            "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 59.8min\n",
            "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed: 60.4min\n",
            "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed: 60.6min\n",
            "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed: 60.8min\n",
            "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 62.8min\n",
            "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 63.6min\n",
            "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed: 63.8min\n",
            "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed: 64.1min\n",
            "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed: 65.9min\n",
            "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed: 66.7min\n",
            "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed: 66.9min\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed: 67.2min\n",
            "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed: 69.0min\n",
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 69.9min\n",
            "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed: 70.0min\n",
            "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed: 70.3min\n",
            "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed: 72.1min\n",
            "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed: 73.3min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=100,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_st...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'bagging_fraction': (0.2, 0.3),\n",
            "                         'feature_fraction': (0.8, 0.9), 'max_bin': (175, 200),\n",
            "                         'min_data_in_leaf': (450, 500),\n",
            "                         'num_leaves': (350, 400)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.932794875229837\n",
            "{'bagging_fraction': 0.2, 'feature_fraction': 0.8, 'max_bin': 175, 'min_data_in_leaf': 450, 'num_leaves': 400}\n",
            "LGBMClassifier(bagging_fraction=0.2, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.8,\n",
            "               importance_type='split', lambda_l1=1, learning_rate=0.1,\n",
            "               max_bin=175, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=450, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=100, num_leaves=400,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d1qmccME6gNU",
        "outputId": "8eb62342-2c9c-4248-fc21-0d8a1c6a0883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'learning_rate':(0.2,0.3),\n",
        "     'lambda_l2':(2,4),     \n",
        "     'max_depth':(60,80,90)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=-1,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90,lambda_l1=1,bagging_fraction=0.2,feature_fraction=0.8,max_bin=175,min_data_in_leaf=450,num_leaves=400)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  5.6min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  5.7min\n",
            "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  8.3min\n",
            "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  8.5min\n",
            "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed: 10.9min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 11.2min\n",
            "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed: 11.2min\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 11.3min\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 13.7min\n",
            "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed: 14.0min\n",
            "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed: 14.1min\n",
            "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed: 14.2min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 16.7min\n",
            "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed: 16.9min\n",
            "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed: 17.0min\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 17.1min\n",
            "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 19.5min\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed: 19.8min\n",
            "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed: 19.9min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 20.0min\n",
            "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed: 22.3min\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed: 22.6min\n",
            "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed: 22.7min\n",
            "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed: 22.8min\n",
            "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 25.2min\n",
            "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed: 25.6min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.2,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      feature_fraction=0.8,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_bin=175,\n",
            "                                      max_depth=-1, min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=450, min_split_gain=0.0,\n",
            "                                      n_estimat...\n",
            "                                      num_iterations=90, num_leaves=400,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'lambda_l2': (2, 4), 'learning_rate': (0.2, 0.3),\n",
            "                         'max_depth': (60, 80, 90)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9342894431282148\n",
            "{'lambda_l2': 2, 'learning_rate': 0.3, 'max_depth': 60}\n",
            "LGBMClassifier(bagging_fraction=0.2, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.8,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=2,\n",
            "               learning_rate=0.3, max_bin=175, max_depth=60,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=450, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=400, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YwFiAmL4JZDO",
        "outputId": "608bee14-973f-46fa-ca39-3677315b59dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'learning_rate':(0.3,0.4),\n",
        "     'lambda_l2':(2,3),     \n",
        "     'max_depth':(50,60)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=-1,refit=\"accuracy\",pre_dispatch=5,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(num_iterations=90,lambda_l1=1,bagging_fraction=0.2,feature_fraction=0.8,max_bin=175,min_data_in_leaf=450,num_leaves=400)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  5.3min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  5.4min\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  8.1min\n",
            "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  8.1min\n",
            "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed: 10.7min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 10.7min\n",
            "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed: 10.8min\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 10.8min\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 13.4min\n",
            "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed: 13.4min\n",
            "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed: 13.5min\n",
            "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed: 13.5min\n",
            "[Parallel(n_jobs=-1)]: Done  21 out of  24 | elapsed: 16.0min remaining:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done  22 out of  24 | elapsed: 16.0min remaining:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 16.1min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 16.1min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.2,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0,\n",
            "                                      feature_fraction=0.8,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_bin=175,\n",
            "                                      max_depth=-1, min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=450, min_split_gain=0.0,\n",
            "                                      n_estimators=100, n_jobs=-1,\n",
            "                                      num_iterations=90, num_leaves=400,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'lambda_l2': (2, 3), 'learning_rate': (0.3, 0.4),\n",
            "                         'max_depth': (50, 60)},\n",
            "             pre_dispatch=5, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9342894431282148\n",
            "{'lambda_l2': 2, 'learning_rate': 0.3, 'max_depth': 50}\n",
            "LGBMClassifier(bagging_fraction=0.2, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, feature_fraction=0.8,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=2,\n",
            "               learning_rate=0.3, max_bin=175, max_depth=50,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=450, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=400, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZdlHThqYTZSQ",
        "outputId": "12391f58-e19f-4822-8818-13c25c4d8d09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {     \n",
        "     'max_depth':(30,40)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=4,refit=\"accuracy\",pre_dispatch=5,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(num_iterations=90,lambda_l1=1,bagging_fraction=0.2,feature_fraction=0.8,max_bin=175,min_data_in_leaf=450,num_leaves=400,lambda_l2=2,learning_rate=0.3)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['YEAR', 'DAY', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'DEPARTURE_DELAY', 'TAXI_OUT', 'SCHEDULED_TIME', 'DISTANCE', 'AIR_TIME',\n",
            "       'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
            "       'B6', 'DL', 'EV', 'F9', 'HA', 'NK', 'OO', 'DEPARTURE_TIME_HOUR'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  2.7min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=4)]: Done   3 out of   6 | elapsed:  2.7min remaining:  2.7min\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   6 | elapsed:  2.8min remaining:  1.4min\n",
            "[Parallel(n_jobs=4)]: Done   6 out of   6 | elapsed:  4.6min remaining:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done   6 out of   6 | elapsed:  4.6min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.2,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0,\n",
            "                                      feature_fraction=0.8,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      lambda_l2=2, learning_rate=0.3,\n",
            "                                      max_bin=175, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=450, min_split_gain=0.0,\n",
            "                                      n_estimators=100, n_jobs=-1,\n",
            "                                      num_iterations=90, num_leaves=400,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=4, param_grid={'max_depth': (30, 40)},\n",
            "             pre_dispatch=5, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9648958559393819\n",
            "{'max_depth': 40}\n",
            "LGBMClassifier(bagging_fraction=0.2, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, feature_fraction=0.8,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=2,\n",
            "               learning_rate=0.3, max_bin=175, max_depth=40,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=450, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=400, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cEBGv0t5Iixl",
        "outputId": "32a8fa87-f18c-437e-abb5-619679ebd0ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols,Y_train.OUTCOME.mean(),Y_test.OUTCOME.mean())\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(num_iterations=120,lambda_l1=1,bagging_fraction=0.2,feature_fraction=0.8,max_bin=175,min_data_in_leaf=450,num_leaves=400,lambda_l2=2,learning_rate=0.3,max_depth=40)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  sel_X_valid=X_valid[sel_cols]\n",
        "  eval_set = [(sel_X_test, Y_test)]\n",
        "  model.fit(sel_X_train, Y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
        "\n",
        "  print(\"Test dataset:\")\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(\"Validation dataset:\")\n",
        "  pred=model.predict(sel_X_valid)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_valid,pred)\n",
        "\n",
        "  \n",
        "  print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "  #plot graph of feature importances for better visualization\n",
        "  feat_importances = pd.Series(model.feature_importances_, index=sel_cols)\n",
        "  feat_importances.nlargest(26).plot(kind='barh')\n",
        "  plt.show()\n",
        "\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test,sel_X_valid])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test,Y_valid])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction'] 0.5 0.3036830716473116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.517079\tvalid_0's binary_logloss: 0.517079\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.423712\tvalid_0's binary_logloss: 0.423712\n",
            "[3]\tvalid_0's binary_logloss: 0.354425\tvalid_0's binary_logloss: 0.354425\n",
            "[4]\tvalid_0's binary_logloss: 0.310488\tvalid_0's binary_logloss: 0.310488\n",
            "[5]\tvalid_0's binary_logloss: 0.289031\tvalid_0's binary_logloss: 0.289031\n",
            "[6]\tvalid_0's binary_logloss: 0.266048\tvalid_0's binary_logloss: 0.266048\n",
            "[7]\tvalid_0's binary_logloss: 0.250659\tvalid_0's binary_logloss: 0.250659\n",
            "[8]\tvalid_0's binary_logloss: 0.241644\tvalid_0's binary_logloss: 0.241644\n",
            "[9]\tvalid_0's binary_logloss: 0.232987\tvalid_0's binary_logloss: 0.232987\n",
            "[10]\tvalid_0's binary_logloss: 0.228635\tvalid_0's binary_logloss: 0.228635\n",
            "[11]\tvalid_0's binary_logloss: 0.224803\tvalid_0's binary_logloss: 0.224803\n",
            "[12]\tvalid_0's binary_logloss: 0.220191\tvalid_0's binary_logloss: 0.220191\n",
            "[13]\tvalid_0's binary_logloss: 0.2169\tvalid_0's binary_logloss: 0.2169\n",
            "[14]\tvalid_0's binary_logloss: 0.214672\tvalid_0's binary_logloss: 0.214672\n",
            "[15]\tvalid_0's binary_logloss: 0.21307\tvalid_0's binary_logloss: 0.21307\n",
            "[16]\tvalid_0's binary_logloss: 0.211322\tvalid_0's binary_logloss: 0.211322\n",
            "[17]\tvalid_0's binary_logloss: 0.209793\tvalid_0's binary_logloss: 0.209793\n",
            "[18]\tvalid_0's binary_logloss: 0.208632\tvalid_0's binary_logloss: 0.208632\n",
            "[19]\tvalid_0's binary_logloss: 0.207727\tvalid_0's binary_logloss: 0.207727\n",
            "[20]\tvalid_0's binary_logloss: 0.206799\tvalid_0's binary_logloss: 0.206799\n",
            "[21]\tvalid_0's binary_logloss: 0.206351\tvalid_0's binary_logloss: 0.206351\n",
            "[22]\tvalid_0's binary_logloss: 0.205438\tvalid_0's binary_logloss: 0.205438\n",
            "[23]\tvalid_0's binary_logloss: 0.204856\tvalid_0's binary_logloss: 0.204856\n",
            "[24]\tvalid_0's binary_logloss: 0.204211\tvalid_0's binary_logloss: 0.204211\n",
            "[25]\tvalid_0's binary_logloss: 0.203676\tvalid_0's binary_logloss: 0.203676\n",
            "[26]\tvalid_0's binary_logloss: 0.20311\tvalid_0's binary_logloss: 0.20311\n",
            "[27]\tvalid_0's binary_logloss: 0.202719\tvalid_0's binary_logloss: 0.202719\n",
            "[28]\tvalid_0's binary_logloss: 0.202383\tvalid_0's binary_logloss: 0.202383\n",
            "[29]\tvalid_0's binary_logloss: 0.202203\tvalid_0's binary_logloss: 0.202203\n",
            "[30]\tvalid_0's binary_logloss: 0.201765\tvalid_0's binary_logloss: 0.201765\n",
            "[31]\tvalid_0's binary_logloss: 0.201413\tvalid_0's binary_logloss: 0.201413\n",
            "[32]\tvalid_0's binary_logloss: 0.201107\tvalid_0's binary_logloss: 0.201107\n",
            "[33]\tvalid_0's binary_logloss: 0.200809\tvalid_0's binary_logloss: 0.200809\n",
            "[34]\tvalid_0's binary_logloss: 0.200644\tvalid_0's binary_logloss: 0.200644\n",
            "[35]\tvalid_0's binary_logloss: 0.200166\tvalid_0's binary_logloss: 0.200166\n",
            "[36]\tvalid_0's binary_logloss: 0.200049\tvalid_0's binary_logloss: 0.200049\n",
            "[37]\tvalid_0's binary_logloss: 0.199721\tvalid_0's binary_logloss: 0.199721\n",
            "[38]\tvalid_0's binary_logloss: 0.199548\tvalid_0's binary_logloss: 0.199548\n",
            "[39]\tvalid_0's binary_logloss: 0.199374\tvalid_0's binary_logloss: 0.199374\n",
            "[40]\tvalid_0's binary_logloss: 0.199202\tvalid_0's binary_logloss: 0.199202\n",
            "[41]\tvalid_0's binary_logloss: 0.19906\tvalid_0's binary_logloss: 0.19906\n",
            "[42]\tvalid_0's binary_logloss: 0.198849\tvalid_0's binary_logloss: 0.198849\n",
            "[43]\tvalid_0's binary_logloss: 0.19867\tvalid_0's binary_logloss: 0.19867\n",
            "[44]\tvalid_0's binary_logloss: 0.198495\tvalid_0's binary_logloss: 0.198495\n",
            "[45]\tvalid_0's binary_logloss: 0.198259\tvalid_0's binary_logloss: 0.198259\n",
            "[46]\tvalid_0's binary_logloss: 0.19806\tvalid_0's binary_logloss: 0.19806\n",
            "[47]\tvalid_0's binary_logloss: 0.198046\tvalid_0's binary_logloss: 0.198046\n",
            "[48]\tvalid_0's binary_logloss: 0.197817\tvalid_0's binary_logloss: 0.197817\n",
            "[49]\tvalid_0's binary_logloss: 0.197626\tvalid_0's binary_logloss: 0.197626\n",
            "[50]\tvalid_0's binary_logloss: 0.19755\tvalid_0's binary_logloss: 0.19755\n",
            "[51]\tvalid_0's binary_logloss: 0.19746\tvalid_0's binary_logloss: 0.19746\n",
            "[52]\tvalid_0's binary_logloss: 0.197388\tvalid_0's binary_logloss: 0.197388\n",
            "[53]\tvalid_0's binary_logloss: 0.197329\tvalid_0's binary_logloss: 0.197329\n",
            "[54]\tvalid_0's binary_logloss: 0.197096\tvalid_0's binary_logloss: 0.197096\n",
            "[55]\tvalid_0's binary_logloss: 0.197074\tvalid_0's binary_logloss: 0.197074\n",
            "[56]\tvalid_0's binary_logloss: 0.196969\tvalid_0's binary_logloss: 0.196969\n",
            "[57]\tvalid_0's binary_logloss: 0.196929\tvalid_0's binary_logloss: 0.196929\n",
            "[58]\tvalid_0's binary_logloss: 0.196772\tvalid_0's binary_logloss: 0.196772\n",
            "[59]\tvalid_0's binary_logloss: 0.196735\tvalid_0's binary_logloss: 0.196735\n",
            "[60]\tvalid_0's binary_logloss: 0.19661\tvalid_0's binary_logloss: 0.19661\n",
            "[61]\tvalid_0's binary_logloss: 0.196606\tvalid_0's binary_logloss: 0.196606\n",
            "[62]\tvalid_0's binary_logloss: 0.196602\tvalid_0's binary_logloss: 0.196602\n",
            "[63]\tvalid_0's binary_logloss: 0.196625\tvalid_0's binary_logloss: 0.196625\n",
            "[64]\tvalid_0's binary_logloss: 0.196485\tvalid_0's binary_logloss: 0.196485\n",
            "[65]\tvalid_0's binary_logloss: 0.196327\tvalid_0's binary_logloss: 0.196327\n",
            "[66]\tvalid_0's binary_logloss: 0.196247\tvalid_0's binary_logloss: 0.196247\n",
            "[67]\tvalid_0's binary_logloss: 0.196105\tvalid_0's binary_logloss: 0.196105\n",
            "[68]\tvalid_0's binary_logloss: 0.196102\tvalid_0's binary_logloss: 0.196102\n",
            "[69]\tvalid_0's binary_logloss: 0.196089\tvalid_0's binary_logloss: 0.196089\n",
            "[70]\tvalid_0's binary_logloss: 0.196063\tvalid_0's binary_logloss: 0.196063\n",
            "[71]\tvalid_0's binary_logloss: 0.196043\tvalid_0's binary_logloss: 0.196043\n",
            "[72]\tvalid_0's binary_logloss: 0.195949\tvalid_0's binary_logloss: 0.195949\n",
            "[73]\tvalid_0's binary_logloss: 0.195912\tvalid_0's binary_logloss: 0.195912\n",
            "[74]\tvalid_0's binary_logloss: 0.19588\tvalid_0's binary_logloss: 0.19588\n",
            "[75]\tvalid_0's binary_logloss: 0.195854\tvalid_0's binary_logloss: 0.195854\n",
            "[76]\tvalid_0's binary_logloss: 0.195831\tvalid_0's binary_logloss: 0.195831\n",
            "[77]\tvalid_0's binary_logloss: 0.195807\tvalid_0's binary_logloss: 0.195807\n",
            "[78]\tvalid_0's binary_logloss: 0.195809\tvalid_0's binary_logloss: 0.195809\n",
            "[79]\tvalid_0's binary_logloss: 0.195754\tvalid_0's binary_logloss: 0.195754\n",
            "[80]\tvalid_0's binary_logloss: 0.195655\tvalid_0's binary_logloss: 0.195655\n",
            "[81]\tvalid_0's binary_logloss: 0.195585\tvalid_0's binary_logloss: 0.195585\n",
            "[82]\tvalid_0's binary_logloss: 0.195532\tvalid_0's binary_logloss: 0.195532\n",
            "[83]\tvalid_0's binary_logloss: 0.19551\tvalid_0's binary_logloss: 0.19551\n",
            "[84]\tvalid_0's binary_logloss: 0.195492\tvalid_0's binary_logloss: 0.195492\n",
            "[85]\tvalid_0's binary_logloss: 0.195468\tvalid_0's binary_logloss: 0.195468\n",
            "[86]\tvalid_0's binary_logloss: 0.195433\tvalid_0's binary_logloss: 0.195433\n",
            "[87]\tvalid_0's binary_logloss: 0.195444\tvalid_0's binary_logloss: 0.195444\n",
            "[88]\tvalid_0's binary_logloss: 0.195431\tvalid_0's binary_logloss: 0.195431\n",
            "[89]\tvalid_0's binary_logloss: 0.195369\tvalid_0's binary_logloss: 0.195369\n",
            "[90]\tvalid_0's binary_logloss: 0.195345\tvalid_0's binary_logloss: 0.195345\n",
            "[91]\tvalid_0's binary_logloss: 0.195242\tvalid_0's binary_logloss: 0.195242\n",
            "[92]\tvalid_0's binary_logloss: 0.195206\tvalid_0's binary_logloss: 0.195206\n",
            "[93]\tvalid_0's binary_logloss: 0.195088\tvalid_0's binary_logloss: 0.195088\n",
            "[94]\tvalid_0's binary_logloss: 0.195063\tvalid_0's binary_logloss: 0.195063\n",
            "[95]\tvalid_0's binary_logloss: 0.195061\tvalid_0's binary_logloss: 0.195061\n",
            "[96]\tvalid_0's binary_logloss: 0.195085\tvalid_0's binary_logloss: 0.195085\n",
            "[97]\tvalid_0's binary_logloss: 0.19498\tvalid_0's binary_logloss: 0.19498\n",
            "[98]\tvalid_0's binary_logloss: 0.194962\tvalid_0's binary_logloss: 0.194962\n",
            "[99]\tvalid_0's binary_logloss: 0.194853\tvalid_0's binary_logloss: 0.194853\n",
            "[100]\tvalid_0's binary_logloss: 0.194848\tvalid_0's binary_logloss: 0.194848\n",
            "[101]\tvalid_0's binary_logloss: 0.194798\tvalid_0's binary_logloss: 0.194798\n",
            "[102]\tvalid_0's binary_logloss: 0.194784\tvalid_0's binary_logloss: 0.194784\n",
            "[103]\tvalid_0's binary_logloss: 0.194792\tvalid_0's binary_logloss: 0.194792\n",
            "[104]\tvalid_0's binary_logloss: 0.194785\tvalid_0's binary_logloss: 0.194785\n",
            "[105]\tvalid_0's binary_logloss: 0.194753\tvalid_0's binary_logloss: 0.194753\n",
            "[106]\tvalid_0's binary_logloss: 0.194761\tvalid_0's binary_logloss: 0.194761\n",
            "[107]\tvalid_0's binary_logloss: 0.194779\tvalid_0's binary_logloss: 0.194779\n",
            "[108]\tvalid_0's binary_logloss: 0.194767\tvalid_0's binary_logloss: 0.194767\n",
            "[109]\tvalid_0's binary_logloss: 0.194772\tvalid_0's binary_logloss: 0.194772\n",
            "[110]\tvalid_0's binary_logloss: 0.194747\tvalid_0's binary_logloss: 0.194747\n",
            "[111]\tvalid_0's binary_logloss: 0.194727\tvalid_0's binary_logloss: 0.194727\n",
            "[112]\tvalid_0's binary_logloss: 0.194729\tvalid_0's binary_logloss: 0.194729\n",
            "[113]\tvalid_0's binary_logloss: 0.194691\tvalid_0's binary_logloss: 0.194691\n",
            "[114]\tvalid_0's binary_logloss: 0.194709\tvalid_0's binary_logloss: 0.194709\n",
            "[115]\tvalid_0's binary_logloss: 0.194734\tvalid_0's binary_logloss: 0.194734\n",
            "[116]\tvalid_0's binary_logloss: 0.194725\tvalid_0's binary_logloss: 0.194725\n",
            "[117]\tvalid_0's binary_logloss: 0.194742\tvalid_0's binary_logloss: 0.194742\n",
            "[118]\tvalid_0's binary_logloss: 0.19476\tvalid_0's binary_logloss: 0.19476\n",
            "[119]\tvalid_0's binary_logloss: 0.194746\tvalid_0's binary_logloss: 0.194746\n",
            "[120]\tvalid_0's binary_logloss: 0.194737\tvalid_0's binary_logloss: 0.194737\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[113]\tvalid_0's binary_logloss: 0.194691\tvalid_0's binary_logloss: 0.194691\n",
            "Test dataset:\n",
            "predictions are  [0 0 1 ... 0 0 0]\n",
            "Test ROC AUC score: 0.891712281793886\n",
            "Test accuracy score: 0.92400622954993\n",
            "Confusion matrix is  [[181153   4843]\n",
            " [ 15456  65662]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95    185996\n",
            "           1       0.93      0.81      0.87     81118\n",
            "\n",
            "    accuracy                           0.92    267114\n",
            "   macro avg       0.93      0.89      0.91    267114\n",
            "weighted avg       0.92      0.92      0.92    267114\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation dataset:\n",
            "predictions are  [0 1 1 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8926256565484934\n",
            "Test accuracy score: 0.924347884596694\n",
            "Confusion matrix is  [[362339   9762]\n",
            " [ 30714 132213]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95    372101\n",
            "           1       0.93      0.81      0.87    162927\n",
            "\n",
            "    accuracy                           0.92    535028\n",
            "   macro avg       0.93      0.89      0.91    535028\n",
            "weighted avg       0.92      0.92      0.92    535028\n",
            "\n",
            "\n",
            "\n",
            "[2254 2904 2990 2586 2573 3736 4555    0    0    0    0    0 2711 2686\n",
            "  939  878 1286  867 1966   24    7    3    2    0 3099 2561 2305 1077\n",
            " 3078]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([120.9060843 , 121.32442689, 121.21530437, 123.27080607,\n",
            "       120.76378298]), 'score_time': array([10.43871808, 10.25442433, 10.32744455, 10.35401726, 10.51426005]), 'test_accuracy': array([0.92498937, 0.92419778, 0.92449996, 0.92407144, 0.92477889]), 'test_roc_auc': array([0.89294067, 0.89181751, 0.89213283, 0.89142643, 0.89264656])}\n",
            "cross for accuracy [0.92498937 0.92419778 0.92449996 0.92407144 0.92477889]\n",
            "cross for roc-auc [0.89294067 0.89181751 0.89213283 0.89142643 0.89264656]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQbFihYc_4ki",
        "colab_type": "code",
        "outputId": "496b2e58-4045-4106-e4a6-0b565c8d75e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sel_cols=cols_after_removing_recursive+['temperature','wind_direction']\n",
        "print(sel_cols,Y_train.OUTCOME.mean(),Y_test.OUTCOME.mean())\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(num_iterations=150,lambda_l1=1,bagging_fraction=0.2,feature_fraction=0.8,max_bin=175,min_data_in_leaf=450,num_leaves=400,lambda_l2=2,learning_rate=0.3,max_depth=40)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  sel_X_valid=X_valid[sel_cols]\n",
        "  eval_set = [(sel_X_test, Y_test)]\n",
        "  model.fit(sel_X_train, Y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
        "\n",
        "  print(\"Test dataset:\")\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(\"Validation dataset:\")\n",
        "  pred=model.predict(sel_X_valid)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_valid,pred)\n",
        "\n",
        "  \n",
        "  print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "  #plot graph of feature importances for better visualization\n",
        "  feat_importances = pd.Series(model.feature_importances_, index=sel_cols)\n",
        "  feat_importances.nlargest(26).plot(kind='barh')\n",
        "  plt.show()\n",
        "\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test,sel_X_valid])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test,Y_valid])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'WHEELS_OFF_HOUR', 'AIR_SYSTEM_DELAY_is_missing', 'pressure', 'wind_speed', 'temperature', 'wind_direction'] 0.5 0.3036830716473116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.517083\tvalid_0's binary_logloss: 0.517083\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.412817\tvalid_0's binary_logloss: 0.412817\n",
            "[3]\tvalid_0's binary_logloss: 0.354701\tvalid_0's binary_logloss: 0.354701\n",
            "[4]\tvalid_0's binary_logloss: 0.315326\tvalid_0's binary_logloss: 0.315326\n",
            "[5]\tvalid_0's binary_logloss: 0.285413\tvalid_0's binary_logloss: 0.285413\n",
            "[6]\tvalid_0's binary_logloss: 0.263822\tvalid_0's binary_logloss: 0.263822\n",
            "[7]\tvalid_0's binary_logloss: 0.249798\tvalid_0's binary_logloss: 0.249798\n",
            "[8]\tvalid_0's binary_logloss: 0.240604\tvalid_0's binary_logloss: 0.240604\n",
            "[9]\tvalid_0's binary_logloss: 0.23349\tvalid_0's binary_logloss: 0.23349\n",
            "[10]\tvalid_0's binary_logloss: 0.227026\tvalid_0's binary_logloss: 0.227026\n",
            "[11]\tvalid_0's binary_logloss: 0.224781\tvalid_0's binary_logloss: 0.224781\n",
            "[12]\tvalid_0's binary_logloss: 0.220812\tvalid_0's binary_logloss: 0.220812\n",
            "[13]\tvalid_0's binary_logloss: 0.217676\tvalid_0's binary_logloss: 0.217676\n",
            "[14]\tvalid_0's binary_logloss: 0.215156\tvalid_0's binary_logloss: 0.215156\n",
            "[15]\tvalid_0's binary_logloss: 0.21296\tvalid_0's binary_logloss: 0.21296\n",
            "[16]\tvalid_0's binary_logloss: 0.212062\tvalid_0's binary_logloss: 0.212062\n",
            "[17]\tvalid_0's binary_logloss: 0.210417\tvalid_0's binary_logloss: 0.210417\n",
            "[18]\tvalid_0's binary_logloss: 0.209333\tvalid_0's binary_logloss: 0.209333\n",
            "[19]\tvalid_0's binary_logloss: 0.20822\tvalid_0's binary_logloss: 0.20822\n",
            "[20]\tvalid_0's binary_logloss: 0.207253\tvalid_0's binary_logloss: 0.207253\n",
            "[21]\tvalid_0's binary_logloss: 0.20659\tvalid_0's binary_logloss: 0.20659\n",
            "[22]\tvalid_0's binary_logloss: 0.205399\tvalid_0's binary_logloss: 0.205399\n",
            "[23]\tvalid_0's binary_logloss: 0.204797\tvalid_0's binary_logloss: 0.204797\n",
            "[24]\tvalid_0's binary_logloss: 0.204364\tvalid_0's binary_logloss: 0.204364\n",
            "[25]\tvalid_0's binary_logloss: 0.203817\tvalid_0's binary_logloss: 0.203817\n",
            "[26]\tvalid_0's binary_logloss: 0.203485\tvalid_0's binary_logloss: 0.203485\n",
            "[27]\tvalid_0's binary_logloss: 0.203289\tvalid_0's binary_logloss: 0.203289\n",
            "[28]\tvalid_0's binary_logloss: 0.202977\tvalid_0's binary_logloss: 0.202977\n",
            "[29]\tvalid_0's binary_logloss: 0.202557\tvalid_0's binary_logloss: 0.202557\n",
            "[30]\tvalid_0's binary_logloss: 0.201958\tvalid_0's binary_logloss: 0.201958\n",
            "[31]\tvalid_0's binary_logloss: 0.20167\tvalid_0's binary_logloss: 0.20167\n",
            "[32]\tvalid_0's binary_logloss: 0.201421\tvalid_0's binary_logloss: 0.201421\n",
            "[33]\tvalid_0's binary_logloss: 0.200819\tvalid_0's binary_logloss: 0.200819\n",
            "[34]\tvalid_0's binary_logloss: 0.200657\tvalid_0's binary_logloss: 0.200657\n",
            "[35]\tvalid_0's binary_logloss: 0.200443\tvalid_0's binary_logloss: 0.200443\n",
            "[36]\tvalid_0's binary_logloss: 0.200134\tvalid_0's binary_logloss: 0.200134\n",
            "[37]\tvalid_0's binary_logloss: 0.199922\tvalid_0's binary_logloss: 0.199922\n",
            "[38]\tvalid_0's binary_logloss: 0.199705\tvalid_0's binary_logloss: 0.199705\n",
            "[39]\tvalid_0's binary_logloss: 0.199536\tvalid_0's binary_logloss: 0.199536\n",
            "[40]\tvalid_0's binary_logloss: 0.199388\tvalid_0's binary_logloss: 0.199388\n",
            "[41]\tvalid_0's binary_logloss: 0.199091\tvalid_0's binary_logloss: 0.199091\n",
            "[42]\tvalid_0's binary_logloss: 0.198884\tvalid_0's binary_logloss: 0.198884\n",
            "[43]\tvalid_0's binary_logloss: 0.198678\tvalid_0's binary_logloss: 0.198678\n",
            "[44]\tvalid_0's binary_logloss: 0.198498\tvalid_0's binary_logloss: 0.198498\n",
            "[45]\tvalid_0's binary_logloss: 0.198389\tvalid_0's binary_logloss: 0.198389\n",
            "[46]\tvalid_0's binary_logloss: 0.198174\tvalid_0's binary_logloss: 0.198174\n",
            "[47]\tvalid_0's binary_logloss: 0.19786\tvalid_0's binary_logloss: 0.19786\n",
            "[48]\tvalid_0's binary_logloss: 0.197719\tvalid_0's binary_logloss: 0.197719\n",
            "[49]\tvalid_0's binary_logloss: 0.197568\tvalid_0's binary_logloss: 0.197568\n",
            "[50]\tvalid_0's binary_logloss: 0.197361\tvalid_0's binary_logloss: 0.197361\n",
            "[51]\tvalid_0's binary_logloss: 0.197288\tvalid_0's binary_logloss: 0.197288\n",
            "[52]\tvalid_0's binary_logloss: 0.197214\tvalid_0's binary_logloss: 0.197214\n",
            "[53]\tvalid_0's binary_logloss: 0.197049\tvalid_0's binary_logloss: 0.197049\n",
            "[54]\tvalid_0's binary_logloss: 0.196778\tvalid_0's binary_logloss: 0.196778\n",
            "[55]\tvalid_0's binary_logloss: 0.19674\tvalid_0's binary_logloss: 0.19674\n",
            "[56]\tvalid_0's binary_logloss: 0.196625\tvalid_0's binary_logloss: 0.196625\n",
            "[57]\tvalid_0's binary_logloss: 0.196602\tvalid_0's binary_logloss: 0.196602\n",
            "[58]\tvalid_0's binary_logloss: 0.196597\tvalid_0's binary_logloss: 0.196597\n",
            "[59]\tvalid_0's binary_logloss: 0.196383\tvalid_0's binary_logloss: 0.196383\n",
            "[60]\tvalid_0's binary_logloss: 0.196378\tvalid_0's binary_logloss: 0.196378\n",
            "[61]\tvalid_0's binary_logloss: 0.196352\tvalid_0's binary_logloss: 0.196352\n",
            "[62]\tvalid_0's binary_logloss: 0.196306\tvalid_0's binary_logloss: 0.196306\n",
            "[63]\tvalid_0's binary_logloss: 0.19631\tvalid_0's binary_logloss: 0.19631\n",
            "[64]\tvalid_0's binary_logloss: 0.196191\tvalid_0's binary_logloss: 0.196191\n",
            "[65]\tvalid_0's binary_logloss: 0.196123\tvalid_0's binary_logloss: 0.196123\n",
            "[66]\tvalid_0's binary_logloss: 0.196114\tvalid_0's binary_logloss: 0.196114\n",
            "[67]\tvalid_0's binary_logloss: 0.196078\tvalid_0's binary_logloss: 0.196078\n",
            "[68]\tvalid_0's binary_logloss: 0.196032\tvalid_0's binary_logloss: 0.196032\n",
            "[69]\tvalid_0's binary_logloss: 0.196012\tvalid_0's binary_logloss: 0.196012\n",
            "[70]\tvalid_0's binary_logloss: 0.195869\tvalid_0's binary_logloss: 0.195869\n",
            "[71]\tvalid_0's binary_logloss: 0.195814\tvalid_0's binary_logloss: 0.195814\n",
            "[72]\tvalid_0's binary_logloss: 0.195794\tvalid_0's binary_logloss: 0.195794\n",
            "[73]\tvalid_0's binary_logloss: 0.19578\tvalid_0's binary_logloss: 0.19578\n",
            "[74]\tvalid_0's binary_logloss: 0.195753\tvalid_0's binary_logloss: 0.195753\n",
            "[75]\tvalid_0's binary_logloss: 0.195637\tvalid_0's binary_logloss: 0.195637\n",
            "[76]\tvalid_0's binary_logloss: 0.195579\tvalid_0's binary_logloss: 0.195579\n",
            "[77]\tvalid_0's binary_logloss: 0.195517\tvalid_0's binary_logloss: 0.195517\n",
            "[78]\tvalid_0's binary_logloss: 0.195516\tvalid_0's binary_logloss: 0.195516\n",
            "[79]\tvalid_0's binary_logloss: 0.195482\tvalid_0's binary_logloss: 0.195482\n",
            "[80]\tvalid_0's binary_logloss: 0.195382\tvalid_0's binary_logloss: 0.195382\n",
            "[81]\tvalid_0's binary_logloss: 0.195362\tvalid_0's binary_logloss: 0.195362\n",
            "[82]\tvalid_0's binary_logloss: 0.195351\tvalid_0's binary_logloss: 0.195351\n",
            "[83]\tvalid_0's binary_logloss: 0.195325\tvalid_0's binary_logloss: 0.195325\n",
            "[84]\tvalid_0's binary_logloss: 0.195255\tvalid_0's binary_logloss: 0.195255\n",
            "[85]\tvalid_0's binary_logloss: 0.195215\tvalid_0's binary_logloss: 0.195215\n",
            "[86]\tvalid_0's binary_logloss: 0.195081\tvalid_0's binary_logloss: 0.195081\n",
            "[87]\tvalid_0's binary_logloss: 0.195085\tvalid_0's binary_logloss: 0.195085\n",
            "[88]\tvalid_0's binary_logloss: 0.195006\tvalid_0's binary_logloss: 0.195006\n",
            "[89]\tvalid_0's binary_logloss: 0.194962\tvalid_0's binary_logloss: 0.194962\n",
            "[90]\tvalid_0's binary_logloss: 0.194927\tvalid_0's binary_logloss: 0.194927\n",
            "[91]\tvalid_0's binary_logloss: 0.194908\tvalid_0's binary_logloss: 0.194908\n",
            "[92]\tvalid_0's binary_logloss: 0.19492\tvalid_0's binary_logloss: 0.19492\n",
            "[93]\tvalid_0's binary_logloss: 0.194861\tvalid_0's binary_logloss: 0.194861\n",
            "[94]\tvalid_0's binary_logloss: 0.194882\tvalid_0's binary_logloss: 0.194882\n",
            "[95]\tvalid_0's binary_logloss: 0.194772\tvalid_0's binary_logloss: 0.194772\n",
            "[96]\tvalid_0's binary_logloss: 0.194774\tvalid_0's binary_logloss: 0.194774\n",
            "[97]\tvalid_0's binary_logloss: 0.194791\tvalid_0's binary_logloss: 0.194791\n",
            "[98]\tvalid_0's binary_logloss: 0.19478\tvalid_0's binary_logloss: 0.19478\n",
            "[99]\tvalid_0's binary_logloss: 0.194724\tvalid_0's binary_logloss: 0.194724\n",
            "[100]\tvalid_0's binary_logloss: 0.194678\tvalid_0's binary_logloss: 0.194678\n",
            "[101]\tvalid_0's binary_logloss: 0.194645\tvalid_0's binary_logloss: 0.194645\n",
            "[102]\tvalid_0's binary_logloss: 0.194678\tvalid_0's binary_logloss: 0.194678\n",
            "[103]\tvalid_0's binary_logloss: 0.194613\tvalid_0's binary_logloss: 0.194613\n",
            "[104]\tvalid_0's binary_logloss: 0.194599\tvalid_0's binary_logloss: 0.194599\n",
            "[105]\tvalid_0's binary_logloss: 0.194592\tvalid_0's binary_logloss: 0.194592\n",
            "[106]\tvalid_0's binary_logloss: 0.19454\tvalid_0's binary_logloss: 0.19454\n",
            "[107]\tvalid_0's binary_logloss: 0.194527\tvalid_0's binary_logloss: 0.194527\n",
            "[108]\tvalid_0's binary_logloss: 0.194529\tvalid_0's binary_logloss: 0.194529\n",
            "[109]\tvalid_0's binary_logloss: 0.194501\tvalid_0's binary_logloss: 0.194501\n",
            "[110]\tvalid_0's binary_logloss: 0.194489\tvalid_0's binary_logloss: 0.194489\n",
            "[111]\tvalid_0's binary_logloss: 0.194515\tvalid_0's binary_logloss: 0.194515\n",
            "[112]\tvalid_0's binary_logloss: 0.19452\tvalid_0's binary_logloss: 0.19452\n",
            "[113]\tvalid_0's binary_logloss: 0.194519\tvalid_0's binary_logloss: 0.194519\n",
            "[114]\tvalid_0's binary_logloss: 0.194537\tvalid_0's binary_logloss: 0.194537\n",
            "[115]\tvalid_0's binary_logloss: 0.194486\tvalid_0's binary_logloss: 0.194486\n",
            "[116]\tvalid_0's binary_logloss: 0.194454\tvalid_0's binary_logloss: 0.194454\n",
            "[117]\tvalid_0's binary_logloss: 0.194471\tvalid_0's binary_logloss: 0.194471\n",
            "[118]\tvalid_0's binary_logloss: 0.194432\tvalid_0's binary_logloss: 0.194432\n",
            "[119]\tvalid_0's binary_logloss: 0.194312\tvalid_0's binary_logloss: 0.194312\n",
            "[120]\tvalid_0's binary_logloss: 0.194308\tvalid_0's binary_logloss: 0.194308\n",
            "[121]\tvalid_0's binary_logloss: 0.194325\tvalid_0's binary_logloss: 0.194325\n",
            "[122]\tvalid_0's binary_logloss: 0.194322\tvalid_0's binary_logloss: 0.194322\n",
            "[123]\tvalid_0's binary_logloss: 0.194335\tvalid_0's binary_logloss: 0.194335\n",
            "[124]\tvalid_0's binary_logloss: 0.194282\tvalid_0's binary_logloss: 0.194282\n",
            "[125]\tvalid_0's binary_logloss: 0.194282\tvalid_0's binary_logloss: 0.194282\n",
            "[126]\tvalid_0's binary_logloss: 0.19431\tvalid_0's binary_logloss: 0.19431\n",
            "[127]\tvalid_0's binary_logloss: 0.194266\tvalid_0's binary_logloss: 0.194266\n",
            "[128]\tvalid_0's binary_logloss: 0.194266\tvalid_0's binary_logloss: 0.194266\n",
            "[129]\tvalid_0's binary_logloss: 0.194235\tvalid_0's binary_logloss: 0.194235\n",
            "[130]\tvalid_0's binary_logloss: 0.194232\tvalid_0's binary_logloss: 0.194232\n",
            "[131]\tvalid_0's binary_logloss: 0.194223\tvalid_0's binary_logloss: 0.194223\n",
            "[132]\tvalid_0's binary_logloss: 0.194203\tvalid_0's binary_logloss: 0.194203\n",
            "[133]\tvalid_0's binary_logloss: 0.194249\tvalid_0's binary_logloss: 0.194249\n",
            "[134]\tvalid_0's binary_logloss: 0.194241\tvalid_0's binary_logloss: 0.194241\n",
            "[135]\tvalid_0's binary_logloss: 0.194241\tvalid_0's binary_logloss: 0.194241\n",
            "[136]\tvalid_0's binary_logloss: 0.194231\tvalid_0's binary_logloss: 0.194231\n",
            "[137]\tvalid_0's binary_logloss: 0.194238\tvalid_0's binary_logloss: 0.194238\n",
            "[138]\tvalid_0's binary_logloss: 0.19424\tvalid_0's binary_logloss: 0.19424\n",
            "[139]\tvalid_0's binary_logloss: 0.194254\tvalid_0's binary_logloss: 0.194254\n",
            "[140]\tvalid_0's binary_logloss: 0.194248\tvalid_0's binary_logloss: 0.194248\n",
            "[141]\tvalid_0's binary_logloss: 0.194238\tvalid_0's binary_logloss: 0.194238\n",
            "[142]\tvalid_0's binary_logloss: 0.19421\tvalid_0's binary_logloss: 0.19421\n",
            "Early stopping, best iteration is:\n",
            "[132]\tvalid_0's binary_logloss: 0.194203\tvalid_0's binary_logloss: 0.194203\n",
            "Test dataset:\n",
            "predictions are  [0 0 1 ... 0 0 0]\n",
            "Test ROC AUC score: 0.892086702456591\n",
            "Test accuracy score: 0.9242420839042507\n",
            "Confusion matrix is  [[181157   4839]\n",
            " [ 15397  65721]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95    185996\n",
            "           1       0.93      0.81      0.87     81118\n",
            "\n",
            "    accuracy                           0.92    267114\n",
            "   macro avg       0.93      0.89      0.91    267114\n",
            "weighted avg       0.92      0.92      0.92    267114\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation dataset:\n",
            "predictions are  [0 1 1 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8926164082313147\n",
            "Test accuracy score: 0.9244861951150221\n",
            "Confusion matrix is  [[362476   9625]\n",
            " [ 30777 132150]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95    372101\n",
            "           1       0.93      0.81      0.87    162927\n",
            "\n",
            "    accuracy                           0.92    535028\n",
            "   macro avg       0.93      0.89      0.91    535028\n",
            "weighted avg       0.92      0.92      0.92    535028\n",
            "\n",
            "\n",
            "\n",
            "[3338 3356 4462 3629 3492 4814 5173 3197 3591 3219   35 3424 1602 5029\n",
            " 4307]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([99.33782101, 97.13895464, 99.15243673, 96.56157136, 97.88030076]), 'score_time': array([12.27495646, 12.28809571, 12.42679405, 12.30111551, 12.50325179]), 'test_accuracy': array([0.92516856, 0.92436295, 0.92444854, 0.92423038, 0.92454047]), 'test_roc_auc': array([0.89325858, 0.89236073, 0.89234717, 0.89172545, 0.89256918])}\n",
            "cross for accuracy [0.92516856 0.92436295 0.92444854 0.92423038 0.92454047]\n",
            "cross for roc-auc [0.89325858 0.89236073 0.89234717 0.89172545 0.89256918]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWIAe7t0f_1r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6685311-9fb9-44f1-8434-3a9b879373a7"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sel_cols=cols_after_removing_recursive\n",
        "print(sel_cols,Y_train.OUTCOME.mean(),Y_test.OUTCOME.mean())\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(num_iterations=150,lambda_l1=1,bagging_fraction=0.2,feature_fraction=0.8,max_bin=175,min_data_in_leaf=450,num_leaves=400,lambda_l2=2,learning_rate=0.3,max_depth=40)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  sel_X_valid=X_valid[sel_cols]\n",
        "  eval_set = [(sel_X_test, Y_test)]\n",
        "  model.fit(sel_X_train, Y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
        "\n",
        "  print(\"Test dataset:\")\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(\"Validation dataset:\")\n",
        "  pred=model.predict(sel_X_valid)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_valid,pred)\n",
        "\n",
        "  \n",
        "  print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "  #plot graph of feature importances for better visualization\n",
        "  feat_importances = pd.Series(model.feature_importances_, index=sel_cols)\n",
        "  feat_importances.nlargest(26).plot(kind='barh')\n",
        "  plt.show()\n",
        "\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test,sel_X_valid])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test,Y_valid])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'WHEELS_OFF_HOUR', 'AIR_SYSTEM_DELAY_is_missing', 'pressure', 'wind_speed'] 0.5 0.3036830716473116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.517082\tvalid_0's binary_logloss: 0.517082\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.432698\tvalid_0's binary_logloss: 0.432698\n",
            "[3]\tvalid_0's binary_logloss: 0.365149\tvalid_0's binary_logloss: 0.365149\n",
            "[4]\tvalid_0's binary_logloss: 0.322596\tvalid_0's binary_logloss: 0.322596\n",
            "[5]\tvalid_0's binary_logloss: 0.290029\tvalid_0's binary_logloss: 0.290029\n",
            "[6]\tvalid_0's binary_logloss: 0.267047\tvalid_0's binary_logloss: 0.267047\n",
            "[7]\tvalid_0's binary_logloss: 0.254355\tvalid_0's binary_logloss: 0.254355\n",
            "[8]\tvalid_0's binary_logloss: 0.244174\tvalid_0's binary_logloss: 0.244174\n",
            "[9]\tvalid_0's binary_logloss: 0.23718\tvalid_0's binary_logloss: 0.23718\n",
            "[10]\tvalid_0's binary_logloss: 0.230465\tvalid_0's binary_logloss: 0.230465\n",
            "[11]\tvalid_0's binary_logloss: 0.225989\tvalid_0's binary_logloss: 0.225989\n",
            "[12]\tvalid_0's binary_logloss: 0.222779\tvalid_0's binary_logloss: 0.222779\n",
            "[13]\tvalid_0's binary_logloss: 0.219108\tvalid_0's binary_logloss: 0.219108\n",
            "[14]\tvalid_0's binary_logloss: 0.217559\tvalid_0's binary_logloss: 0.217559\n",
            "[15]\tvalid_0's binary_logloss: 0.21459\tvalid_0's binary_logloss: 0.21459\n",
            "[16]\tvalid_0's binary_logloss: 0.212703\tvalid_0's binary_logloss: 0.212703\n",
            "[17]\tvalid_0's binary_logloss: 0.211268\tvalid_0's binary_logloss: 0.211268\n",
            "[18]\tvalid_0's binary_logloss: 0.209704\tvalid_0's binary_logloss: 0.209704\n",
            "[19]\tvalid_0's binary_logloss: 0.208645\tvalid_0's binary_logloss: 0.208645\n",
            "[20]\tvalid_0's binary_logloss: 0.207645\tvalid_0's binary_logloss: 0.207645\n",
            "[21]\tvalid_0's binary_logloss: 0.206788\tvalid_0's binary_logloss: 0.206788\n",
            "[22]\tvalid_0's binary_logloss: 0.206121\tvalid_0's binary_logloss: 0.206121\n",
            "[23]\tvalid_0's binary_logloss: 0.205069\tvalid_0's binary_logloss: 0.205069\n",
            "[24]\tvalid_0's binary_logloss: 0.204426\tvalid_0's binary_logloss: 0.204426\n",
            "[25]\tvalid_0's binary_logloss: 0.203897\tvalid_0's binary_logloss: 0.203897\n",
            "[26]\tvalid_0's binary_logloss: 0.203588\tvalid_0's binary_logloss: 0.203588\n",
            "[27]\tvalid_0's binary_logloss: 0.203282\tvalid_0's binary_logloss: 0.203282\n",
            "[28]\tvalid_0's binary_logloss: 0.202751\tvalid_0's binary_logloss: 0.202751\n",
            "[29]\tvalid_0's binary_logloss: 0.202454\tvalid_0's binary_logloss: 0.202454\n",
            "[30]\tvalid_0's binary_logloss: 0.20227\tvalid_0's binary_logloss: 0.20227\n",
            "[31]\tvalid_0's binary_logloss: 0.201948\tvalid_0's binary_logloss: 0.201948\n",
            "[32]\tvalid_0's binary_logloss: 0.201733\tvalid_0's binary_logloss: 0.201733\n",
            "[33]\tvalid_0's binary_logloss: 0.201289\tvalid_0's binary_logloss: 0.201289\n",
            "[34]\tvalid_0's binary_logloss: 0.201001\tvalid_0's binary_logloss: 0.201001\n",
            "[35]\tvalid_0's binary_logloss: 0.200656\tvalid_0's binary_logloss: 0.200656\n",
            "[36]\tvalid_0's binary_logloss: 0.200423\tvalid_0's binary_logloss: 0.200423\n",
            "[37]\tvalid_0's binary_logloss: 0.200253\tvalid_0's binary_logloss: 0.200253\n",
            "[38]\tvalid_0's binary_logloss: 0.200038\tvalid_0's binary_logloss: 0.200038\n",
            "[39]\tvalid_0's binary_logloss: 0.199813\tvalid_0's binary_logloss: 0.199813\n",
            "[40]\tvalid_0's binary_logloss: 0.199616\tvalid_0's binary_logloss: 0.199616\n",
            "[41]\tvalid_0's binary_logloss: 0.199466\tvalid_0's binary_logloss: 0.199466\n",
            "[42]\tvalid_0's binary_logloss: 0.199371\tvalid_0's binary_logloss: 0.199371\n",
            "[43]\tvalid_0's binary_logloss: 0.199193\tvalid_0's binary_logloss: 0.199193\n",
            "[44]\tvalid_0's binary_logloss: 0.199027\tvalid_0's binary_logloss: 0.199027\n",
            "[45]\tvalid_0's binary_logloss: 0.198933\tvalid_0's binary_logloss: 0.198933\n",
            "[46]\tvalid_0's binary_logloss: 0.198787\tvalid_0's binary_logloss: 0.198787\n",
            "[47]\tvalid_0's binary_logloss: 0.198589\tvalid_0's binary_logloss: 0.198589\n",
            "[48]\tvalid_0's binary_logloss: 0.198473\tvalid_0's binary_logloss: 0.198473\n",
            "[49]\tvalid_0's binary_logloss: 0.19832\tvalid_0's binary_logloss: 0.19832\n",
            "[50]\tvalid_0's binary_logloss: 0.198076\tvalid_0's binary_logloss: 0.198076\n",
            "[51]\tvalid_0's binary_logloss: 0.197973\tvalid_0's binary_logloss: 0.197973\n",
            "[52]\tvalid_0's binary_logloss: 0.197906\tvalid_0's binary_logloss: 0.197906\n",
            "[53]\tvalid_0's binary_logloss: 0.197794\tvalid_0's binary_logloss: 0.197794\n",
            "[54]\tvalid_0's binary_logloss: 0.197664\tvalid_0's binary_logloss: 0.197664\n",
            "[55]\tvalid_0's binary_logloss: 0.197592\tvalid_0's binary_logloss: 0.197592\n",
            "[56]\tvalid_0's binary_logloss: 0.197529\tvalid_0's binary_logloss: 0.197529\n",
            "[57]\tvalid_0's binary_logloss: 0.197325\tvalid_0's binary_logloss: 0.197325\n",
            "[58]\tvalid_0's binary_logloss: 0.197176\tvalid_0's binary_logloss: 0.197176\n",
            "[59]\tvalid_0's binary_logloss: 0.197111\tvalid_0's binary_logloss: 0.197111\n",
            "[60]\tvalid_0's binary_logloss: 0.19708\tvalid_0's binary_logloss: 0.19708\n",
            "[61]\tvalid_0's binary_logloss: 0.197021\tvalid_0's binary_logloss: 0.197021\n",
            "[62]\tvalid_0's binary_logloss: 0.197002\tvalid_0's binary_logloss: 0.197002\n",
            "[63]\tvalid_0's binary_logloss: 0.196959\tvalid_0's binary_logloss: 0.196959\n",
            "[64]\tvalid_0's binary_logloss: 0.196885\tvalid_0's binary_logloss: 0.196885\n",
            "[65]\tvalid_0's binary_logloss: 0.19688\tvalid_0's binary_logloss: 0.19688\n",
            "[66]\tvalid_0's binary_logloss: 0.196757\tvalid_0's binary_logloss: 0.196757\n",
            "[67]\tvalid_0's binary_logloss: 0.196763\tvalid_0's binary_logloss: 0.196763\n",
            "[68]\tvalid_0's binary_logloss: 0.196779\tvalid_0's binary_logloss: 0.196779\n",
            "[69]\tvalid_0's binary_logloss: 0.196758\tvalid_0's binary_logloss: 0.196758\n",
            "[70]\tvalid_0's binary_logloss: 0.196611\tvalid_0's binary_logloss: 0.196611\n",
            "[71]\tvalid_0's binary_logloss: 0.196573\tvalid_0's binary_logloss: 0.196573\n",
            "[72]\tvalid_0's binary_logloss: 0.196531\tvalid_0's binary_logloss: 0.196531\n",
            "[73]\tvalid_0's binary_logloss: 0.196499\tvalid_0's binary_logloss: 0.196499\n",
            "[74]\tvalid_0's binary_logloss: 0.196514\tvalid_0's binary_logloss: 0.196514\n",
            "[75]\tvalid_0's binary_logloss: 0.196404\tvalid_0's binary_logloss: 0.196404\n",
            "[76]\tvalid_0's binary_logloss: 0.196385\tvalid_0's binary_logloss: 0.196385\n",
            "[77]\tvalid_0's binary_logloss: 0.196338\tvalid_0's binary_logloss: 0.196338\n",
            "[78]\tvalid_0's binary_logloss: 0.196263\tvalid_0's binary_logloss: 0.196263\n",
            "[79]\tvalid_0's binary_logloss: 0.196226\tvalid_0's binary_logloss: 0.196226\n",
            "[80]\tvalid_0's binary_logloss: 0.196096\tvalid_0's binary_logloss: 0.196096\n",
            "[81]\tvalid_0's binary_logloss: 0.196081\tvalid_0's binary_logloss: 0.196081\n",
            "[82]\tvalid_0's binary_logloss: 0.195942\tvalid_0's binary_logloss: 0.195942\n",
            "[83]\tvalid_0's binary_logloss: 0.195942\tvalid_0's binary_logloss: 0.195942\n",
            "[84]\tvalid_0's binary_logloss: 0.195968\tvalid_0's binary_logloss: 0.195968\n",
            "[85]\tvalid_0's binary_logloss: 0.19587\tvalid_0's binary_logloss: 0.19587\n",
            "[86]\tvalid_0's binary_logloss: 0.195876\tvalid_0's binary_logloss: 0.195876\n",
            "[87]\tvalid_0's binary_logloss: 0.195873\tvalid_0's binary_logloss: 0.195873\n",
            "[88]\tvalid_0's binary_logloss: 0.195853\tvalid_0's binary_logloss: 0.195853\n",
            "[89]\tvalid_0's binary_logloss: 0.195745\tvalid_0's binary_logloss: 0.195745\n",
            "[90]\tvalid_0's binary_logloss: 0.195743\tvalid_0's binary_logloss: 0.195743\n",
            "[91]\tvalid_0's binary_logloss: 0.195734\tvalid_0's binary_logloss: 0.195734\n",
            "[92]\tvalid_0's binary_logloss: 0.195662\tvalid_0's binary_logloss: 0.195662\n",
            "[93]\tvalid_0's binary_logloss: 0.195662\tvalid_0's binary_logloss: 0.195662\n",
            "[94]\tvalid_0's binary_logloss: 0.195673\tvalid_0's binary_logloss: 0.195673\n",
            "[95]\tvalid_0's binary_logloss: 0.19568\tvalid_0's binary_logloss: 0.19568\n",
            "[96]\tvalid_0's binary_logloss: 0.195649\tvalid_0's binary_logloss: 0.195649\n",
            "[97]\tvalid_0's binary_logloss: 0.195596\tvalid_0's binary_logloss: 0.195596\n",
            "[98]\tvalid_0's binary_logloss: 0.19556\tvalid_0's binary_logloss: 0.19556\n",
            "[99]\tvalid_0's binary_logloss: 0.195513\tvalid_0's binary_logloss: 0.195513\n",
            "[100]\tvalid_0's binary_logloss: 0.195497\tvalid_0's binary_logloss: 0.195497\n",
            "[101]\tvalid_0's binary_logloss: 0.195472\tvalid_0's binary_logloss: 0.195472\n",
            "[102]\tvalid_0's binary_logloss: 0.195458\tvalid_0's binary_logloss: 0.195458\n",
            "[103]\tvalid_0's binary_logloss: 0.19544\tvalid_0's binary_logloss: 0.19544\n",
            "[104]\tvalid_0's binary_logloss: 0.195456\tvalid_0's binary_logloss: 0.195456\n",
            "[105]\tvalid_0's binary_logloss: 0.195447\tvalid_0's binary_logloss: 0.195447\n",
            "[106]\tvalid_0's binary_logloss: 0.195484\tvalid_0's binary_logloss: 0.195484\n",
            "[107]\tvalid_0's binary_logloss: 0.195498\tvalid_0's binary_logloss: 0.195498\n",
            "[108]\tvalid_0's binary_logloss: 0.195475\tvalid_0's binary_logloss: 0.195475\n",
            "[109]\tvalid_0's binary_logloss: 0.195415\tvalid_0's binary_logloss: 0.195415\n",
            "[110]\tvalid_0's binary_logloss: 0.195412\tvalid_0's binary_logloss: 0.195412\n",
            "[111]\tvalid_0's binary_logloss: 0.195407\tvalid_0's binary_logloss: 0.195407\n",
            "[112]\tvalid_0's binary_logloss: 0.195336\tvalid_0's binary_logloss: 0.195336\n",
            "[113]\tvalid_0's binary_logloss: 0.195335\tvalid_0's binary_logloss: 0.195335\n",
            "[114]\tvalid_0's binary_logloss: 0.195358\tvalid_0's binary_logloss: 0.195358\n",
            "[115]\tvalid_0's binary_logloss: 0.195321\tvalid_0's binary_logloss: 0.195321\n",
            "[116]\tvalid_0's binary_logloss: 0.195329\tvalid_0's binary_logloss: 0.195329\n",
            "[117]\tvalid_0's binary_logloss: 0.195348\tvalid_0's binary_logloss: 0.195348\n",
            "[118]\tvalid_0's binary_logloss: 0.19531\tvalid_0's binary_logloss: 0.19531\n",
            "[119]\tvalid_0's binary_logloss: 0.19532\tvalid_0's binary_logloss: 0.19532\n",
            "[120]\tvalid_0's binary_logloss: 0.195309\tvalid_0's binary_logloss: 0.195309\n",
            "[121]\tvalid_0's binary_logloss: 0.195299\tvalid_0's binary_logloss: 0.195299\n",
            "[122]\tvalid_0's binary_logloss: 0.195288\tvalid_0's binary_logloss: 0.195288\n",
            "[123]\tvalid_0's binary_logloss: 0.195267\tvalid_0's binary_logloss: 0.195267\n",
            "[124]\tvalid_0's binary_logloss: 0.195256\tvalid_0's binary_logloss: 0.195256\n",
            "[125]\tvalid_0's binary_logloss: 0.195267\tvalid_0's binary_logloss: 0.195267\n",
            "[126]\tvalid_0's binary_logloss: 0.195263\tvalid_0's binary_logloss: 0.195263\n",
            "[127]\tvalid_0's binary_logloss: 0.195247\tvalid_0's binary_logloss: 0.195247\n",
            "[128]\tvalid_0's binary_logloss: 0.195229\tvalid_0's binary_logloss: 0.195229\n",
            "[129]\tvalid_0's binary_logloss: 0.19521\tvalid_0's binary_logloss: 0.19521\n",
            "[130]\tvalid_0's binary_logloss: 0.195233\tvalid_0's binary_logloss: 0.195233\n",
            "[131]\tvalid_0's binary_logloss: 0.195207\tvalid_0's binary_logloss: 0.195207\n",
            "[132]\tvalid_0's binary_logloss: 0.195183\tvalid_0's binary_logloss: 0.195183\n",
            "[133]\tvalid_0's binary_logloss: 0.195184\tvalid_0's binary_logloss: 0.195184\n",
            "[134]\tvalid_0's binary_logloss: 0.195162\tvalid_0's binary_logloss: 0.195162\n",
            "[135]\tvalid_0's binary_logloss: 0.195138\tvalid_0's binary_logloss: 0.195138\n",
            "[136]\tvalid_0's binary_logloss: 0.195145\tvalid_0's binary_logloss: 0.195145\n",
            "[137]\tvalid_0's binary_logloss: 0.195168\tvalid_0's binary_logloss: 0.195168\n",
            "[138]\tvalid_0's binary_logloss: 0.195143\tvalid_0's binary_logloss: 0.195143\n",
            "[139]\tvalid_0's binary_logloss: 0.195126\tvalid_0's binary_logloss: 0.195126\n",
            "[140]\tvalid_0's binary_logloss: 0.195152\tvalid_0's binary_logloss: 0.195152\n",
            "[141]\tvalid_0's binary_logloss: 0.195181\tvalid_0's binary_logloss: 0.195181\n",
            "[142]\tvalid_0's binary_logloss: 0.195193\tvalid_0's binary_logloss: 0.195193\n",
            "[143]\tvalid_0's binary_logloss: 0.195182\tvalid_0's binary_logloss: 0.195182\n",
            "[144]\tvalid_0's binary_logloss: 0.195203\tvalid_0's binary_logloss: 0.195203\n",
            "[145]\tvalid_0's binary_logloss: 0.195194\tvalid_0's binary_logloss: 0.195194\n",
            "[146]\tvalid_0's binary_logloss: 0.195175\tvalid_0's binary_logloss: 0.195175\n",
            "[147]\tvalid_0's binary_logloss: 0.195137\tvalid_0's binary_logloss: 0.195137\n",
            "[148]\tvalid_0's binary_logloss: 0.195145\tvalid_0's binary_logloss: 0.195145\n",
            "[149]\tvalid_0's binary_logloss: 0.195162\tvalid_0's binary_logloss: 0.195162\n",
            "Early stopping, best iteration is:\n",
            "[139]\tvalid_0's binary_logloss: 0.195126\tvalid_0's binary_logloss: 0.195126\n",
            "Test dataset:\n",
            "predictions are  [0 0 1 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8915114272991821\n",
            "Test accuracy score: 0.9239201239920034\n",
            "Confusion matrix is  [[181170   4826]\n",
            " [ 15496  65622]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95    185996\n",
            "           1       0.93      0.81      0.87     81118\n",
            "\n",
            "    accuracy                           0.92    267114\n",
            "   macro avg       0.93      0.89      0.91    267114\n",
            "weighted avg       0.92      0.92      0.92    267114\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation dataset:\n",
            "predictions are  [0 1 1 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8923704830385034\n",
            "Test accuracy score: 0.9243048961923488\n",
            "Confusion matrix is  [[362446   9655]\n",
            " [ 30844 132083]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95    372101\n",
            "           1       0.93      0.81      0.87    162927\n",
            "\n",
            "    accuracy                           0.92    535028\n",
            "   macro avg       0.93      0.89      0.91    535028\n",
            "weighted avg       0.92      0.92      0.92    535028\n",
            "\n",
            "\n",
            "\n",
            "[4659 4111 5337 3938 4764 5902 6563 3960 4753 4306   38 4912 2218]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([33.7039752 , 33.44732523, 33.93704224, 33.50874758, 33.58323479]), 'score_time': array([4.13270855, 4.11064172, 4.23528075, 4.15545106, 4.30626774]), 'test_accuracy': array([0.92483666, 0.92399832, 0.92429739, 0.92427401, 0.92461527]), 'test_roc_auc': array([0.89289596, 0.8915717 , 0.89196132, 0.89161671, 0.89247849])}\n",
            "cross for accuracy [0.92483666 0.92399832 0.92429739 0.92427401 0.92461527]\n",
            "cross for roc-auc [0.89289596 0.8915717  0.89196132 0.89161671 0.89247849]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}