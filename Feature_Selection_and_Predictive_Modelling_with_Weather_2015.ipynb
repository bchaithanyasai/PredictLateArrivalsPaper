{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Selection and Predictive Modelling with Weather 2015",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMDXG0pg5ehx+AsUE92cGqR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bchaithanyasai/PredictLateArrivalsPaper/blob/master/Feature_Selection_and_Predictive_Modelling_with_Weather_2015.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zk626ZMKEedL",
        "outputId": "c35f424c-4afe-452c-b46d-f0fcf720a20c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4mJaM6qcFABM",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data=pd.read_csv(\"/content/drive/My Drive/train_data_with_weather_2015.csv\")\n",
        "test_data=pd.read_csv(\"/content/drive/My Drive/test_data_with_weather_2015.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mQQWbYz2gMIN",
        "outputId": "5c1171e7-1520-4855-bf7c-218220629ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_data.OUTCOME.mean(),test_data.OUTCOME.mean())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5 0.3042416430008652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8nFtnzW2ZDo_",
        "outputId": "0c0aa264-684b-4c70-d755-4c493ad90e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "train_data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>SCHEDULED_DEPARTURE</th>\n",
              "      <th>DEPARTURE_TIME</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>SCHEDULED_ARRIVAL</th>\n",
              "      <th>ARRIVAL_TIME</th>\n",
              "      <th>ARRIVAL_DELAY</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>ELAPSED_TIME</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>WHEELS_OFF</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>pressure</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.257109</td>\n",
              "      <td>821.000000</td>\n",
              "      <td>822.000000</td>\n",
              "      <td>0.174887</td>\n",
              "      <td>830.000000</td>\n",
              "      <td>832.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>838.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>290.470333</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>346.000000</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.308900</td>\n",
              "      <td>0.285001</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2358.000000</td>\n",
              "      <td>0.078960</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>741.000000</td>\n",
              "      <td>-27.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>283.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>2296.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>263.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>295.501763</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1023.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>27.00000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>2028.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.297450</td>\n",
              "      <td>907.000000</td>\n",
              "      <td>912.000000</td>\n",
              "      <td>0.275508</td>\n",
              "      <td>1117.000000</td>\n",
              "      <td>1106.000000</td>\n",
              "      <td>-11.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>922.000000</td>\n",
              "      <td>794.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>292.250000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1017.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>343.000000</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>11.0</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.289338</td>\n",
              "      <td>1415.000000</td>\n",
              "      <td>1423.000000</td>\n",
              "      <td>0.376994</td>\n",
              "      <td>1704.000000</td>\n",
              "      <td>1721.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>1450.000000</td>\n",
              "      <td>578.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>279.088667</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1033.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>115.00000</td>\n",
              "      <td>430.000000</td>\n",
              "      <td>1554.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.327223</td>\n",
              "      <td>1620.000000</td>\n",
              "      <td>1617.000000</td>\n",
              "      <td>0.099516</td>\n",
              "      <td>1905.000000</td>\n",
              "      <td>1847.000000</td>\n",
              "      <td>-18.000000</td>\n",
              "      <td>285.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1630.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>251.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>270.075667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1038.000000</td>\n",
              "      <td>239.000000</td>\n",
              "      <td>270.00000</td>\n",
              "      <td>1095.000000</td>\n",
              "      <td>1626.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>16.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>19.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350795</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.506379</td>\n",
              "      <td>22.948966</td>\n",
              "      <td>3.012758</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.277645</td>\n",
              "      <td>1344.974483</td>\n",
              "      <td>1343.987242</td>\n",
              "      <td>0.132491</td>\n",
              "      <td>1439.493621</td>\n",
              "      <td>1448.455346</td>\n",
              "      <td>8.961725</td>\n",
              "      <td>114.519138</td>\n",
              "      <td>124.468104</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1400.987242</td>\n",
              "      <td>591.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>102.961725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>268.289824</td>\n",
              "      <td>66.366037</td>\n",
              "      <td>3.012758</td>\n",
              "      <td>1035.595688</td>\n",
              "      <td>303.748789</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>43.987242</td>\n",
              "      <td>13.0</td>\n",
              "      <td>44.974483</td>\n",
              "      <td>14.0</td>\n",
              "      <td>39.493621</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.987242</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350796</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>6.831457</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.328222</td>\n",
              "      <td>0.315815</td>\n",
              "      <td>25.353123</td>\n",
              "      <td>28.070625</td>\n",
              "      <td>0.243565</td>\n",
              "      <td>819.282498</td>\n",
              "      <td>827.690208</td>\n",
              "      <td>8.407710</td>\n",
              "      <td>293.929375</td>\n",
              "      <td>299.619584</td>\n",
              "      <td>22.619584</td>\n",
              "      <td>50.690208</td>\n",
              "      <td>2342.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>257.646877</td>\n",
              "      <td>1.548959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.407710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>296.870758</td>\n",
              "      <td>54.054587</td>\n",
              "      <td>3.690208</td>\n",
              "      <td>1014.000000</td>\n",
              "      <td>242.423748</td>\n",
              "      <td>13.00000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>1093.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.070625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.353123</td>\n",
              "      <td>8.0</td>\n",
              "      <td>19.282498</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.690208</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350797</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>7.578120</td>\n",
              "      <td>4.375042</td>\n",
              "      <td>5.296866</td>\n",
              "      <td>0.293531</td>\n",
              "      <td>0.262450</td>\n",
              "      <td>1714.218802</td>\n",
              "      <td>2265.718858</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1826.406267</td>\n",
              "      <td>8.968774</td>\n",
              "      <td>342.562507</td>\n",
              "      <td>72.187465</td>\n",
              "      <td>68.874986</td>\n",
              "      <td>13.562507</td>\n",
              "      <td>2313.656295</td>\n",
              "      <td>377.937214</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.171852</td>\n",
              "      <td>0.984387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>341.578120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>304.561649</td>\n",
              "      <td>46.718858</td>\n",
              "      <td>3.281253</td>\n",
              "      <td>1016.125014</td>\n",
              "      <td>334.671685</td>\n",
              "      <td>277.42188</td>\n",
              "      <td>1130.156351</td>\n",
              "      <td>237.656630</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.140627</td>\n",
              "      <td>51.656184</td>\n",
              "      <td>17.0</td>\n",
              "      <td>14.218802</td>\n",
              "      <td>18.0</td>\n",
              "      <td>26.406267</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>13.656295</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350798</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.122429</td>\n",
              "      <td>2.843879</td>\n",
              "      <td>0.324190</td>\n",
              "      <td>0.325316</td>\n",
              "      <td>1938.438785</td>\n",
              "      <td>2120.434672</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2217.658178</td>\n",
              "      <td>2338.185700</td>\n",
              "      <td>80.527522</td>\n",
              "      <td>279.219393</td>\n",
              "      <td>257.751028</td>\n",
              "      <td>8.843879</td>\n",
              "      <td>2129.278551</td>\n",
              "      <td>1843.063271</td>\n",
              "      <td>0.0</td>\n",
              "      <td>242.751028</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.029579</td>\n",
              "      <td>2.497943</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>287.798401</td>\n",
              "      <td>73.751028</td>\n",
              "      <td>1.936729</td>\n",
              "      <td>1030.438785</td>\n",
              "      <td>98.738689</td>\n",
              "      <td>290.00000</td>\n",
              "      <td>1153.590794</td>\n",
              "      <td>1280.434672</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>20.434672</td>\n",
              "      <td>19.0</td>\n",
              "      <td>38.438785</td>\n",
              "      <td>22.0</td>\n",
              "      <td>17.658178</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>29.278551</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350799</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.523548</td>\n",
              "      <td>20.141288</td>\n",
              "      <td>3.382260</td>\n",
              "      <td>0.331816</td>\n",
              "      <td>0.287352</td>\n",
              "      <td>1230.000000</td>\n",
              "      <td>1234.711932</td>\n",
              "      <td>0.291612</td>\n",
              "      <td>1514.717424</td>\n",
              "      <td>1526.811616</td>\n",
              "      <td>12.094192</td>\n",
              "      <td>104.717424</td>\n",
              "      <td>112.099684</td>\n",
              "      <td>18.711932</td>\n",
              "      <td>1274.365783</td>\n",
              "      <td>582.806124</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.864205</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>265.676510</td>\n",
              "      <td>63.083207</td>\n",
              "      <td>2.905808</td>\n",
              "      <td>1045.423864</td>\n",
              "      <td>257.069066</td>\n",
              "      <td>104.00000</td>\n",
              "      <td>424.628725</td>\n",
              "      <td>474.817109</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>34.711932</td>\n",
              "      <td>12.0</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.717424</td>\n",
              "      <td>12.523548</td>\n",
              "      <td>22.010985</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3350800 rows Ã— 60 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR      MONTH  ...  WHEELS_OFF_MINUTE  OUTCOME\n",
              "0        2015.0   5.000000  ...          38.000000        0\n",
              "1        2015.0   8.000000  ...          13.000000        0\n",
              "2        2015.0   9.000000  ...          22.000000        0\n",
              "3        2015.0   4.000000  ...          50.000000        1\n",
              "4        2015.0   1.000000  ...          30.000000        0\n",
              "...         ...        ...  ...                ...      ...\n",
              "3350795  2015.0   1.506379  ...           0.987242        1\n",
              "3350796  2015.0  11.000000  ...          50.690208        1\n",
              "3350797  2015.0   7.578120  ...          13.656295        1\n",
              "3350798  2015.0   5.000000  ...          29.278551        1\n",
              "3350799  2015.0   1.523548  ...          22.010985        1\n",
              "\n",
              "[3350800 rows x 60 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vvUpEEFbZGZ9",
        "outputId": "5b45fda4-079a-45c6-8ec7-1cbea0d0f0ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "test_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>SCHEDULED_DEPARTURE</th>\n",
              "      <th>DEPARTURE_TIME</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>SCHEDULED_ARRIVAL</th>\n",
              "      <th>ARRIVAL_TIME</th>\n",
              "      <th>ARRIVAL_DELAY</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>ELAPSED_TIME</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>WHEELS_OFF</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>pressure</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>converted_DEPARTURE_TIME</th>\n",
              "      <th>converted_SCHEDULED_DEPARTURE</th>\n",
              "      <th>converted_SCHEDULED_ARRIVAL</th>\n",
              "      <th>converted_WHEELS_OFF</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>9</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.327277</td>\n",
              "      <td>1725</td>\n",
              "      <td>1722.0</td>\n",
              "      <td>0.099516</td>\n",
              "      <td>1832</td>\n",
              "      <td>1913.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1751.0</td>\n",
              "      <td>689</td>\n",
              "      <td>0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>295.420000</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>99</td>\n",
              "      <td>440</td>\n",
              "      <td>101</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17:22:00</td>\n",
              "      <td>17:25:00</td>\n",
              "      <td>18:32:00</td>\n",
              "      <td>17:51:00</td>\n",
              "      <td>17</td>\n",
              "      <td>22</td>\n",
              "      <td>17</td>\n",
              "      <td>25</td>\n",
              "      <td>18</td>\n",
              "      <td>32</td>\n",
              "      <td>17</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>0.328222</td>\n",
              "      <td>0.302174</td>\n",
              "      <td>1110</td>\n",
              "      <td>1120.0</td>\n",
              "      <td>0.455724</td>\n",
              "      <td>1222</td>\n",
              "      <td>1237.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1152.0</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>275.140522</td>\n",
              "      <td>57.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1029.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>82</td>\n",
              "      <td>276</td>\n",
              "      <td>1087</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11:20:00</td>\n",
              "      <td>11:10:00</td>\n",
              "      <td>12:22:00</td>\n",
              "      <td>11:52:00</td>\n",
              "      <td>11</td>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>11</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>0.283660</td>\n",
              "      <td>0.277645</td>\n",
              "      <td>1545</td>\n",
              "      <td>1550.0</td>\n",
              "      <td>0.275508</td>\n",
              "      <td>1710</td>\n",
              "      <td>1708.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1600.0</td>\n",
              "      <td>395</td>\n",
              "      <td>0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>291.892000</td>\n",
              "      <td>92.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>277</td>\n",
              "      <td>1144</td>\n",
              "      <td>220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15:50:00</td>\n",
              "      <td>15:45:00</td>\n",
              "      <td>17:10:00</td>\n",
              "      <td>16:00:00</td>\n",
              "      <td>15</td>\n",
              "      <td>50</td>\n",
              "      <td>15</td>\n",
              "      <td>45</td>\n",
              "      <td>17</td>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.268674</td>\n",
              "      <td>1950</td>\n",
              "      <td>1946.0</td>\n",
              "      <td>0.092683</td>\n",
              "      <td>2229</td>\n",
              "      <td>2224.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>279.0</td>\n",
              "      <td>278.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>1739</td>\n",
              "      <td>0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>288.610673</td>\n",
              "      <td>62.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>998.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>228</td>\n",
              "      <td>969</td>\n",
              "      <td>1602</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19:46:00</td>\n",
              "      <td>19:50:00</td>\n",
              "      <td>22:29:00</td>\n",
              "      <td>20:09:00</td>\n",
              "      <td>19</td>\n",
              "      <td>46</td>\n",
              "      <td>19</td>\n",
              "      <td>50</td>\n",
              "      <td>22</td>\n",
              "      <td>29</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.269565</td>\n",
              "      <td>1400</td>\n",
              "      <td>1351.0</td>\n",
              "      <td>0.070576</td>\n",
              "      <td>1546</td>\n",
              "      <td>1550.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>1422.0</td>\n",
              "      <td>534</td>\n",
              "      <td>0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>277.037667</td>\n",
              "      <td>95.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1025.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>99</td>\n",
              "      <td>439</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13:51:00</td>\n",
              "      <td>14:00:00</td>\n",
              "      <td>15:46:00</td>\n",
              "      <td>14:22:00</td>\n",
              "      <td>13</td>\n",
              "      <td>51</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>46</td>\n",
              "      <td>14</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802137</th>\n",
              "      <td>2015</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.336873</td>\n",
              "      <td>931</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.080515</td>\n",
              "      <td>1139</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>945.0</td>\n",
              "      <td>1118</td>\n",
              "      <td>0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>281.810000</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>228</td>\n",
              "      <td>903</td>\n",
              "      <td>1487</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>09:25:00</td>\n",
              "      <td>09:31:00</td>\n",
              "      <td>11:39:00</td>\n",
              "      <td>09:45:00</td>\n",
              "      <td>9</td>\n",
              "      <td>25</td>\n",
              "      <td>9</td>\n",
              "      <td>31</td>\n",
              "      <td>11</td>\n",
              "      <td>39</td>\n",
              "      <td>9</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802138</th>\n",
              "      <td>2015</td>\n",
              "      <td>10</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>0.328222</td>\n",
              "      <td>0.407928</td>\n",
              "      <td>940</td>\n",
              "      <td>931.0</td>\n",
              "      <td>0.070576</td>\n",
              "      <td>1240</td>\n",
              "      <td>1219.0</td>\n",
              "      <td>-21.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>348.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>940.0</td>\n",
              "      <td>2556</td>\n",
              "      <td>0</td>\n",
              "      <td>335.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>283.930000</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1027.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>144</td>\n",
              "      <td>583</td>\n",
              "      <td>1077</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>09:31:00</td>\n",
              "      <td>09:40:00</td>\n",
              "      <td>12:40:00</td>\n",
              "      <td>09:40:00</td>\n",
              "      <td>9</td>\n",
              "      <td>31</td>\n",
              "      <td>9</td>\n",
              "      <td>40</td>\n",
              "      <td>12</td>\n",
              "      <td>40</td>\n",
              "      <td>9</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802139</th>\n",
              "      <td>2015</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.331816</td>\n",
              "      <td>0.341802</td>\n",
              "      <td>1003</td>\n",
              "      <td>1003.0</td>\n",
              "      <td>0.154482</td>\n",
              "      <td>1314</td>\n",
              "      <td>1304.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>775</td>\n",
              "      <td>0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>280.991333</td>\n",
              "      <td>45.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1021.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>216</td>\n",
              "      <td>908</td>\n",
              "      <td>432</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10:03:00</td>\n",
              "      <td>10:03:00</td>\n",
              "      <td>13:14:00</td>\n",
              "      <td>10:17:00</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802140</th>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0.308362</td>\n",
              "      <td>0.279126</td>\n",
              "      <td>2150</td>\n",
              "      <td>2150.0</td>\n",
              "      <td>0.154482</td>\n",
              "      <td>2325</td>\n",
              "      <td>2303.0</td>\n",
              "      <td>-22.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2208.0</td>\n",
              "      <td>301</td>\n",
              "      <td>0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>273.539500</td>\n",
              "      <td>74.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1037.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>55</td>\n",
              "      <td>147</td>\n",
              "      <td>912</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21:50:00</td>\n",
              "      <td>21:50:00</td>\n",
              "      <td>23:25:00</td>\n",
              "      <td>22:08:00</td>\n",
              "      <td>21</td>\n",
              "      <td>50</td>\n",
              "      <td>21</td>\n",
              "      <td>50</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802141</th>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>0.336319</td>\n",
              "      <td>0.354764</td>\n",
              "      <td>850</td>\n",
              "      <td>859.0</td>\n",
              "      <td>0.416406</td>\n",
              "      <td>1310</td>\n",
              "      <td>1302.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>908.0</td>\n",
              "      <td>1428</td>\n",
              "      <td>0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>288.740000</td>\n",
              "      <td>93.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>283</td>\n",
              "      <td>1139</td>\n",
              "      <td>706</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>08:59:00</td>\n",
              "      <td>08:50:00</td>\n",
              "      <td>13:10:00</td>\n",
              "      <td>09:08:00</td>\n",
              "      <td>8</td>\n",
              "      <td>59</td>\n",
              "      <td>8</td>\n",
              "      <td>50</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>802142 rows Ã— 64 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        YEAR  MONTH  DAY  ...  WHEELS_OFF_HOUR  WHEELS_OFF_MINUTE  OUTCOME\n",
              "0       2015      9   28  ...               17                 51        1\n",
              "1       2015     12   17  ...               11                 52        1\n",
              "2       2015      4   19  ...               16                  0        0\n",
              "3       2015     11   18  ...               20                  9        0\n",
              "4       2015      1   24  ...               14                 22        0\n",
              "...      ...    ...  ...  ...              ...                ...      ...\n",
              "802137  2015     10   15  ...                9                 45        0\n",
              "802138  2015     10   24  ...                9                 40        0\n",
              "802139  2015      6    3  ...               10                 17        0\n",
              "802140  2015      3   23  ...               22                  8        0\n",
              "802141  2015     12   24  ...                9                  8        0\n",
              "\n",
              "[802142 rows x 64 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aigROTKhFYB6",
        "colab": {}
      },
      "source": [
        "drop_cols=['SCHEDULED_DEPARTURE','DEPARTURE_TIME']\n",
        "init_cols=['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT',\n",
        "       'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'SCHEDULED_TIME',\n",
        "       'DISTANCE', 'AIR_TIME', 'DIVERTED', 'AIR_SYSTEM_DELAY',\n",
        "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
        "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
        "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
        "       'AA', 'AS', 'B6', 'DL', 'EV', 'F9', 'HA', 'MQ', 'NK', 'OO', 'UA', 'US',\n",
        "       'VX', 'WN', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR',\n",
        "       'SCHEDULED_ARRIVAL_HOUR', 'DEPARTURE_TIME_MINUTE',\n",
        "       'SCHEDULED_DEPARTURE_MINUTE', 'SCHEDULED_ARRIVAL_MINUTE',\n",
        "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
        "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
        "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing','temperature','humidity','wind_speed','wind_direction','pressure']\n",
        "Y_train=pd.DataFrame(train_data['OUTCOME'])\n",
        "X_train=train_data[init_cols]\n",
        "\n",
        "Y_test=pd.DataFrame(test_data['OUTCOME'])\n",
        "X_test=test_data[init_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T6ZfhIrJFoAo",
        "outputId": "e5d00504-89c8-403f-e7ae-d1e914747deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>pressure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.257109</td>\n",
              "      <td>0.174887</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>290.470333</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>346.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.308900</td>\n",
              "      <td>0.285001</td>\n",
              "      <td>0.078960</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>2296.000000</td>\n",
              "      <td>263.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.00000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>2028.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>295.501763</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>1023.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.297450</td>\n",
              "      <td>0.275508</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>794.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>343.000000</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>292.250000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1017.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.289338</td>\n",
              "      <td>0.376994</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>578.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.00000</td>\n",
              "      <td>430.000000</td>\n",
              "      <td>1554.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>279.088667</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>1033.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.327223</td>\n",
              "      <td>0.099516</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>285.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>251.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>270.00000</td>\n",
              "      <td>1095.000000</td>\n",
              "      <td>1626.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>270.075667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>239.000000</td>\n",
              "      <td>1038.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350795</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.506379</td>\n",
              "      <td>22.948966</td>\n",
              "      <td>3.012758</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.277645</td>\n",
              "      <td>0.132491</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>114.519138</td>\n",
              "      <td>591.000000</td>\n",
              "      <td>102.961725</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>43.987242</td>\n",
              "      <td>44.974483</td>\n",
              "      <td>39.493621</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.987242</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>268.289824</td>\n",
              "      <td>66.366037</td>\n",
              "      <td>3.012758</td>\n",
              "      <td>303.748789</td>\n",
              "      <td>1035.595688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350796</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>6.831457</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.328222</td>\n",
              "      <td>0.315815</td>\n",
              "      <td>0.243565</td>\n",
              "      <td>22.619584</td>\n",
              "      <td>293.929375</td>\n",
              "      <td>2342.000000</td>\n",
              "      <td>257.646877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.548959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.407710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.00000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>1093.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>28.070625</td>\n",
              "      <td>25.353123</td>\n",
              "      <td>19.282498</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>0.690208</td>\n",
              "      <td>296.870758</td>\n",
              "      <td>54.054587</td>\n",
              "      <td>3.690208</td>\n",
              "      <td>242.423748</td>\n",
              "      <td>1014.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350797</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>7.578120</td>\n",
              "      <td>4.375042</td>\n",
              "      <td>5.296866</td>\n",
              "      <td>0.293531</td>\n",
              "      <td>0.262450</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.562507</td>\n",
              "      <td>72.187465</td>\n",
              "      <td>377.937214</td>\n",
              "      <td>52.171852</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.984387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>341.578120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>277.42188</td>\n",
              "      <td>1130.156351</td>\n",
              "      <td>237.656630</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.140627</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>51.656184</td>\n",
              "      <td>14.218802</td>\n",
              "      <td>26.406267</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>13.656295</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>304.561649</td>\n",
              "      <td>46.718858</td>\n",
              "      <td>3.281253</td>\n",
              "      <td>334.671685</td>\n",
              "      <td>1016.125014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350798</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.122429</td>\n",
              "      <td>2.843879</td>\n",
              "      <td>0.324190</td>\n",
              "      <td>0.325316</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.843879</td>\n",
              "      <td>279.219393</td>\n",
              "      <td>1843.063271</td>\n",
              "      <td>242.751028</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.029579</td>\n",
              "      <td>2.497943</td>\n",
              "      <td>0.0</td>\n",
              "      <td>290.00000</td>\n",
              "      <td>1153.590794</td>\n",
              "      <td>1280.434672</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>19.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>20.434672</td>\n",
              "      <td>38.438785</td>\n",
              "      <td>17.658178</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>29.278551</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>287.798401</td>\n",
              "      <td>73.751028</td>\n",
              "      <td>1.936729</td>\n",
              "      <td>98.738689</td>\n",
              "      <td>1030.438785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350799</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.523548</td>\n",
              "      <td>20.141288</td>\n",
              "      <td>3.382260</td>\n",
              "      <td>0.331816</td>\n",
              "      <td>0.287352</td>\n",
              "      <td>0.291612</td>\n",
              "      <td>18.711932</td>\n",
              "      <td>104.717424</td>\n",
              "      <td>582.806124</td>\n",
              "      <td>87.864205</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>104.00000</td>\n",
              "      <td>424.628725</td>\n",
              "      <td>474.817109</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>34.711932</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>14.717424</td>\n",
              "      <td>12.523548</td>\n",
              "      <td>22.010985</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>265.676510</td>\n",
              "      <td>63.083207</td>\n",
              "      <td>2.905808</td>\n",
              "      <td>257.069066</td>\n",
              "      <td>1045.423864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3350800 rows Ã— 52 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR      MONTH        DAY  ...  wind_speed  wind_direction     pressure\n",
              "0        2015.0   5.000000  22.000000  ...    3.000000      346.000000  1032.000000\n",
              "1        2015.0   8.000000  29.000000  ...    4.000000      275.000000  1023.000000\n",
              "2        2015.0   9.000000  22.000000  ...    3.000000       30.000000  1017.000000\n",
              "3        2015.0   4.000000  16.000000  ...    3.000000       58.000000  1033.000000\n",
              "4        2015.0   1.000000  31.000000  ...    4.000000      239.000000  1038.000000\n",
              "...         ...        ...        ...  ...         ...             ...          ...\n",
              "3350795  2015.0   1.506379  22.948966  ...    3.012758      303.748789  1035.595688\n",
              "3350796  2015.0  11.000000   6.831457  ...    3.690208      242.423748  1014.000000\n",
              "3350797  2015.0   7.578120   4.375042  ...    3.281253      334.671685  1016.125014\n",
              "3350798  2015.0   5.000000   9.122429  ...    1.936729       98.738689  1030.438785\n",
              "3350799  2015.0   1.523548  20.141288  ...    2.905808      257.069066  1045.423864\n",
              "\n",
              "[3350800 rows x 52 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RIeo9LwFZl6W",
        "outputId": "1b0fe095-7165-49a0-edb5-4fbcd4b76c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_train[:2406600]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>pressure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.257109</td>\n",
              "      <td>0.174887</td>\n",
              "      <td>16.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>351.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>290.470333</td>\n",
              "      <td>65.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>346.0</td>\n",
              "      <td>1032.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.308900</td>\n",
              "      <td>0.285001</td>\n",
              "      <td>0.078960</td>\n",
              "      <td>15.0</td>\n",
              "      <td>303.0</td>\n",
              "      <td>2296.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2028.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>295.501763</td>\n",
              "      <td>66.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>275.0</td>\n",
              "      <td>1023.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.297450</td>\n",
              "      <td>0.275508</td>\n",
              "      <td>10.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>794.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>343.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>292.250000</td>\n",
              "      <td>88.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1017.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.289338</td>\n",
              "      <td>0.376994</td>\n",
              "      <td>27.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>578.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>430.0</td>\n",
              "      <td>1554.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>279.088667</td>\n",
              "      <td>86.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>1033.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.327223</td>\n",
              "      <td>0.099516</td>\n",
              "      <td>13.0</td>\n",
              "      <td>285.0</td>\n",
              "      <td>1846.0</td>\n",
              "      <td>251.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>1095.0</td>\n",
              "      <td>1626.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>270.075667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>1038.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406595</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.297972</td>\n",
              "      <td>0.347496</td>\n",
              "      <td>0.128038</td>\n",
              "      <td>12.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>954.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>1978.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>282.650000</td>\n",
              "      <td>62.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1016.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406596</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.267691</td>\n",
              "      <td>0.327277</td>\n",
              "      <td>0.109931</td>\n",
              "      <td>21.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>1075.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>941.0</td>\n",
              "      <td>616.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>277.259667</td>\n",
              "      <td>76.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>1034.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406597</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.308900</td>\n",
              "      <td>0.298923</td>\n",
              "      <td>0.084287</td>\n",
              "      <td>22.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>837.0</td>\n",
              "      <td>2059.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>289.166667</td>\n",
              "      <td>79.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1034.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406598</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.308362</td>\n",
              "      <td>0.332620</td>\n",
              "      <td>0.072696</td>\n",
              "      <td>16.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>1069.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>278.351000</td>\n",
              "      <td>97.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>1015.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406599</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.329166</td>\n",
              "      <td>0.315249</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>517.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>359.0</td>\n",
              "      <td>734.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>296.945667</td>\n",
              "      <td>99.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>1024.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2406600 rows Ã— 52 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR  MONTH   DAY  ...  wind_speed  wind_direction  pressure\n",
              "0        2015.0    5.0  22.0  ...         3.0           346.0    1032.0\n",
              "1        2015.0    8.0  29.0  ...         4.0           275.0    1023.0\n",
              "2        2015.0    9.0  22.0  ...         3.0            30.0    1017.0\n",
              "3        2015.0    4.0  16.0  ...         3.0            58.0    1033.0\n",
              "4        2015.0    1.0  31.0  ...         4.0           239.0    1038.0\n",
              "...         ...    ...   ...  ...         ...             ...       ...\n",
              "2406595  2015.0   10.0   4.0  ...         5.0            40.0    1016.0\n",
              "2406596  2015.0    4.0   6.0  ...         4.0           111.0    1034.0\n",
              "2406597  2015.0    1.0  24.0  ...         2.0            50.0    1034.0\n",
              "2406598  2015.0    3.0  11.0  ...         2.0           241.0    1015.0\n",
              "2406599  2015.0    6.0  15.0  ...         5.0            57.0    1024.0\n",
              "\n",
              "[2406600 rows x 52 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XDNQRu46FrIu",
        "outputId": "b8340a8b-ea1a-42f9-b5ed-cb4e390b8370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "Y_train"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350795</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350796</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350797</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350798</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350799</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3350800 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         OUTCOME\n",
              "0              0\n",
              "1              0\n",
              "2              0\n",
              "3              1\n",
              "4              0\n",
              "...          ...\n",
              "3350795        1\n",
              "3350796        1\n",
              "3350797        1\n",
              "3350798        1\n",
              "3350799        1\n",
              "\n",
              "[3350800 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B5vXc6IeFrS4",
        "outputId": "39bdabaf-f8db-43a8-b176-ac78b74439ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_test"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>pressure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>9</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.327277</td>\n",
              "      <td>0.099516</td>\n",
              "      <td>29.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>689</td>\n",
              "      <td>136.0</td>\n",
              "      <td>0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99</td>\n",
              "      <td>440</td>\n",
              "      <td>101</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>25</td>\n",
              "      <td>32</td>\n",
              "      <td>17</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>295.420000</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1017.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>0.328222</td>\n",
              "      <td>0.302174</td>\n",
              "      <td>0.455724</td>\n",
              "      <td>32.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>236</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82</td>\n",
              "      <td>276</td>\n",
              "      <td>1087</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>22</td>\n",
              "      <td>11</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>275.140522</td>\n",
              "      <td>57.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1029.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>0.283660</td>\n",
              "      <td>0.277645</td>\n",
              "      <td>0.275508</td>\n",
              "      <td>10.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>395</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>277</td>\n",
              "      <td>1144</td>\n",
              "      <td>220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>50</td>\n",
              "      <td>45</td>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>291.892000</td>\n",
              "      <td>92.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>1019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.268674</td>\n",
              "      <td>0.092683</td>\n",
              "      <td>23.0</td>\n",
              "      <td>279.0</td>\n",
              "      <td>1739</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228</td>\n",
              "      <td>969</td>\n",
              "      <td>1602</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>22</td>\n",
              "      <td>46</td>\n",
              "      <td>50</td>\n",
              "      <td>29</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>288.610673</td>\n",
              "      <td>62.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>998.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>0.254655</td>\n",
              "      <td>0.269565</td>\n",
              "      <td>0.070576</td>\n",
              "      <td>31.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>534</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99</td>\n",
              "      <td>439</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>14</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>277.037667</td>\n",
              "      <td>95.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>1025.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802137</th>\n",
              "      <td>2015</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.336873</td>\n",
              "      <td>0.080515</td>\n",
              "      <td>20.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>1118</td>\n",
              "      <td>158.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228</td>\n",
              "      <td>903</td>\n",
              "      <td>1487</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>25</td>\n",
              "      <td>31</td>\n",
              "      <td>39</td>\n",
              "      <td>9</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>281.810000</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>1016.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802138</th>\n",
              "      <td>2015</td>\n",
              "      <td>10</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>0.328222</td>\n",
              "      <td>0.407928</td>\n",
              "      <td>0.070576</td>\n",
              "      <td>9.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>2556</td>\n",
              "      <td>335.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>144</td>\n",
              "      <td>583</td>\n",
              "      <td>1077</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>9</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>283.930000</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1027.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802139</th>\n",
              "      <td>2015</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.331816</td>\n",
              "      <td>0.341802</td>\n",
              "      <td>0.154482</td>\n",
              "      <td>14.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>775</td>\n",
              "      <td>101.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216</td>\n",
              "      <td>908</td>\n",
              "      <td>432</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>280.991333</td>\n",
              "      <td>45.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1021.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802140</th>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0.308362</td>\n",
              "      <td>0.279126</td>\n",
              "      <td>0.154482</td>\n",
              "      <td>18.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>301</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55</td>\n",
              "      <td>147</td>\n",
              "      <td>912</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>25</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>273.539500</td>\n",
              "      <td>74.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>1037.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802141</th>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>0.336319</td>\n",
              "      <td>0.354764</td>\n",
              "      <td>0.416406</td>\n",
              "      <td>9.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>1428</td>\n",
              "      <td>169.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>283</td>\n",
              "      <td>1139</td>\n",
              "      <td>706</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>59</td>\n",
              "      <td>50</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>288.740000</td>\n",
              "      <td>93.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>1007.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>802142 rows Ã— 52 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        YEAR  MONTH  DAY  ...  wind_speed  wind_direction  pressure\n",
              "0       2015      9   28  ...         1.0            50.0    1017.0\n",
              "1       2015     12   17  ...         1.0            27.0    1029.0\n",
              "2       2015      4   19  ...         3.0           180.0    1019.0\n",
              "3       2015     11   18  ...        10.0           204.0     998.0\n",
              "4       2015      1   24  ...         5.0           306.0    1025.0\n",
              "...      ...    ...  ...  ...         ...             ...       ...\n",
              "802137  2015     10   15  ...         3.0           240.0    1016.0\n",
              "802138  2015     10   24  ...         0.0            21.0    1027.0\n",
              "802139  2015      6    3  ...         2.0           262.0    1021.0\n",
              "802140  2015      3   23  ...         2.0           322.0    1037.0\n",
              "802141  2015     12   24  ...         1.0           180.0    1007.0\n",
              "\n",
              "[802142 rows x 52 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KrZdDvSZFrcm",
        "outputId": "498222c5-4902-4351-b7c0-b3b25af11f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802137</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802138</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802139</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802140</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802141</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>802142 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        OUTCOME\n",
              "0             1\n",
              "1             1\n",
              "2             0\n",
              "3             0\n",
              "4             0\n",
              "...         ...\n",
              "802137        0\n",
              "802138        0\n",
              "802139        0\n",
              "802140        0\n",
              "802141        0\n",
              "\n",
              "[802142 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FO3YyADUn0UN",
        "colab": {}
      },
      "source": [
        "####Unused as it would be used for regression problems\n",
        "from sklearn.feature_selection import SelectPercentile, f_regression                      \n",
        "Selector_f = SelectPercentile(f_regression, percentile=25)\n",
        "Selector_f.fit(X,y)\n",
        "for n,s in zip(Unhandled_data.feature_names,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s \" % (s,n))\n",
        "Selector_f.get_support(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SpVyYrOyGYoH",
        "outputId": "7d364f04-0dc5-4e6f-9b8c-6c53c27d7e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "X_train.columns"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT',\n",
              "       'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'SCHEDULED_TIME',\n",
              "       'DISTANCE', 'AIR_TIME', 'DIVERTED', 'AIR_SYSTEM_DELAY',\n",
              "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
              "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
              "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
              "       'AA', 'AS', 'B6', 'DL', 'EV', 'F9', 'HA', 'MQ', 'NK', 'OO', 'UA', 'US',\n",
              "       'VX', 'WN', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR',\n",
              "       'SCHEDULED_ARRIVAL_HOUR', 'DEPARTURE_TIME_MINUTE',\n",
              "       'SCHEDULED_DEPARTURE_MINUTE', 'SCHEDULED_ARRIVAL_MINUTE',\n",
              "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
              "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
              "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing',\n",
              "       'temperature', 'humidity', 'wind_speed', 'wind_direction', 'pressure'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ubU8RqqzAvk",
        "colab_type": "code",
        "outputId": "cf538723-59a8-40f8-a6cc-0e886e34b819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=25)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 11172.31t for feature MONTH\n",
            "F-score: 412.38t for feature DAY\n",
            "F-score: 925.27t for feature DAY_OF_WEEK\n",
            "F-score: 19959.62t for feature ORIGIN_AIRPORT\n",
            "F-score: 16025.41t for feature DESTINATION_AIRPORT\n",
            "F-score: 2883925.81t for feature DEPARTURE_DELAY\n",
            "F-score: 264740.81t for feature TAXI_OUT\n",
            "F-score: 33.57t for feature SCHEDULED_TIME\n",
            "F-score: 20.21t for feature DISTANCE\n",
            "F-score: 2815.93t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 248117.44t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 1616.56t for feature SECURITY_DELAY\n",
            "F-score: 191010.50t for feature AIRLINE_DELAY\n",
            "F-score: 285923.89t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 21812.68t for feature WEATHER_DELAY\n",
            "F-score: 8267.40t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 8874.31t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 533.54t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 341.90t for feature AA\n",
            "F-score: 1586.34t for feature AS\n",
            "F-score: 596.83t for feature B6\n",
            "F-score: 19972.64t for feature DL\n",
            "F-score: 77.72t for feature EV\n",
            "F-score: 2411.50t for feature F9\n",
            "F-score: 474.76t for feature HA\n",
            "F-score: 1.31t for feature MQ\n",
            "F-score: 7479.44t for feature NK\n",
            "F-score: 1198.12t for feature OO\n",
            "F-score: 255.37t for feature UA\n",
            "F-score: 296.68t for feature US\n",
            "F-score: 192.40t for feature VX\n",
            "F-score: 1874.12t for feature WN\n",
            "F-score: 99191.76t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 63770.78t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 43615.31t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 3711.86t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 699.64t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 1.43t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 98112.89t for feature WHEELS_OFF_HOUR\n",
            "F-score: 3036.30t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 3185073.83t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature WEATHER_DELAY_is_missing\n",
            "F-score: 643.03t for feature temperature\n",
            "F-score: 74.19t for feature humidity\n",
            "F-score: 16365.36t for feature wind_speed\n",
            "F-score: 453.96t for feature wind_direction\n",
            "F-score: 191.50t for feature pressure\n",
            "Index(['DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'WHEELS_OFF_HOUR',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
            "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
            "       'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DMVewQKgHfpC",
        "outputId": "00c52f48-e322-4642-a721-daf0a2e35a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=50)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 11172.31t for feature MONTH\n",
            "F-score: 412.38t for feature DAY\n",
            "F-score: 925.27t for feature DAY_OF_WEEK\n",
            "F-score: 19959.62t for feature ORIGIN_AIRPORT\n",
            "F-score: 16025.41t for feature DESTINATION_AIRPORT\n",
            "F-score: 2883925.81t for feature DEPARTURE_DELAY\n",
            "F-score: 264740.81t for feature TAXI_OUT\n",
            "F-score: 33.57t for feature SCHEDULED_TIME\n",
            "F-score: 20.21t for feature DISTANCE\n",
            "F-score: 2815.93t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 248117.44t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 1616.56t for feature SECURITY_DELAY\n",
            "F-score: 191010.50t for feature AIRLINE_DELAY\n",
            "F-score: 285923.89t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 21812.68t for feature WEATHER_DELAY\n",
            "F-score: 8267.40t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 8874.31t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 533.54t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 341.90t for feature AA\n",
            "F-score: 1586.34t for feature AS\n",
            "F-score: 596.83t for feature B6\n",
            "F-score: 19972.64t for feature DL\n",
            "F-score: 77.72t for feature EV\n",
            "F-score: 2411.50t for feature F9\n",
            "F-score: 474.76t for feature HA\n",
            "F-score: 1.31t for feature MQ\n",
            "F-score: 7479.44t for feature NK\n",
            "F-score: 1198.12t for feature OO\n",
            "F-score: 255.37t for feature UA\n",
            "F-score: 296.68t for feature US\n",
            "F-score: 192.40t for feature VX\n",
            "F-score: 1874.12t for feature WN\n",
            "F-score: 99191.76t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 63770.78t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 43615.31t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 3711.86t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 699.64t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 1.43t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 98112.89t for feature WHEELS_OFF_HOUR\n",
            "F-score: 3036.30t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 3185073.83t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature WEATHER_DELAY_is_missing\n",
            "F-score: 643.03t for feature temperature\n",
            "F-score: 74.19t for feature humidity\n",
            "F-score: 16365.36t for feature wind_speed\n",
            "F-score: 453.96t for feature wind_direction\n",
            "F-score: 191.50t for feature pressure\n",
            "Index(['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
            "       'TAXI_OUT', 'AIR_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'DL', 'NK', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR',\n",
            "       'DEPARTURE_TIME_MINUTE', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
            "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
            "       'WEATHER_DELAY_is_missing', 'wind_speed'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TyOUNz2dgJAq",
        "outputId": "494e58b1-f4f0-4f9b-9caf-848126a8876c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=75)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 11172.31t for feature MONTH\n",
            "F-score: 412.38t for feature DAY\n",
            "F-score: 925.27t for feature DAY_OF_WEEK\n",
            "F-score: 19959.62t for feature ORIGIN_AIRPORT\n",
            "F-score: 16025.41t for feature DESTINATION_AIRPORT\n",
            "F-score: 2883925.81t for feature DEPARTURE_DELAY\n",
            "F-score: 264740.81t for feature TAXI_OUT\n",
            "F-score: 33.57t for feature SCHEDULED_TIME\n",
            "F-score: 20.21t for feature DISTANCE\n",
            "F-score: 2815.93t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 248117.44t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 1616.56t for feature SECURITY_DELAY\n",
            "F-score: 191010.50t for feature AIRLINE_DELAY\n",
            "F-score: 285923.89t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 21812.68t for feature WEATHER_DELAY\n",
            "F-score: 8267.40t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 8874.31t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 533.54t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 341.90t for feature AA\n",
            "F-score: 1586.34t for feature AS\n",
            "F-score: 596.83t for feature B6\n",
            "F-score: 19972.64t for feature DL\n",
            "F-score: 77.72t for feature EV\n",
            "F-score: 2411.50t for feature F9\n",
            "F-score: 474.76t for feature HA\n",
            "F-score: 1.31t for feature MQ\n",
            "F-score: 7479.44t for feature NK\n",
            "F-score: 1198.12t for feature OO\n",
            "F-score: 255.37t for feature UA\n",
            "F-score: 296.68t for feature US\n",
            "F-score: 192.40t for feature VX\n",
            "F-score: 1874.12t for feature WN\n",
            "F-score: 99191.76t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 63770.78t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 43615.31t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 3711.86t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 699.64t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 1.43t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 98112.89t for feature WHEELS_OFF_HOUR\n",
            "F-score: 3036.30t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 3185073.83t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 3185073.83t for feature WEATHER_DELAY_is_missing\n",
            "F-score: 643.03t for feature temperature\n",
            "F-score: 74.19t for feature humidity\n",
            "F-score: 16365.36t for feature wind_speed\n",
            "F-score: 453.96t for feature wind_direction\n",
            "F-score: 191.50t for feature pressure\n",
            "Index(['MONTH', 'DAY', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
            "       'AS', 'B6', 'DL', 'F9', 'HA', 'NK', 'OO', 'WN', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR',\n",
            "       'DEPARTURE_TIME_MINUTE', 'SCHEDULED_DEPARTURE_MINUTE',\n",
            "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
            "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing',\n",
            "       'temperature', 'wind_speed', 'wind_direction'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H3DVM-Qtu-Fo",
        "outputId": "132a48cc-1487-4067-f92c-e1f56bc006d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=25)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 18491.77t for feature MONTH \n",
            "F-score: 1842.31t for feature DAY \n",
            "F-score: 842.75t for feature DAY_OF_WEEK \n",
            "F-score: 65.10t for feature ORIGIN_AIRPORT \n",
            "F-score: 42.02t for feature DESTINATION_AIRPORT \n",
            "F-score: 511058.32t for feature DEPARTURE_DELAY \n",
            "F-score: 1384872.97t for feature TAXI_OUT \n",
            "F-score: 1361.31t for feature SCHEDULED_TIME \n",
            "F-score: 9074.91t for feature DISTANCE \n",
            "F-score: 132363.42t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 13101204.35t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 75910.10t for feature SECURITY_DELAY \n",
            "F-score: 19648072.50t for feature AIRLINE_DELAY \n",
            "F-score: 23331639.14t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 2747154.72t for feature WEATHER_DELAY \n",
            "F-score: 500380.35t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 2374411.18t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 198660.70t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 298.42t for feature AA \n",
            "F-score: 1532.33t for feature AS \n",
            "F-score: 569.50t for feature B6 \n",
            "F-score: 16421.09t for feature DL \n",
            "F-score: 71.66t for feature EV \n",
            "F-score: 2350.49t for feature F9 \n",
            "F-score: 473.39t for feature HA \n",
            "F-score: 1.27t for feature MQ \n",
            "F-score: 7249.78t for feature NK \n",
            "F-score: 1083.69t for feature OO \n",
            "F-score: 226.97t for feature UA \n",
            "F-score: 281.72t for feature US \n",
            "F-score: 186.88t for feature VX \n",
            "F-score: 1461.13t for feature WN \n",
            "F-score: 178632.38t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 107465.63t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 76724.22t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 37323.69t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 8353.07t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 14.77t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 176288.53t for feature WHEELS_OFF_HOUR \n",
            "F-score: 29034.75t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 486202.29t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 486202.29t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 486202.29t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 486202.29t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 486202.29t for feature WEATHER_DELAY_is_missing \n",
            "F-score: 255.44t for feature temperature \n",
            "F-score: 476.78t for feature humidity \n",
            "F-score: 20602.03t for feature wind_speed \n",
            "F-score: 23504.41t for feature wind_direction \n",
            "F-score: 20.25t for feature pressure \n",
            "Index(['DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
            "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iZMAvNE7E9NS",
        "outputId": "3bc1eaca-d243-490f-b6b1-51dee97ad5f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=50)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 18491.77t for feature MONTH \n",
            "F-score: 1842.31t for feature DAY \n",
            "F-score: 842.75t for feature DAY_OF_WEEK \n",
            "F-score: 65.10t for feature ORIGIN_AIRPORT \n",
            "F-score: 42.02t for feature DESTINATION_AIRPORT \n",
            "F-score: 511058.32t for feature DEPARTURE_DELAY \n",
            "F-score: 1384872.97t for feature TAXI_OUT \n",
            "F-score: 1361.31t for feature SCHEDULED_TIME \n",
            "F-score: 9074.91t for feature DISTANCE \n",
            "F-score: 132363.42t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 13101204.35t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 75910.10t for feature SECURITY_DELAY \n",
            "F-score: 19648072.50t for feature AIRLINE_DELAY \n",
            "F-score: 23331639.14t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 2747154.72t for feature WEATHER_DELAY \n",
            "F-score: 500380.35t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 2374411.18t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 198660.70t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 298.42t for feature AA \n",
            "F-score: 1532.33t for feature AS \n",
            "F-score: 569.50t for feature B6 \n",
            "F-score: 16421.09t for feature DL \n",
            "F-score: 71.66t for feature EV \n",
            "F-score: 2350.49t for feature F9 \n",
            "F-score: 473.39t for feature HA \n",
            "F-score: 1.27t for feature MQ \n",
            "F-score: 7249.78t for feature NK \n",
            "F-score: 1083.69t for feature OO \n",
            "F-score: 226.97t for feature UA \n",
            "F-score: 281.72t for feature US \n",
            "F-score: 186.88t for feature VX \n",
            "F-score: 1461.13t for feature WN \n",
            "F-score: 178632.38t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 107465.63t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 76724.22t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 37323.69t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 8353.07t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 14.77t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 176288.53t for feature WHEELS_OFF_HOUR \n",
            "F-score: 29034.75t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 486202.29t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 486202.29t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 486202.29t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 486202.29t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 486202.29t for feature WEATHER_DELAY_is_missing \n",
            "F-score: 255.44t for feature temperature \n",
            "F-score: 476.78t for feature humidity \n",
            "F-score: 20602.03t for feature wind_speed \n",
            "F-score: 23504.41t for feature wind_direction \n",
            "F-score: 20.25t for feature pressure \n",
            "Index(['MONTH', 'DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
            "       'DL', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR',\n",
            "       'SCHEDULED_ARRIVAL_HOUR', 'DEPARTURE_TIME_MINUTE', 'WHEELS_OFF_HOUR',\n",
            "       'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
            "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing',\n",
            "       'wind_speed', 'wind_direction'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5E3V06WmE_4l",
        "outputId": "a4890da0-7733-487d-c0a9-d957d36e3ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=75)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 18491.77t for feature MONTH \n",
            "F-score: 1842.31t for feature DAY \n",
            "F-score: 842.75t for feature DAY_OF_WEEK \n",
            "F-score: 65.10t for feature ORIGIN_AIRPORT \n",
            "F-score: 42.02t for feature DESTINATION_AIRPORT \n",
            "F-score: 511058.32t for feature DEPARTURE_DELAY \n",
            "F-score: 1384872.97t for feature TAXI_OUT \n",
            "F-score: 1361.31t for feature SCHEDULED_TIME \n",
            "F-score: 9074.91t for feature DISTANCE \n",
            "F-score: 132363.42t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 13101204.35t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 75910.10t for feature SECURITY_DELAY \n",
            "F-score: 19648072.50t for feature AIRLINE_DELAY \n",
            "F-score: 23331639.14t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 2747154.72t for feature WEATHER_DELAY \n",
            "F-score: 500380.35t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 2374411.18t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 198660.70t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 298.42t for feature AA \n",
            "F-score: 1532.33t for feature AS \n",
            "F-score: 569.50t for feature B6 \n",
            "F-score: 16421.09t for feature DL \n",
            "F-score: 71.66t for feature EV \n",
            "F-score: 2350.49t for feature F9 \n",
            "F-score: 473.39t for feature HA \n",
            "F-score: 1.27t for feature MQ \n",
            "F-score: 7249.78t for feature NK \n",
            "F-score: 1083.69t for feature OO \n",
            "F-score: 226.97t for feature UA \n",
            "F-score: 281.72t for feature US \n",
            "F-score: 186.88t for feature VX \n",
            "F-score: 1461.13t for feature WN \n",
            "F-score: 178632.38t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 107465.63t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 76724.22t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 37323.69t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 8353.07t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 14.77t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 176288.53t for feature WHEELS_OFF_HOUR \n",
            "F-score: 29034.75t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 486202.29t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 486202.29t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 486202.29t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 486202.29t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 486202.29t for feature WEATHER_DELAY_is_missing \n",
            "F-score: 255.44t for feature temperature \n",
            "F-score: 476.78t for feature humidity \n",
            "F-score: 20602.03t for feature wind_speed \n",
            "F-score: 23504.41t for feature wind_direction \n",
            "F-score: 20.25t for feature pressure \n",
            "Index(['MONTH', 'DAY', 'DAY_OF_WEEK', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'SCHEDULED_TIME', 'DISTANCE', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
            "       'AS', 'B6', 'DL', 'F9', 'HA', 'NK', 'OO', 'WN', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR',\n",
            "       'DEPARTURE_TIME_MINUTE', 'SCHEDULED_DEPARTURE_MINUTE',\n",
            "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
            "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing',\n",
            "       'humidity', 'wind_speed', 'wind_direction'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nnPzt_pvDJs6",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "val_df, test_df = train_test_split(test_data, test_size=0.333, random_state=0)\n",
        "\n",
        "#Y_train=pd.DataFrame(train_data['OUTCOME'])\n",
        "#X_train=train_data.drop(\"OUTCOME\",axis=1)\n",
        "\n",
        "Y_test=pd.DataFrame(test_df['OUTCOME'])\n",
        "X_test=test_df.drop(\"OUTCOME\",axis=1)\n",
        "\n",
        "Y_valid=pd.DataFrame(val_df['OUTCOME'])\n",
        "X_valid=val_df.drop(\"OUTCOME\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s_vLx-nobFzs",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer,accuracy_score,roc_auc_score\n",
        "from sklearn import metrics\n",
        "\n",
        "def cross_validation(model,X,y):\n",
        "  scores = cross_validate(model, X, y, scoring={'accuracy':make_scorer(accuracy_score),'roc_auc':make_scorer(roc_auc_score)},cv=5)\n",
        "  print(\"Cross-validated scores:\", scores)\n",
        "  print(\"cross for accuracy\",scores['test_accuracy'])\n",
        "  print(\"cross for roc-auc\",scores['test_roc_auc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZIBZy8h6bUmh",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "def report(Y_test,pred):\n",
        "  score1=metrics.roc_auc_score(Y_test,pred)\n",
        "  score2=metrics.accuracy_score(Y_test,pred)\n",
        "\n",
        "  print(f\"Test ROC AUC score: {score1}\")\n",
        "  print(f\"Test accuracy score: {score2}\")\n",
        "  print(\"Confusion matrix is \",metrics.confusion_matrix(Y_test,pred))\n",
        "  print(\"Classification report is \\n\",metrics.classification_report(Y_test,pred))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "REAFrlKudcHT",
        "colab": {}
      },
      "source": [
        "from math import log\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def calculate_aic(n, mse, num_params):\n",
        "\taic = n * log(mse) + 2 * num_params\n",
        "\treturn aic\n",
        "\n",
        "def calculate_bic(n, mse, num_params):\n",
        "\tbic = n * log(mse) + num_params * log(n)\n",
        "\treturn bic\n",
        "  \n",
        "def aic_and_bic(Y_test,pred,num_params):\n",
        "  mse=mean_squared_error(Y_test,pred)\n",
        "  print(pred)\n",
        "  print('Number of parameters: %d' % (num_params))\n",
        "  aic=calculate_aic(len(Y_train), mse, num_params)\n",
        "  print('AIC: %.3f' % aic)\n",
        "  bic = calculate_bic(len(y), mse, num_params)\n",
        "  print('BIC: %.3f' % bic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0jLcuAH-cSKo",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.svm import *\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iePhsaLZ50Im",
        "colab_type": "code",
        "outputId": "bca29ac3-bb67-4b0d-a434-f586100bead3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "cols=['MONTH','ORIGIN_AIRPORT','DESTINATION_AIRPORT','DEPARTURE_DELAY','TAXI_OUT','DISTANCE','SCHEDULED_TIME',\n",
        "'AIR_SYSTEM_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY','SECURITY_DELAY','AIRLINE_ORIGIN_AIRPORT','AIRLINE_DESTINATION_AIRPORT',\n",
        "'DEPARTURE_TIME_HOUR','SCHEDULED_DEPARTURE_HOUR','SCHEDULED_ARRIVAL_HOUR','WHEELS_OFF_HOUR','WHEELS_OFF_MINUTE',\n",
        "'AIR_SYSTEM_DELAY_is_missing','SECURITY_DELAY_is_missing','AIRLINE_DELAY_is_missing','LATE_AIRCRAFT_DELAY_is_missing','WEATHER_DELAY_is_missing',\n",
        "'temperature','humidity','pressure','wind_speed','wind_direction']\n",
        "print(cols)\n",
        "print(len(cols))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n",
            "29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Qio4-8g6aQJ",
        "outputId": "f75726d7-537c-4978-85e5-0cd50676c61b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "selected_X_train=X_train[cols]\n",
        "print(selected_X_train)\n",
        "\n",
        "lgbmclassifier=LGBMClassifier()\n",
        "selector = RFECV(estimator=lgbmclassifier, cv=5,scoring='accuracy',n_jobs=1)\n",
        "selector.fit(selected_X_train,Y_train)\n",
        "print(\"Optimal number of features: %d\" % selector.n_features_)\n",
        "print(selected_X_train.columns[selector.support_])\n",
        "print(selector.ranking_)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             MONTH  ORIGIN_AIRPORT  ...  wind_speed  wind_direction\n",
            "0         5.000000        0.254655  ...    3.000000      346.000000\n",
            "1         8.000000        0.308900  ...    4.000000      275.000000\n",
            "2         9.000000        0.254655  ...    3.000000       30.000000\n",
            "3         4.000000        0.336164  ...    3.000000       58.000000\n",
            "4         1.000000        0.336164  ...    4.000000      239.000000\n",
            "...            ...             ...  ...         ...             ...\n",
            "3350795   1.506379        0.254655  ...    3.012758      303.748789\n",
            "3350796  11.000000        0.328222  ...    3.690208      242.423748\n",
            "3350797   7.578120        0.293531  ...    3.281253      334.671685\n",
            "3350798   5.000000        0.324190  ...    1.936729       98.738689\n",
            "3350799   1.523548        0.331816  ...    2.905808      257.069066\n",
            "\n",
            "[3350800 rows x 29 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimal number of features: 13\n",
            "Index(['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
            "       'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'WHEELS_OFF_HOUR',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'pressure', 'wind_speed'],\n",
            "      dtype='object')\n",
            "[ 1  1  1  1  1  1  1 10 16 12  9  8  1  1  7  6  3  1 11  1 13 14 15 17\n",
            "  5  2  1  1  4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "raZFbf_bIrHa",
        "outputId": "e8844b78-4d6d-4a3e-c1fc-b2e92a8077ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "selected_X_train=X_train[cols]\n",
        "print(selected_X_train)\n",
        "\n",
        "model = LGBMClassifier()\n",
        "model.fit(selected_X_train,Y_train)\n",
        "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "#plot graph of feature importances for better visualization\n",
        "feat_importances = pd.Series(model.feature_importances_, index=selected_X_train.columns)\n",
        "feat_importances.nlargest(24).plot(kind='barh')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             MONTH  ORIGIN_AIRPORT  ...  wind_speed  wind_direction\n",
            "0         5.000000        0.254655  ...    3.000000      346.000000\n",
            "1         8.000000        0.308900  ...    4.000000      275.000000\n",
            "2         9.000000        0.254655  ...    3.000000       30.000000\n",
            "3         4.000000        0.336164  ...    3.000000       58.000000\n",
            "4         1.000000        0.336164  ...    4.000000      239.000000\n",
            "...            ...             ...  ...         ...             ...\n",
            "3350795   1.506379        0.254655  ...    3.012758      303.748789\n",
            "3350796  11.000000        0.328222  ...    3.690208      242.423748\n",
            "3350797   7.578120        0.293531  ...    3.281253      334.671685\n",
            "3350798   5.000000        0.324190  ...    1.936729       98.738689\n",
            "3350799   1.523548        0.331816  ...    2.905808      257.069066\n",
            "\n",
            "[3350800 rows x 29 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[180 184  48 668 669 347 396   0   0   0   0   0 173  60   4   5  13  16\n",
            "   0  81   0   0   0   0  11  17  25  93  10]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEoNAdnTL873",
        "colab_type": "code",
        "outputId": "b685b61e-750a-44f3-a986-0b310f2bdffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cols_after_removing_recursive=['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
        "       'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT',\n",
        "       'AIRLINE_DESTINATION_AIRPORT', 'WHEELS_OFF_HOUR',\n",
        "       'AIR_SYSTEM_DELAY_is_missing', 'pressure', 'wind_speed']\n",
        "print(len(cols_after_removing_recursive))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5pi4gQReHbqt",
        "outputId": "64750816-5e89-4463-fcef-8c950687bd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpBernoulliNBModel():\n",
        "  model = BernoulliNB()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpBernoulliNBModel()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 1 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8190005941527178\n",
            "Test accuracy score: 0.8898648867656849\n",
            "Confusion matrix is  [[558097      0]\n",
            " [ 88344 155701]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.93    558097\n",
            "           1       1.00      0.64      0.78    244045\n",
            "\n",
            "    accuracy                           0.89    802142\n",
            "   macro avg       0.93      0.82      0.85    802142\n",
            "weighted avg       0.90      0.89      0.88    802142\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([1.99183226, 1.68242741, 1.68979955, 1.68275881, 1.64707398]), 'score_time': array([0.52345419, 0.51428699, 0.50859761, 0.50866985, 0.51663709]), 'test_accuracy': array([0.89028888, 0.8898479 , 0.88969502, 0.88931169, 0.89015003]), 'test_roc_auc': array([0.81951458, 0.81878912, 0.81853791, 0.8179073 , 0.81928644])}\n",
            "cross for accuracy [0.89028888 0.8898479  0.88969502 0.88931169 0.89015003]\n",
            "cross for roc-auc [0.81951458 0.81878912 0.81853791 0.8179073  0.81928644]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y5T6_ef4OO_u",
        "outputId": "1e734af0-f100-43ff-b089-f9f076028c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpLinearSVCModel():\n",
        "  model = LinearSVC(random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpLinearSVCModel()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 1 1 ... 0 0 1]\n",
            "Test ROC AUC score: 0.8532021829072994\n",
            "Test accuracy score: 0.8392765869384723\n",
            "Confusion matrix is  [[456319 101778]\n",
            " [ 27145 216900]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.82      0.88    558097\n",
            "           1       0.68      0.89      0.77    244045\n",
            "\n",
            "    accuracy                           0.84    802142\n",
            "   macro avg       0.81      0.85      0.82    802142\n",
            "weighted avg       0.86      0.84      0.84    802142\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([1105.7853179 , 1066.17519736, 1083.73204374, 1068.52170157,\n",
            "       1077.35190964]), 'score_time': array([0.31255555, 0.29819727, 0.30377221, 0.30368543, 0.35512972]), 'test_accuracy': array([0.91505869, 0.90330643, 0.88857932, 0.90523227, 0.90484427]), 'test_roc_auc': array([0.87770274, 0.85350383, 0.81671113, 0.84768683, 0.86107398])}\n",
            "cross for accuracy [0.91505869 0.90330643 0.88857932 0.90523227 0.90484427]\n",
            "cross for roc-auc [0.87770274 0.85350383 0.81671113 0.84768683 0.86107398]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Pfvps8ZPgE2",
        "outputId": "523cb0b3-4f8d-4001-a6c1-6637662dd12d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpLGBMClassifierModel():\n",
        "  model = LGBMClassifier(random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpLGBMClassifierModel()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 1 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8845391049674239\n",
            "Test accuracy score: 0.918338648269259\n",
            "Confusion matrix is  [[541839  16258]\n",
            " [ 49246 194799]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94    558097\n",
            "           1       0.92      0.80      0.86    244045\n",
            "\n",
            "    accuracy                           0.92    802142\n",
            "   macro avg       0.92      0.88      0.90    802142\n",
            "weighted avg       0.92      0.92      0.92    802142\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([25.09105492, 24.77594137, 25.12956619, 24.88204813, 25.06817675]), 'score_time': array([1.9161911 , 1.8842752 , 1.99704766, 1.91676688, 1.96233606]), 'test_accuracy': array([0.92016817, 0.91927841, 0.91990314, 0.91903676, 0.92039866]), 'test_roc_auc': array([0.88350887, 0.88232963, 0.88296908, 0.88171276, 0.88378426])}\n",
            "cross for accuracy [0.92016817 0.91927841 0.91990314 0.91903676 0.92039866]\n",
            "cross for roc-auc [0.88350887 0.88232963 0.88296908 0.88171276 0.88378426]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W-dq1z4DYbE7",
        "outputId": "11d2bfb0-c2a1-43c7-a630-abe1be0c8e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpDecisionTreeModel():\n",
        "  tree = DecisionTreeClassifier(random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  tree.fit(sel_X_train, Y_train)\n",
        "  pred=tree.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(tree,X,y)\n",
        "\n",
        "runexpDecisionTreeModel()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n",
            "predictions are  [1 1 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.851275491724302\n",
            "Test accuracy score: 0.870556584744347\n",
            "Confusion matrix is  [[502579  55518]\n",
            " [ 48314 195731]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.90      0.91    558097\n",
            "           1       0.78      0.80      0.79    244045\n",
            "\n",
            "    accuracy                           0.87    802142\n",
            "   macro avg       0.85      0.85      0.85    802142\n",
            "weighted avg       0.87      0.87      0.87    802142\n",
            "\n",
            "\n",
            "\n",
            "Cross-validated scores: {'fit_time': array([70.23361468, 70.37452698, 71.01513004, 72.16629291, 71.06960392]), 'score_time': array([0.56062889, 0.53719044, 0.54364467, 0.56111956, 0.54596472]), 'test_accuracy': array([0.87345676, 0.87294098, 0.87355161, 0.87298285, 0.87349552]), 'test_roc_auc': array([0.85450118, 0.85370611, 0.85423576, 0.85327987, 0.85442797])}\n",
            "cross for accuracy [0.87345676 0.87294098 0.87355161 0.87298285 0.87349552]\n",
            "cross for roc-auc [0.85450118 0.85370611 0.85423576 0.85327987 0.85442797]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1T8qD_h5S9mU",
        "outputId": "b5ea8b09-dbb3-4642-e28c-916dcba669d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpRandomForestModel():\n",
        "  forest = RandomForestClassifier(max_features=16,max_depth=25,min_samples_leaf=10,random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  forest.fit(sel_X_train, Y_train)\n",
        "  pred=forest.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)                                         #91.87\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(forest,X,y)\n",
        "\n",
        "runexpRandomForestModel()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 1 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.884233096460892\n",
            "Test accuracy score: 0.9185032076614864\n",
            "Confusion matrix is  [[542339  15758]\n",
            " [ 49614 194431]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94    558097\n",
            "           1       0.93      0.80      0.86    244045\n",
            "\n",
            "    accuracy                           0.92    802142\n",
            "   macro avg       0.92      0.88      0.90    802142\n",
            "weighted avg       0.92      0.92      0.92    802142\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([3403.81328917, 3719.38586807, 3639.58003139, 3608.16589308,\n",
            "       3486.36436272]), 'score_time': array([21.14107108, 21.52273655, 21.34525776, 21.43328524, 21.51010394]), 'test_accuracy': array([0.92085223, 0.92012453, 0.92050151, 0.91981588, 0.92069784]), 'test_roc_auc': array([0.88378508, 0.88273813, 0.88327615, 0.88206591, 0.88371901])}\n",
            "cross for accuracy [0.92085223 0.92012453 0.92050151 0.91981588 0.92069784]\n",
            "cross for roc-auc [0.88378508 0.88273813 0.88327615 0.88206591 0.88371901]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "guOphXVvu15j",
        "outputId": "b6095b5e-7499-4bab-c256-0fa748a3c3ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLogisticRegressionModel():\n",
        "  lrmodel=LogisticRegression()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  lrmodel.fit(sel_X_train, Y_train)\n",
        "  pred=lrmodel.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(lrmodel,X,y)\n",
        "  num_params = len(lrmodel.coef_) + 1\n",
        "  aic_and_bic(Y_test,pred,num_params)\n",
        "\n",
        "runLogisticRegressionModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [0 1 0 ... 0 0 1]\n",
            "Test ROC AUC score: 0.8296774206409845\n",
            "Test accuracy score: 0.8885107080764145\n",
            "Confusion matrix is  [[326571   9234]\n",
            " [ 43798  96066]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92    335805\n",
            "           1       0.91      0.69      0.78    139864\n",
            "\n",
            "    accuracy                           0.89    475669\n",
            "   macro avg       0.90      0.83      0.85    475669\n",
            "weighted avg       0.89      0.89      0.88    475669\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([67.50734687, 65.93810582, 66.96874094, 66.1269958 , 65.12360954]), 'score_time': array([0.41015744, 0.42351747, 0.41843605, 0.40717268, 0.41280127]), 'test_accuracy': array([0.8936544 , 0.89500911, 0.89364285, 0.89404716, 0.8939663 ]), 'test_roc_auc': array([0.82146836, 0.82712552, 0.82564117, 0.82180698, 0.82085378])}\n",
            "cross for accuracy [0.8936544  0.89500911 0.89364285 0.89404716 0.8939663 ]\n",
            "cross for roc-auc [0.82146836 0.82712552 0.82564117 0.82180698 0.82085378]\n",
            "[0 1 0 ... 0 0 1]\n",
            "Number of parameters: 2\n",
            "AIC: -13283217.569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c89c4cf15e04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0maic_and_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrunLogisticRegressionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-c89c4cf15e04>\u001b[0m in \u001b[0;36mrunLogisticRegressionModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mnum_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0maic_and_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mrunLogisticRegressionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-15c7f88bee80>\u001b[0m in \u001b[0;36maic_and_bic\u001b[0;34m(Y_test, pred, num_params)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0maic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalculate_aic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AIC: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mbic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BIC: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBxc3eE0YXL8",
        "colab_type": "code",
        "outputId": "d218e3c2-23c8-4191-ebb4-8aa7d7f8ee2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runXGBClassifierModel():\n",
        "  model=XGBClassifier()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runXGBClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[12:14:03] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8799539221752859\n",
            "Test accuracy score: 0.9069905175944303\n",
            "Confusion matrix is  [[953982  55036]\n",
            " [ 77822 341595]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93   1009018\n",
            "           1       0.86      0.81      0.84    419417\n",
            "\n",
            "    accuracy                           0.91   1428435\n",
            "   macro avg       0.89      0.88      0.89   1428435\n",
            "weighted avg       0.91      0.91      0.91   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[13:00:04] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[13:33:07] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[14:06:18] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[14:39:28] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[15:12:40] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
            "Cross-validated scores: {'fit_time': array([1982.48600912, 1986.70746088, 1986.53589177, 1987.457937  ,\n",
            "       1982.43312955]), 'score_time': array([3.77771521, 3.85807991, 3.84304357, 3.85526156, 3.86914086]), 'test_accuracy': array([0.91359997, 0.91408205, 0.91418706, 0.91419406, 0.91461583]), 'test_roc_auc': array([0.8665095 , 0.86698104, 0.86721075, 0.86698055, 0.86812215])}\n",
            "cross for accuracy [0.91359997 0.91408205 0.91418706 0.91419406 0.91461583]\n",
            "cross for roc-auc [0.8665095  0.86698104 0.86721075 0.86698055 0.86812215]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VEX6VSX0SbJT",
        "outputId": "fc44a228-a295-424f-e7d2-8c09c057b98f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(max_bin=175,num_leaves=150,lambda_l1=2,lambda_l2=2,max_depth=100)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8864658355968845\n",
            "Test accuracy score: 0.9229394407165884\n",
            "Confusion matrix is  [[983622  25396]\n",
            " [ 84680 334737]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95   1009018\n",
            "           1       0.93      0.80      0.86    419417\n",
            "\n",
            "    accuracy                           0.92   1428435\n",
            "   macro avg       0.93      0.89      0.90   1428435\n",
            "weighted avg       0.92      0.92      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([60.28556156, 58.70853829, 59.37966013, 59.14075065, 58.98669577]), 'score_time': array([4.36771607, 4.28731585, 4.35411382, 4.39645362, 4.26688361]), 'test_accuracy': array([0.92274514, 0.92301722, 0.92293759, 0.92366826, 0.92380564]), 'test_roc_auc': array([0.8837847 , 0.88449522, 0.88409949, 0.8850948 , 0.88547858])}\n",
            "cross for accuracy [0.92274514 0.92301722 0.92293759 0.92366826 0.92380564]\n",
            "cross for roc-auc [0.8837847  0.88449522 0.88409949 0.8850948  0.88547858]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E9wkWA2b1USV",
        "outputId": "18a12aee-b2d9-4987-abc5-25604d1a0aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(max_bin=150,num_leaves=150,lambda_l1=5,lambda_l2=5,max_depth=90,bagging_fraction=0.8)#decrease bagging_fraction\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8863051495392817\n",
            "Test accuracy score: 0.9228610332286733\n",
            "Confusion matrix is  [[983661  25357]\n",
            " [ 84831 334586]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95   1009018\n",
            "           1       0.93      0.80      0.86    419417\n",
            "\n",
            "    accuracy                           0.92   1428435\n",
            "   macro avg       0.93      0.89      0.90   1428435\n",
            "weighted avg       0.92      0.92      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([59.39565849, 59.75253558, 58.57243896, 58.77869701, 60.90981364]), 'score_time': array([4.42929626, 4.32503486, 4.49348521, 4.35506034, 4.42180252]), 'test_accuracy': array([0.92274339, 0.92305047, 0.92290084, 0.923509  , 0.92384327]), 'test_roc_auc': array([0.88380785, 0.88453791, 0.88411963, 0.88505175, 0.88558011])}\n",
            "cross for accuracy [0.92274339 0.92305047 0.92290084 0.923509   0.92384327]\n",
            "cross for roc-auc [0.88380785 0.88453791 0.88411963 0.88505175 0.88558011]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OQQEenwR-EHf",
        "outputId": "3b88bfe8-75a1-4684-83bf-7406926d3a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(learning_rate=0.2,max_bin=150,num_leaves=250,min_data_in_leaf=300,lambda_l1=4,lambda_l2=4,max_depth=80,bagging_fraction=0.7)#decrease bagging_fraction\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8896156328262435\n",
            "Test accuracy score: 0.9252370601392433\n",
            "Confusion matrix is  [[984717  24301]\n",
            " [ 82493 336924]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95   1009018\n",
            "           1       0.93      0.80      0.86    419417\n",
            "\n",
            "    accuracy                           0.93   1428435\n",
            "   macro avg       0.93      0.89      0.91   1428435\n",
            "weighted avg       0.93      0.93      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([67.17893696, 66.94291735, 65.40629935, 65.40760207, 64.98969841]), 'score_time': array([5.00798702, 5.02646971, 5.04435062, 5.04537511, 4.97464848]), 'test_accuracy': array([0.92467201, 0.92484083, 0.92466494, 0.92539649, 0.92560387]), 'test_roc_auc': array([0.88757584, 0.88820022, 0.88781038, 0.88874621, 0.88905413])}\n",
            "cross for accuracy [0.92467201 0.92484083 0.92466494 0.92539649 0.92560387]\n",
            "cross for roc-auc [0.88757584 0.88820022 0.88781038 0.88874621 0.88905413]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ixe9qVM6_pj5",
        "outputId": "b46eb36d-7db1-411c-a57e-0868a0f73355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'max_bin':(125,150),#               #'learning_rate':(0.2,0.3),\n",
        "     'feature_fraction':(0.6,0.7),\n",
        "     'num_leaves':(250,300),#\n",
        "     'min_data_in_leaf':(300,400),\n",
        "     'lambda_l1':(1,2),#--6                    #'lambda_l2':(2,4,6),     #'max_depth':(60,80,90),\n",
        "     'bagging_fraction':(0.4,0.5)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=3,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  6.0min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed:  9.1min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 17.3min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 18.5min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 19.9min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 20.7min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 21.4min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 22.5min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 24.2min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 24.3min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 25.4min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 26.6min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 27.2min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 28.5min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 29.4min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 30.6min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 32.5min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 33.0min\n",
            "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed: 34.2min\n",
            "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed: 35.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed: 36.3min\n",
            "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed: 37.0min\n",
            "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed: 38.4min\n",
            "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed: 38.7min\n",
            "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed: 40.1min\n",
            "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed: 42.0min\n",
            "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed: 42.1min\n",
            "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed: 42.3min\n",
            "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 44.9min\n",
            "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed: 45.2min\n",
            "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed: 45.3min\n",
            "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed: 47.7min\n",
            "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed: 48.5min\n",
            "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed: 48.7min\n",
            "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed: 50.5min\n",
            "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed: 51.4min\n",
            "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed: 52.0min\n",
            "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed: 53.5min\n",
            "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed: 54.7min\n",
            "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed: 54.9min\n",
            "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed: 56.2min\n",
            "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed: 57.5min\n",
            "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed: 58.1min\n",
            "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed: 59.7min\n",
            "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed: 60.4min\n",
            "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed: 61.0min\n",
            "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed: 62.6min\n",
            "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed: 63.2min\n",
            "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed: 64.2min\n",
            "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed: 65.8min\n",
            "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed: 66.5min\n",
            "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed: 67.0min\n",
            "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed: 68.6min\n",
            "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed: 69.3min\n",
            "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed: 70.0min\n",
            "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed: 71.9min\n",
            "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed: 72.5min\n",
            "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed: 73.1min\n",
            "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed: 74.3min\n",
            "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed: 75.8min\n",
            "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed: 76.3min\n",
            "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed: 77.3min\n",
            "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed: 78.9min\n",
            "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed: 79.2min\n",
            "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed: 80.2min\n",
            "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed: 82.1min\n",
            "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed: 82.4min\n",
            "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed: 83.2min\n",
            "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed: 85.2min\n",
            "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed: 85.7min\n",
            "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed: 85.9min\n",
            "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed: 88.0min\n",
            "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed: 88.7min\n",
            "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed: 89.3min\n",
            "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed: 91.3min\n",
            "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed: 92.3min\n",
            "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed: 94.2min\n",
            "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed: 94.7min\n",
            "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed: 95.5min\n",
            "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed: 97.3min\n",
            "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed: 97.6min\n",
            "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed: 98.3min\n",
            "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed: 100.2min\n",
            "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed: 100.3min\n",
            "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed: 101.7min\n",
            "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed: 103.1min\n",
            "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed: 103.3min\n",
            "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed: 104.6min\n",
            "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed: 106.1min\n",
            "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed: 106.2min\n",
            "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed: 107.7min\n",
            "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed: 108.7min\n",
            "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed: 109.5min\n",
            "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed: 110.6min\n",
            "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed: 111.6min\n",
            "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed: 112.4min\n",
            "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed: 114.1min\n",
            "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed: 114.8min\n",
            "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed: 114.9min\n",
            "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed: 116.9min\n",
            "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed: 117.6min\n",
            "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed: 117.9min\n",
            "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed: 120.0min\n",
            "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed: 120.7min\n",
            "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed: 120.9min\n",
            "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed: 122.5min\n",
            "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed: 123.8min\n",
            "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed: 123.9min\n",
            "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed: 125.4min\n",
            "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed: 126.7min\n",
            "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed: 127.1min\n",
            "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed: 127.9min\n",
            "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed: 129.5min\n",
            "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed: 130.1min\n",
            "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed: 131.0min\n",
            "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed: 132.7min\n",
            "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed: 132.8min\n",
            "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed: 133.5min\n",
            "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed: 135.6min\n",
            "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed: 136.0min\n",
            "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed: 136.8min\n",
            "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed: 139.2min\n",
            "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed: 141.7min\n",
            "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed: 142.0min\n",
            "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed: 142.2min\n",
            "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed: 145.3min\n",
            "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed: 147.5min\n",
            "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed: 148.2min\n",
            "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed: 148.8min\n",
            "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed: 150.8min\n",
            "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed: 151.2min\n",
            "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed: 151.6min\n",
            "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed: 153.7min\n",
            "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed: 154.1min\n",
            "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed: 155.1min\n",
            "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 156.8min\n",
            "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed: 156.9min\n",
            "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed: 158.3min\n",
            "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed: 159.7min\n",
            "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed: 159.9min\n",
            "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed: 161.6min\n",
            "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed: 162.8min\n",
            "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed: 163.0min\n",
            "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed: 164.7min\n",
            "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed: 165.7min\n",
            "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed: 166.1min\n",
            "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed: 168.0min\n",
            "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed: 168.9min\n",
            "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed: 169.4min\n",
            "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed: 170.8min\n",
            "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed: 171.8min\n",
            "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed: 172.5min\n",
            "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed: 174.2min\n",
            "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed: 177.0min\n",
            "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed: 177.8min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  6.0min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed:  9.1min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 17.3min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 18.5min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 19.9min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 20.7min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 21.4min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 22.5min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 24.2min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 24.3min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 25.4min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 26.6min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 27.2min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 28.5min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 29.4min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 30.6min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 32.5min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 33.0min\n",
            "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed: 34.2min\n",
            "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed: 35.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed: 36.3min\n",
            "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed: 37.0min\n",
            "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed: 38.4min\n",
            "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed: 38.7min\n",
            "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed: 40.1min\n",
            "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed: 42.0min\n",
            "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed: 42.1min\n",
            "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed: 42.3min\n",
            "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 44.9min\n",
            "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed: 45.2min\n",
            "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed: 45.3min\n",
            "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed: 47.7min\n",
            "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed: 48.5min\n",
            "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed: 48.7min\n",
            "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed: 50.5min\n",
            "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed: 51.4min\n",
            "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed: 52.0min\n",
            "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed: 53.5min\n",
            "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed: 54.7min\n",
            "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed: 54.9min\n",
            "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed: 56.2min\n",
            "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed: 57.5min\n",
            "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed: 58.1min\n",
            "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed: 59.7min\n",
            "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed: 60.4min\n",
            "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed: 61.0min\n",
            "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed: 62.6min\n",
            "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed: 63.2min\n",
            "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed: 64.2min\n",
            "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed: 65.8min\n",
            "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed: 66.5min\n",
            "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed: 67.0min\n",
            "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed: 68.6min\n",
            "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed: 69.3min\n",
            "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed: 70.0min\n",
            "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed: 71.9min\n",
            "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed: 72.5min\n",
            "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed: 73.1min\n",
            "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed: 74.3min\n",
            "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed: 75.8min\n",
            "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed: 76.3min\n",
            "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed: 77.3min\n",
            "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed: 78.9min\n",
            "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed: 79.2min\n",
            "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed: 80.2min\n",
            "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed: 82.1min\n",
            "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed: 82.4min\n",
            "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed: 83.2min\n",
            "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed: 85.2min\n",
            "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed: 85.7min\n",
            "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed: 85.9min\n",
            "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed: 88.0min\n",
            "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed: 88.7min\n",
            "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed: 89.3min\n",
            "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed: 91.3min\n",
            "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed: 92.3min\n",
            "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed: 94.2min\n",
            "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed: 94.7min\n",
            "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed: 95.5min\n",
            "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed: 97.3min\n",
            "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed: 97.6min\n",
            "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed: 98.3min\n",
            "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed: 100.2min\n",
            "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed: 100.3min\n",
            "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed: 101.7min\n",
            "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed: 103.1min\n",
            "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed: 103.3min\n",
            "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed: 104.6min\n",
            "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed: 106.1min\n",
            "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed: 106.2min\n",
            "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed: 107.7min\n",
            "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed: 108.7min\n",
            "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed: 109.5min\n",
            "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed: 110.6min\n",
            "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed: 111.6min\n",
            "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed: 112.4min\n",
            "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed: 114.1min\n",
            "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed: 114.8min\n",
            "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed: 114.9min\n",
            "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed: 116.9min\n",
            "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed: 117.6min\n",
            "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed: 117.9min\n",
            "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed: 120.0min\n",
            "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed: 120.7min\n",
            "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed: 120.9min\n",
            "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed: 122.5min\n",
            "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed: 123.8min\n",
            "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed: 123.9min\n",
            "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed: 125.4min\n",
            "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed: 126.7min\n",
            "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed: 127.1min\n",
            "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed: 127.9min\n",
            "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed: 129.5min\n",
            "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed: 130.1min\n",
            "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed: 131.0min\n",
            "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed: 132.7min\n",
            "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed: 132.8min\n",
            "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed: 133.5min\n",
            "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed: 135.6min\n",
            "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed: 136.0min\n",
            "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed: 136.8min\n",
            "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed: 139.2min\n",
            "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed: 141.7min\n",
            "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed: 142.0min\n",
            "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed: 142.2min\n",
            "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed: 145.3min\n",
            "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed: 147.5min\n",
            "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed: 148.2min\n",
            "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed: 148.8min\n",
            "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed: 150.8min\n",
            "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed: 151.2min\n",
            "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed: 151.6min\n",
            "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed: 153.7min\n",
            "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed: 154.1min\n",
            "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed: 155.1min\n",
            "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 156.8min\n",
            "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed: 156.9min\n",
            "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed: 158.3min\n",
            "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed: 159.7min\n",
            "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed: 159.9min\n",
            "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed: 161.6min\n",
            "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed: 162.8min\n",
            "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed: 163.0min\n",
            "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed: 164.7min\n",
            "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed: 165.7min\n",
            "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed: 166.1min\n",
            "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed: 168.0min\n",
            "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed: 168.9min\n",
            "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed: 169.4min\n",
            "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed: 170.8min\n",
            "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed: 171.8min\n",
            "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed: 172.5min\n",
            "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed: 174.2min\n",
            "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed: 177.0min\n",
            "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed: 177.8min\n",
            "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed: 178.6min\n",
            "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed: 178.6min\n",
            "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed: 180.3min\n",
            "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed: 180.3min\n",
            "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed: 181.1min\n",
            "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed: 181.1min\n",
            "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed: 181.4min\n",
            "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed: 181.4min\n",
            "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed: 183.1min\n",
            "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed: 183.1min\n",
            "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed: 184.1min\n",
            "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed: 184.1min\n",
            "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed: 184.5min\n",
            "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed: 184.5min\n",
            "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed: 186.1min\n",
            "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed: 186.1min\n",
            "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed: 187.2min\n",
            "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed: 187.2min\n",
            "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed: 187.5min\n",
            "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed: 187.5min\n",
            "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed: 189.1min\n",
            "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed: 189.1min\n",
            "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed: 190.1min\n",
            "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed: 190.1min\n",
            "[Parallel(n_jobs=3)]: Done 192 out of 192 | elapsed: 192.8min finished\n",
            "[Parallel(n_jobs=3)]: Done 192 out of 192 | elapsed: 192.8min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split',\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=90,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_state=None, reg_...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'bagging_fraction': (0.5, 0.6),\n",
            "                         'feature_fraction': (0.5, 0.6), 'lambda_l1': (2, 4),\n",
            "                         'max_bin': (100, 125), 'min_data_in_leaf': (200, 300),\n",
            "                         'num_leaves': (150, 250)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9267652722511871\n",
            "{'bagging_fraction': 0.5, 'feature_fraction': 0.6, 'lambda_l1': 2, 'max_bin': 125, 'min_data_in_leaf': 300, 'num_leaves': 250}\n",
            "LGBMClassifier(bagging_fraction=0.5, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.6,\n",
            "               importance_type='split', lambda_l1=2, learning_rate=0.1,\n",
            "               max_bin=125, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=300, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=90, num_leaves=250,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n",
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split',\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=90,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_state=None, reg_...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'bagging_fraction': (0.5, 0.6),\n",
            "                         'feature_fraction': (0.5, 0.6), 'lambda_l1': (2, 4),\n",
            "                         'max_bin': (100, 125), 'min_data_in_leaf': (200, 300),\n",
            "                         'num_leaves': (150, 250)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9267652722511871\n",
            "{'bagging_fraction': 0.5, 'feature_fraction': 0.6, 'lambda_l1': 2, 'max_bin': 125, 'min_data_in_leaf': 300, 'num_leaves': 250}\n",
            "LGBMClassifier(bagging_fraction=0.5, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.6,\n",
            "               importance_type='split', lambda_l1=2, learning_rate=0.1,\n",
            "               max_bin=125, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=300, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=90, num_leaves=250,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "52sUc9Uswc1x",
        "outputId": "7dfa9c3b-227e-437f-fe7a-d88372d8a4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'max_bin':(100,125),#               #'learning_rate':(0.2,0.3),\n",
        "     'feature_fraction':(0.7,0.8),\n",
        "     'num_leaves':(300,350),#\n",
        "     'min_data_in_leaf':(300),\n",
        "     'lambda_l1':(1),#                    #'lambda_l2':(2,4,6),     #'max_depth':(60,80,90),\n",
        "     'bagging_fraction':(0.3,0.4)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=3,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  7.0min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  7.3min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed: 10.3min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed: 10.9min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 13.8min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 13.9min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 17.0min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 17.2min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 18.2min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 20.4min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 20.9min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 21.9min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 23.5min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 24.5min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 25.2min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 26.9min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 27.8min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 29.1min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 30.4min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 32.5min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 33.5min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 34.5min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 36.2min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 36.7min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 37.8min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 39.6min\n",
            "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed: 39.8min\n",
            "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed: 41.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed: 43.1min\n",
            "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed: 43.2min\n",
            "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed: 44.4min\n",
            "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed: 46.1min\n",
            "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed: 46.7min\n",
            "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed: 48.2min\n",
            "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed: 49.6min\n",
            "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed: 49.7min\n",
            "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 51.6min\n",
            "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed: 53.0min\n",
            "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed: 53.0min\n",
            "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed: 55.0min\n",
            "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed: 56.0min\n",
            "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed: 56.6min\n",
            "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed: 58.7min\n",
            "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed: 59.6min\n",
            "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed: 60.1min\n",
            "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed: 62.7min\n",
            "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed: 62.9min\n",
            "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed: 63.6min\n",
            "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed: 66.1min\n",
            "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed: 66.4min\n",
            "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed: 67.2min\n",
            "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed: 69.8min\n",
            "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed: 70.3min\n",
            "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed: 70.5min\n",
            "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed: 73.2min\n",
            "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed: 74.1min\n",
            "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed: 74.2min\n",
            "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed: 76.9min\n",
            "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed: 77.7min\n",
            "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed: 77.8min\n",
            "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed: 80.7min\n",
            "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed: 81.0min\n",
            "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed: 81.4min\n",
            "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed: 84.1min\n",
            "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed: 84.8min\n",
            "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed: 84.9min\n",
            "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed: 87.8min\n",
            "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed: 88.4min\n",
            "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed: 88.4min\n",
            "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed: 92.1min\n",
            "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed: 95.0min\n",
            "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed: 95.2min\n",
            "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed: 95.9min\n",
            "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed: 98.8min\n",
            "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed: 99.0min\n",
            "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed: 99.1min\n",
            "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed: 101.9min\n",
            "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed: 102.9min\n",
            "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed: 102.9min\n",
            "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed: 105.4min\n",
            "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed: 106.4min\n",
            "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed: 106.8min\n",
            "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed: 108.6min\n",
            "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed: 110.0min\n",
            "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed: 110.4min\n",
            "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed: 112.4min\n",
            "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed: 113.3min\n",
            "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed: 114.0min\n",
            "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed: 116.0min\n",
            "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed: 116.6min\n",
            "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed: 117.3min\n",
            "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed: 119.8min\n",
            "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed: 120.2min\n",
            "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed: 120.7min\n",
            "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed: 123.3min\n",
            "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed: 123.7min\n",
            "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed: 124.0min\n",
            "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed: 127.0min\n",
            "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed: 127.2min\n",
            "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed: 127.3min\n",
            "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed: 130.6min\n",
            "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed: 130.7min\n",
            "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed: 130.7min\n",
            "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed: 133.7min\n",
            "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed: 134.3min\n",
            "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed: 134.4min\n",
            "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed: 137.1min\n",
            "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed: 137.7min\n",
            "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed: 138.1min\n",
            "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed: 140.6min\n",
            "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed: 141.1min\n",
            "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed: 141.6min\n",
            "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed: 143.9min\n",
            "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed: 144.7min\n",
            "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed: 147.1min\n",
            "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed: 148.3min\n",
            "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed: 148.5min\n",
            "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed: 150.6min\n",
            "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed: 151.8min\n",
            "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed: 152.1min\n",
            "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed: 154.0min\n",
            "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed: 155.4min\n",
            "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed: 155.7min\n",
            "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed: 157.4min\n",
            "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed: 158.6min\n",
            "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed: 159.3min\n",
            "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed: 160.8min\n",
            "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed: 162.2min\n",
            "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed: 162.7min\n",
            "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed: 164.2min\n",
            "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed: 165.5min\n",
            "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed: 166.0min\n",
            "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed: 168.0min\n",
            "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed: 169.1min\n",
            "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed: 169.3min\n",
            "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed: 171.4min\n",
            "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed: 172.8min\n",
            "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed: 172.9min\n",
            "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed: 175.2min\n",
            "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed: 176.4min\n",
            "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed: 176.5min\n",
            "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed: 178.7min\n",
            "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed: 179.8min\n",
            "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed: 180.1min\n",
            "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed: 182.3min\n",
            "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 183.5min\n",
            "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed: 183.7min\n",
            "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed: 185.8min\n",
            "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed: 187.2min\n",
            "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed: 187.3min\n",
            "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed: 189.6min\n",
            "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed: 190.5min\n",
            "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed: 191.1min\n",
            "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed: 192.9min\n",
            "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed: 194.2min\n",
            "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed: 194.6min\n",
            "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed: 196.8min\n",
            "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed: 197.6min\n",
            "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed: 198.0min\n",
            "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed: 200.2min\n",
            "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed: 201.1min\n",
            "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed: 201.7min\n",
            "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed: 203.9min\n",
            "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed: 204.6min\n",
            "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed: 205.2min\n",
            "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed: 207.5min\n",
            "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed: 207.9min\n",
            "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed: 208.8min\n",
            "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed: 211.4min\n",
            "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed: 212.0min\n",
            "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed: 212.0min\n",
            "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed: 215.0min\n",
            "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed: 215.6min\n",
            "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed: 215.7min\n",
            "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed: 218.4min\n",
            "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed: 219.1min\n",
            "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed: 219.3min\n",
            "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed: 222.1min\n",
            "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed: 222.6min\n",
            "[Parallel(n_jobs=3)]: Done 192 out of 192 | elapsed: 225.7min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split',\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=90,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_state=None, reg_...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'bagging_fraction': (0.4, 0.5),\n",
            "                         'feature_fraction': (0.6, 0.7), 'lambda_l1': (1, 2),\n",
            "                         'max_bin': (125, 150), 'min_data_in_leaf': (300, 400),\n",
            "                         'num_leaves': (250, 300)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9272417521074825\n",
            "{'bagging_fraction': 0.4, 'feature_fraction': 0.7, 'lambda_l1': 1, 'max_bin': 125, 'min_data_in_leaf': 300, 'num_leaves': 300}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, learning_rate=0.1,\n",
            "               max_bin=125, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=300, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=90, num_leaves=300,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d1qmccME6gNU",
        "outputId": "7059376d-383a-43b4-863a-17fc988b5119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'learning_rate':(0.2,0.3),\n",
        "     'lambda_l2':(2,4),     \n",
        "     'max_depth':(60,80,90)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=3,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=1,max_bin=125,min_data_in_leaf=300,num_leaves=300)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  6.7min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  7.2min\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed: 11.0min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed: 11.1min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 14.0min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 14.0min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 14.7min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 17.1min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 17.5min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 18.3min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 20.5min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 20.9min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 22.1min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 23.8min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 24.6min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 25.8min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 27.4min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 28.2min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 29.6min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 30.8min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 32.3min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 33.1min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 34.0min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 35.9min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 36.7min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 37.3min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 39.3min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 40.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 out of  36 | elapsed: 43.2min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.4,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      feature_fraction=0.7,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_bin=125,\n",
            "                                      max_depth=-1, min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=300, min_split_gain=0.0,\n",
            "                                      n_estimat...\n",
            "                                      num_iterations=90, num_leaves=300,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'lambda_l2': (2, 4), 'learning_rate': (0.2, 0.3),\n",
            "                         'max_depth': (60, 80, 90)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9319399935584403\n",
            "{'lambda_l2': 4, 'learning_rate': 0.3, 'max_depth': 60}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=4,\n",
            "               learning_rate=0.3, max_bin=125, max_depth=60,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=300, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=300, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YwFiAmL4JZDO",
        "outputId": "1aac075a-8258-4c64-c232-55266ebeb34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'learning_rate':(0.4,0.5),\n",
        "     'lambda_l2':(6,8),     \n",
        "     'max_depth':(40,50)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=4,refit=\"accuracy\",pre_dispatch=5,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=1,max_bin=125,min_data_in_leaf=300,num_leaves=300)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  7.9min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:  8.1min\n",
            "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed: 11.7min\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed: 11.9min\n",
            "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed: 12.0min\n",
            "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed: 15.7min\n",
            "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed: 15.9min\n",
            "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed: 16.0min\n",
            "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed: 16.0min\n",
            "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed: 19.6min\n",
            "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed: 19.7min\n",
            "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed: 19.9min\n",
            "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed: 20.1min\n",
            "[Parallel(n_jobs=4)]: Done  21 out of  24 | elapsed: 23.6min remaining:  3.4min\n",
            "[Parallel(n_jobs=4)]: Done  22 out of  24 | elapsed: 23.7min remaining:  2.2min\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 24.0min finished\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 24.0min remaining:    0.0s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.4,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      feature_fraction=0.7,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_bin=125,\n",
            "                                      max_depth=-1, min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=300, min_split_gain=0.0,\n",
            "                                      n_estimat...\n",
            "                                      num_iterations=90, num_leaves=300,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=4,\n",
            "             param_grid={'lambda_l2': (4, 6), 'learning_rate': (0.3, 0.4),\n",
            "                         'max_depth': (50, 60)},\n",
            "             pre_dispatch=5, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9330757831179838\n",
            "{'lambda_l2': 6, 'learning_rate': 0.4, 'max_depth': 50}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=6,\n",
            "               learning_rate=0.4, max_bin=125, max_depth=50,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=300, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=300, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZdlHThqYTZSQ",
        "outputId": "fbf31d0c-2636-4028-a7b8-174f914e6c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'learning_rate':(0.4,0.5),\n",
        "     'lambda_l2':(6,8),     \n",
        "     'max_depth':(40,50)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=4,refit=\"accuracy\",pre_dispatch=5,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=1,max_bin=125,min_data_in_leaf=300,num_leaves=300)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  7.7min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed: 11.5min\n",
            "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed: 11.7min\n",
            "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed: 15.2min\n",
            "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed: 15.5min\n",
            "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed: 15.5min\n",
            "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed: 15.6min\n",
            "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed: 19.2min\n",
            "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed: 19.3min\n",
            "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed: 19.5min\n",
            "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed: 19.5min\n",
            "[Parallel(n_jobs=4)]: Done  21 out of  24 | elapsed: 23.1min remaining:  3.3min\n",
            "[Parallel(n_jobs=4)]: Done  22 out of  24 | elapsed: 23.2min remaining:  2.1min\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 23.4min remaining:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 23.4min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.4,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      feature_fraction=0.7,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_bin=125,\n",
            "                                      max_depth=-1, min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=300, min_split_gain=0.0,\n",
            "                                      n_estimat...\n",
            "                                      num_iterations=90, num_leaves=300,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=4,\n",
            "             param_grid={'lambda_l2': (6, 8), 'learning_rate': (0.4, 0.5),\n",
            "                         'max_depth': (40, 50)},\n",
            "             pre_dispatch=5, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9337819973503855\n",
            "{'lambda_l2': 8, 'learning_rate': 0.5, 'max_depth': 40}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=8,\n",
            "               learning_rate=0.5, max_bin=125, max_depth=40,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=300, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=300, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cEBGv0t5Iixl",
        "outputId": "40dd92c9-2a43-48b4-9f7a-d0ac3eadc296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols,Y_train.OUTCOME.mean(),Y_test.OUTCOME.mean())\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(extra_trees=True,num_iterations=100,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=3,max_bin=125,min_data_in_leaf=300,num_leaves=300,lambda_l2=8,learning_rate=0.2,max_depth=40)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  sel_X_valid=X_valid[sel_cols]\n",
        "  eval_set = [(sel_X_test, Y_test)]\n",
        "  model.fit(sel_X_train, Y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
        "\n",
        "  print(\"Test dataset:\")\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(\"Validation dataset:\")\n",
        "  pred=model.predict(sel_X_valid)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_valid,pred)\n",
        "\n",
        "  \n",
        "  print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "  #plot graph of feature importances for better visualization\n",
        "  feat_importances = pd.Series(model.feature_importances_, index=sel_cols)\n",
        "  feat_importances.nlargest(26).plot(kind='barh')\n",
        "  plt.show()\n",
        "\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test,sel_X_valid])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test,Y_valid])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing', 'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction'] 0.5 0.3036830716473116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.570168\tvalid_0's binary_logloss: 0.570168\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.491394\tvalid_0's binary_logloss: 0.491394\n",
            "[3]\tvalid_0's binary_logloss: 0.436575\tvalid_0's binary_logloss: 0.436575\n",
            "[4]\tvalid_0's binary_logloss: 0.385073\tvalid_0's binary_logloss: 0.385073\n",
            "[5]\tvalid_0's binary_logloss: 0.357315\tvalid_0's binary_logloss: 0.357315\n",
            "[6]\tvalid_0's binary_logloss: 0.328788\tvalid_0's binary_logloss: 0.328788\n",
            "[7]\tvalid_0's binary_logloss: 0.310631\tvalid_0's binary_logloss: 0.310631\n",
            "[8]\tvalid_0's binary_logloss: 0.292662\tvalid_0's binary_logloss: 0.292662\n",
            "[9]\tvalid_0's binary_logloss: 0.283471\tvalid_0's binary_logloss: 0.283471\n",
            "[10]\tvalid_0's binary_logloss: 0.27649\tvalid_0's binary_logloss: 0.27649\n",
            "[11]\tvalid_0's binary_logloss: 0.266331\tvalid_0's binary_logloss: 0.266331\n",
            "[12]\tvalid_0's binary_logloss: 0.25487\tvalid_0's binary_logloss: 0.25487\n",
            "[13]\tvalid_0's binary_logloss: 0.245989\tvalid_0's binary_logloss: 0.245989\n",
            "[14]\tvalid_0's binary_logloss: 0.239264\tvalid_0's binary_logloss: 0.239264\n",
            "[15]\tvalid_0's binary_logloss: 0.234017\tvalid_0's binary_logloss: 0.234017\n",
            "[16]\tvalid_0's binary_logloss: 0.230791\tvalid_0's binary_logloss: 0.230791\n",
            "[17]\tvalid_0's binary_logloss: 0.227808\tvalid_0's binary_logloss: 0.227808\n",
            "[18]\tvalid_0's binary_logloss: 0.224644\tvalid_0's binary_logloss: 0.224644\n",
            "[19]\tvalid_0's binary_logloss: 0.222551\tvalid_0's binary_logloss: 0.222551\n",
            "[20]\tvalid_0's binary_logloss: 0.2207\tvalid_0's binary_logloss: 0.2207\n",
            "[21]\tvalid_0's binary_logloss: 0.219439\tvalid_0's binary_logloss: 0.219439\n",
            "[22]\tvalid_0's binary_logloss: 0.218189\tvalid_0's binary_logloss: 0.218189\n",
            "[23]\tvalid_0's binary_logloss: 0.216337\tvalid_0's binary_logloss: 0.216337\n",
            "[24]\tvalid_0's binary_logloss: 0.215447\tvalid_0's binary_logloss: 0.215447\n",
            "[25]\tvalid_0's binary_logloss: 0.214748\tvalid_0's binary_logloss: 0.214748\n",
            "[26]\tvalid_0's binary_logloss: 0.213644\tvalid_0's binary_logloss: 0.213644\n",
            "[27]\tvalid_0's binary_logloss: 0.212427\tvalid_0's binary_logloss: 0.212427\n",
            "[28]\tvalid_0's binary_logloss: 0.211696\tvalid_0's binary_logloss: 0.211696\n",
            "[29]\tvalid_0's binary_logloss: 0.210929\tvalid_0's binary_logloss: 0.210929\n",
            "[30]\tvalid_0's binary_logloss: 0.210033\tvalid_0's binary_logloss: 0.210033\n",
            "[31]\tvalid_0's binary_logloss: 0.209203\tvalid_0's binary_logloss: 0.209203\n",
            "[32]\tvalid_0's binary_logloss: 0.208718\tvalid_0's binary_logloss: 0.208718\n",
            "[33]\tvalid_0's binary_logloss: 0.208162\tvalid_0's binary_logloss: 0.208162\n",
            "[34]\tvalid_0's binary_logloss: 0.20784\tvalid_0's binary_logloss: 0.20784\n",
            "[35]\tvalid_0's binary_logloss: 0.207099\tvalid_0's binary_logloss: 0.207099\n",
            "[36]\tvalid_0's binary_logloss: 0.206755\tvalid_0's binary_logloss: 0.206755\n",
            "[37]\tvalid_0's binary_logloss: 0.206165\tvalid_0's binary_logloss: 0.206165\n",
            "[38]\tvalid_0's binary_logloss: 0.205888\tvalid_0's binary_logloss: 0.205888\n",
            "[39]\tvalid_0's binary_logloss: 0.205596\tvalid_0's binary_logloss: 0.205596\n",
            "[40]\tvalid_0's binary_logloss: 0.205263\tvalid_0's binary_logloss: 0.205263\n",
            "[41]\tvalid_0's binary_logloss: 0.204911\tvalid_0's binary_logloss: 0.204911\n",
            "[42]\tvalid_0's binary_logloss: 0.204667\tvalid_0's binary_logloss: 0.204667\n",
            "[43]\tvalid_0's binary_logloss: 0.20421\tvalid_0's binary_logloss: 0.20421\n",
            "[44]\tvalid_0's binary_logloss: 0.203853\tvalid_0's binary_logloss: 0.203853\n",
            "[45]\tvalid_0's binary_logloss: 0.203639\tvalid_0's binary_logloss: 0.203639\n",
            "[46]\tvalid_0's binary_logloss: 0.203098\tvalid_0's binary_logloss: 0.203098\n",
            "[47]\tvalid_0's binary_logloss: 0.202861\tvalid_0's binary_logloss: 0.202861\n",
            "[48]\tvalid_0's binary_logloss: 0.202492\tvalid_0's binary_logloss: 0.202492\n",
            "[49]\tvalid_0's binary_logloss: 0.20227\tvalid_0's binary_logloss: 0.20227\n",
            "[50]\tvalid_0's binary_logloss: 0.202049\tvalid_0's binary_logloss: 0.202049\n",
            "[51]\tvalid_0's binary_logloss: 0.201785\tvalid_0's binary_logloss: 0.201785\n",
            "[52]\tvalid_0's binary_logloss: 0.201612\tvalid_0's binary_logloss: 0.201612\n",
            "[53]\tvalid_0's binary_logloss: 0.201473\tvalid_0's binary_logloss: 0.201473\n",
            "[54]\tvalid_0's binary_logloss: 0.201336\tvalid_0's binary_logloss: 0.201336\n",
            "[55]\tvalid_0's binary_logloss: 0.201183\tvalid_0's binary_logloss: 0.201183\n",
            "[56]\tvalid_0's binary_logloss: 0.20107\tvalid_0's binary_logloss: 0.20107\n",
            "[57]\tvalid_0's binary_logloss: 0.200817\tvalid_0's binary_logloss: 0.200817\n",
            "[58]\tvalid_0's binary_logloss: 0.200626\tvalid_0's binary_logloss: 0.200626\n",
            "[59]\tvalid_0's binary_logloss: 0.200552\tvalid_0's binary_logloss: 0.200552\n",
            "[60]\tvalid_0's binary_logloss: 0.200303\tvalid_0's binary_logloss: 0.200303\n",
            "[61]\tvalid_0's binary_logloss: 0.20016\tvalid_0's binary_logloss: 0.20016\n",
            "[62]\tvalid_0's binary_logloss: 0.20001\tvalid_0's binary_logloss: 0.20001\n",
            "[63]\tvalid_0's binary_logloss: 0.199891\tvalid_0's binary_logloss: 0.199891\n",
            "[64]\tvalid_0's binary_logloss: 0.199622\tvalid_0's binary_logloss: 0.199622\n",
            "[65]\tvalid_0's binary_logloss: 0.199348\tvalid_0's binary_logloss: 0.199348\n",
            "[66]\tvalid_0's binary_logloss: 0.199213\tvalid_0's binary_logloss: 0.199213\n",
            "[67]\tvalid_0's binary_logloss: 0.198983\tvalid_0's binary_logloss: 0.198983\n",
            "[68]\tvalid_0's binary_logloss: 0.198848\tvalid_0's binary_logloss: 0.198848\n",
            "[69]\tvalid_0's binary_logloss: 0.198788\tvalid_0's binary_logloss: 0.198788\n",
            "[70]\tvalid_0's binary_logloss: 0.198617\tvalid_0's binary_logloss: 0.198617\n",
            "[71]\tvalid_0's binary_logloss: 0.198531\tvalid_0's binary_logloss: 0.198531\n",
            "[72]\tvalid_0's binary_logloss: 0.1985\tvalid_0's binary_logloss: 0.1985\n",
            "[73]\tvalid_0's binary_logloss: 0.198346\tvalid_0's binary_logloss: 0.198346\n",
            "[74]\tvalid_0's binary_logloss: 0.19822\tvalid_0's binary_logloss: 0.19822\n",
            "[75]\tvalid_0's binary_logloss: 0.198066\tvalid_0's binary_logloss: 0.198066\n",
            "[76]\tvalid_0's binary_logloss: 0.197994\tvalid_0's binary_logloss: 0.197994\n",
            "[77]\tvalid_0's binary_logloss: 0.197876\tvalid_0's binary_logloss: 0.197876\n",
            "[78]\tvalid_0's binary_logloss: 0.197782\tvalid_0's binary_logloss: 0.197782\n",
            "[79]\tvalid_0's binary_logloss: 0.197709\tvalid_0's binary_logloss: 0.197709\n",
            "[80]\tvalid_0's binary_logloss: 0.197601\tvalid_0's binary_logloss: 0.197601\n",
            "[81]\tvalid_0's binary_logloss: 0.197432\tvalid_0's binary_logloss: 0.197432\n",
            "[82]\tvalid_0's binary_logloss: 0.197374\tvalid_0's binary_logloss: 0.197374\n",
            "[83]\tvalid_0's binary_logloss: 0.19722\tvalid_0's binary_logloss: 0.19722\n",
            "[84]\tvalid_0's binary_logloss: 0.197128\tvalid_0's binary_logloss: 0.197128\n",
            "[85]\tvalid_0's binary_logloss: 0.196954\tvalid_0's binary_logloss: 0.196954\n",
            "[86]\tvalid_0's binary_logloss: 0.196828\tvalid_0's binary_logloss: 0.196828\n",
            "[87]\tvalid_0's binary_logloss: 0.196757\tvalid_0's binary_logloss: 0.196757\n",
            "[88]\tvalid_0's binary_logloss: 0.196697\tvalid_0's binary_logloss: 0.196697\n",
            "[89]\tvalid_0's binary_logloss: 0.196655\tvalid_0's binary_logloss: 0.196655\n",
            "[90]\tvalid_0's binary_logloss: 0.19649\tvalid_0's binary_logloss: 0.19649\n",
            "[91]\tvalid_0's binary_logloss: 0.196397\tvalid_0's binary_logloss: 0.196397\n",
            "[92]\tvalid_0's binary_logloss: 0.196361\tvalid_0's binary_logloss: 0.196361\n",
            "[93]\tvalid_0's binary_logloss: 0.1963\tvalid_0's binary_logloss: 0.1963\n",
            "[94]\tvalid_0's binary_logloss: 0.196218\tvalid_0's binary_logloss: 0.196218\n",
            "[95]\tvalid_0's binary_logloss: 0.196191\tvalid_0's binary_logloss: 0.196191\n",
            "[96]\tvalid_0's binary_logloss: 0.196155\tvalid_0's binary_logloss: 0.196155\n",
            "[97]\tvalid_0's binary_logloss: 0.196116\tvalid_0's binary_logloss: 0.196116\n",
            "[98]\tvalid_0's binary_logloss: 0.196047\tvalid_0's binary_logloss: 0.196047\n",
            "[99]\tvalid_0's binary_logloss: 0.196002\tvalid_0's binary_logloss: 0.196002\n",
            "[100]\tvalid_0's binary_logloss: 0.195977\tvalid_0's binary_logloss: 0.195977\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's binary_logloss: 0.195977\tvalid_0's binary_logloss: 0.195977\n",
            "Test dataset:\n",
            "predictions are  [0 0 1 ... 0 0 0]\n",
            "Test ROC AUC score: 0.890926654025669\n",
            "Test accuracy score: 0.9240399230291186\n",
            "Confusion matrix is  [[181395   4601]\n",
            " [ 15689  65429]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95    185996\n",
            "           1       0.93      0.81      0.87     81118\n",
            "\n",
            "    accuracy                           0.92    267114\n",
            "   macro avg       0.93      0.89      0.91    267114\n",
            "weighted avg       0.92      0.92      0.92    267114\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation dataset:\n",
            "predictions are  [0 1 1 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8916015472841764\n",
            "Test accuracy score: 0.924209574078366\n",
            "Confusion matrix is  [[362801   9300]\n",
            " [ 31250 131677]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95    372101\n",
            "           1       0.93      0.81      0.87    162927\n",
            "\n",
            "    accuracy                           0.92    535028\n",
            "   macro avg       0.93      0.89      0.91    535028\n",
            "weighted avg       0.92      0.92      0.92    535028\n",
            "\n",
            "\n",
            "\n",
            "[1959 2586 2144 1634 1872 2987 3511    0    0    0    0    0 2347 1854\n",
            "  679  551  802  573  685   40   14    6    3    1 1483 1136 1108  710\n",
            " 1215]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([37.20670152, 37.25255466, 37.24802899, 37.65227151, 38.78528047]), 'score_time': array([3.06525946, 3.09736371, 3.16466808, 3.13587904, 3.15779543]), 'test_accuracy': array([0.9246372 , 0.92377082, 0.9239499 , 0.92363358, 0.92434725]), 'test_roc_auc': array([0.89131   , 0.89014033, 0.89037155, 0.88960423, 0.8910209 ])}\n",
            "cross for accuracy [0.9246372  0.92377082 0.9239499  0.92363358 0.92434725]\n",
            "cross for roc-auc [0.89131    0.89014033 0.89037155 0.88960423 0.8910209 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQbFihYc_4ki",
        "colab_type": "code",
        "outputId": "44e4289d-6788-43bd-cd16-a78992d0342f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sel_cols=cols_after_removing_recursive\n",
        "print(sel_cols,Y_train.OUTCOME.mean(),Y_test.OUTCOME.mean())\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(extra_trees=True,num_iterations=100,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=3,max_bin=125,min_data_in_leaf=300,num_leaves=300,lambda_l2=8,learning_rate=0.2,max_depth=40)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  sel_X_valid=X_valid[sel_cols]\n",
        "  eval_set = [(sel_X_test, Y_test)]\n",
        "  model.fit(sel_X_train, Y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
        "\n",
        "  print(\"Test dataset:\")\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(\"Validation dataset:\")\n",
        "  pred=model.predict(sel_X_valid)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_valid,pred)\n",
        "\n",
        "  \n",
        "  print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "  #plot graph of feature importances for better visualization\n",
        "  feat_importances = pd.Series(model.feature_importances_, index=sel_cols)\n",
        "  feat_importances.nlargest(26).plot(kind='barh')\n",
        "  plt.show()\n",
        "\n",
        "  X=pd.concat([sel_X_train[:2406600],sel_X_test,sel_X_valid])\n",
        "  y=pd.concat([Y_train[:2406600],Y_test,Y_valid])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'WHEELS_OFF_HOUR', 'AIR_SYSTEM_DELAY_is_missing', 'pressure', 'wind_speed'] 0.5 0.3036830716473116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.570172\tvalid_0's binary_logloss: 0.570172\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.497118\tvalid_0's binary_logloss: 0.497118\n",
            "[3]\tvalid_0's binary_logloss: 0.434784\tvalid_0's binary_logloss: 0.434784\n",
            "[4]\tvalid_0's binary_logloss: 0.390017\tvalid_0's binary_logloss: 0.390017\n",
            "[5]\tvalid_0's binary_logloss: 0.357049\tvalid_0's binary_logloss: 0.357049\n",
            "[6]\tvalid_0's binary_logloss: 0.326321\tvalid_0's binary_logloss: 0.326321\n",
            "[7]\tvalid_0's binary_logloss: 0.307394\tvalid_0's binary_logloss: 0.307394\n",
            "[8]\tvalid_0's binary_logloss: 0.290036\tvalid_0's binary_logloss: 0.290036\n",
            "[9]\tvalid_0's binary_logloss: 0.278138\tvalid_0's binary_logloss: 0.278138\n",
            "[10]\tvalid_0's binary_logloss: 0.266081\tvalid_0's binary_logloss: 0.266081\n",
            "[11]\tvalid_0's binary_logloss: 0.260346\tvalid_0's binary_logloss: 0.260346\n",
            "[12]\tvalid_0's binary_logloss: 0.253967\tvalid_0's binary_logloss: 0.253967\n",
            "[13]\tvalid_0's binary_logloss: 0.247008\tvalid_0's binary_logloss: 0.247008\n",
            "[14]\tvalid_0's binary_logloss: 0.24452\tvalid_0's binary_logloss: 0.24452\n",
            "[15]\tvalid_0's binary_logloss: 0.237892\tvalid_0's binary_logloss: 0.237892\n",
            "[16]\tvalid_0's binary_logloss: 0.23293\tvalid_0's binary_logloss: 0.23293\n",
            "[17]\tvalid_0's binary_logloss: 0.230403\tvalid_0's binary_logloss: 0.230403\n",
            "[18]\tvalid_0's binary_logloss: 0.226827\tvalid_0's binary_logloss: 0.226827\n",
            "[19]\tvalid_0's binary_logloss: 0.224\tvalid_0's binary_logloss: 0.224\n",
            "[20]\tvalid_0's binary_logloss: 0.221418\tvalid_0's binary_logloss: 0.221418\n",
            "[21]\tvalid_0's binary_logloss: 0.22047\tvalid_0's binary_logloss: 0.22047\n",
            "[22]\tvalid_0's binary_logloss: 0.218667\tvalid_0's binary_logloss: 0.218667\n",
            "[23]\tvalid_0's binary_logloss: 0.216593\tvalid_0's binary_logloss: 0.216593\n",
            "[24]\tvalid_0's binary_logloss: 0.215179\tvalid_0's binary_logloss: 0.215179\n",
            "[25]\tvalid_0's binary_logloss: 0.214029\tvalid_0's binary_logloss: 0.214029\n",
            "[26]\tvalid_0's binary_logloss: 0.213188\tvalid_0's binary_logloss: 0.213188\n",
            "[27]\tvalid_0's binary_logloss: 0.212289\tvalid_0's binary_logloss: 0.212289\n",
            "[28]\tvalid_0's binary_logloss: 0.211479\tvalid_0's binary_logloss: 0.211479\n",
            "[29]\tvalid_0's binary_logloss: 0.210291\tvalid_0's binary_logloss: 0.210291\n",
            "[30]\tvalid_0's binary_logloss: 0.209786\tvalid_0's binary_logloss: 0.209786\n",
            "[31]\tvalid_0's binary_logloss: 0.209265\tvalid_0's binary_logloss: 0.209265\n",
            "[32]\tvalid_0's binary_logloss: 0.208804\tvalid_0's binary_logloss: 0.208804\n",
            "[33]\tvalid_0's binary_logloss: 0.207992\tvalid_0's binary_logloss: 0.207992\n",
            "[34]\tvalid_0's binary_logloss: 0.207571\tvalid_0's binary_logloss: 0.207571\n",
            "[35]\tvalid_0's binary_logloss: 0.206869\tvalid_0's binary_logloss: 0.206869\n",
            "[36]\tvalid_0's binary_logloss: 0.206277\tvalid_0's binary_logloss: 0.206277\n",
            "[37]\tvalid_0's binary_logloss: 0.20607\tvalid_0's binary_logloss: 0.20607\n",
            "[38]\tvalid_0's binary_logloss: 0.205559\tvalid_0's binary_logloss: 0.205559\n",
            "[39]\tvalid_0's binary_logloss: 0.205238\tvalid_0's binary_logloss: 0.205238\n",
            "[40]\tvalid_0's binary_logloss: 0.20476\tvalid_0's binary_logloss: 0.20476\n",
            "[41]\tvalid_0's binary_logloss: 0.204441\tvalid_0's binary_logloss: 0.204441\n",
            "[42]\tvalid_0's binary_logloss: 0.204194\tvalid_0's binary_logloss: 0.204194\n",
            "[43]\tvalid_0's binary_logloss: 0.203963\tvalid_0's binary_logloss: 0.203963\n",
            "[44]\tvalid_0's binary_logloss: 0.203756\tvalid_0's binary_logloss: 0.203756\n",
            "[45]\tvalid_0's binary_logloss: 0.203472\tvalid_0's binary_logloss: 0.203472\n",
            "[46]\tvalid_0's binary_logloss: 0.203218\tvalid_0's binary_logloss: 0.203218\n",
            "[47]\tvalid_0's binary_logloss: 0.202922\tvalid_0's binary_logloss: 0.202922\n",
            "[48]\tvalid_0's binary_logloss: 0.202768\tvalid_0's binary_logloss: 0.202768\n",
            "[49]\tvalid_0's binary_logloss: 0.202531\tvalid_0's binary_logloss: 0.202531\n",
            "[50]\tvalid_0's binary_logloss: 0.202331\tvalid_0's binary_logloss: 0.202331\n",
            "[51]\tvalid_0's binary_logloss: 0.202174\tvalid_0's binary_logloss: 0.202174\n",
            "[52]\tvalid_0's binary_logloss: 0.202054\tvalid_0's binary_logloss: 0.202054\n",
            "[53]\tvalid_0's binary_logloss: 0.201861\tvalid_0's binary_logloss: 0.201861\n",
            "[54]\tvalid_0's binary_logloss: 0.201757\tvalid_0's binary_logloss: 0.201757\n",
            "[55]\tvalid_0's binary_logloss: 0.20146\tvalid_0's binary_logloss: 0.20146\n",
            "[56]\tvalid_0's binary_logloss: 0.201311\tvalid_0's binary_logloss: 0.201311\n",
            "[57]\tvalid_0's binary_logloss: 0.201146\tvalid_0's binary_logloss: 0.201146\n",
            "[58]\tvalid_0's binary_logloss: 0.200858\tvalid_0's binary_logloss: 0.200858\n",
            "[59]\tvalid_0's binary_logloss: 0.200619\tvalid_0's binary_logloss: 0.200619\n",
            "[60]\tvalid_0's binary_logloss: 0.2004\tvalid_0's binary_logloss: 0.2004\n",
            "[61]\tvalid_0's binary_logloss: 0.200194\tvalid_0's binary_logloss: 0.200194\n",
            "[62]\tvalid_0's binary_logloss: 0.200097\tvalid_0's binary_logloss: 0.200097\n",
            "[63]\tvalid_0's binary_logloss: 0.200007\tvalid_0's binary_logloss: 0.200007\n",
            "[64]\tvalid_0's binary_logloss: 0.199832\tvalid_0's binary_logloss: 0.199832\n",
            "[65]\tvalid_0's binary_logloss: 0.199685\tvalid_0's binary_logloss: 0.199685\n",
            "[66]\tvalid_0's binary_logloss: 0.199512\tvalid_0's binary_logloss: 0.199512\n",
            "[67]\tvalid_0's binary_logloss: 0.199335\tvalid_0's binary_logloss: 0.199335\n",
            "[68]\tvalid_0's binary_logloss: 0.199265\tvalid_0's binary_logloss: 0.199265\n",
            "[69]\tvalid_0's binary_logloss: 0.199174\tvalid_0's binary_logloss: 0.199174\n",
            "[70]\tvalid_0's binary_logloss: 0.199004\tvalid_0's binary_logloss: 0.199004\n",
            "[71]\tvalid_0's binary_logloss: 0.198937\tvalid_0's binary_logloss: 0.198937\n",
            "[72]\tvalid_0's binary_logloss: 0.198801\tvalid_0's binary_logloss: 0.198801\n",
            "[73]\tvalid_0's binary_logloss: 0.198635\tvalid_0's binary_logloss: 0.198635\n",
            "[74]\tvalid_0's binary_logloss: 0.198535\tvalid_0's binary_logloss: 0.198535\n",
            "[75]\tvalid_0's binary_logloss: 0.198377\tvalid_0's binary_logloss: 0.198377\n",
            "[76]\tvalid_0's binary_logloss: 0.198256\tvalid_0's binary_logloss: 0.198256\n",
            "[77]\tvalid_0's binary_logloss: 0.198156\tvalid_0's binary_logloss: 0.198156\n",
            "[78]\tvalid_0's binary_logloss: 0.198056\tvalid_0's binary_logloss: 0.198056\n",
            "[79]\tvalid_0's binary_logloss: 0.197986\tvalid_0's binary_logloss: 0.197986\n",
            "[80]\tvalid_0's binary_logloss: 0.197805\tvalid_0's binary_logloss: 0.197805\n",
            "[81]\tvalid_0's binary_logloss: 0.197777\tvalid_0's binary_logloss: 0.197777\n",
            "[82]\tvalid_0's binary_logloss: 0.197607\tvalid_0's binary_logloss: 0.197607\n",
            "[83]\tvalid_0's binary_logloss: 0.197536\tvalid_0's binary_logloss: 0.197536\n",
            "[84]\tvalid_0's binary_logloss: 0.197511\tvalid_0's binary_logloss: 0.197511\n",
            "[85]\tvalid_0's binary_logloss: 0.197471\tvalid_0's binary_logloss: 0.197471\n",
            "[86]\tvalid_0's binary_logloss: 0.197417\tvalid_0's binary_logloss: 0.197417\n",
            "[87]\tvalid_0's binary_logloss: 0.197342\tvalid_0's binary_logloss: 0.197342\n",
            "[88]\tvalid_0's binary_logloss: 0.197297\tvalid_0's binary_logloss: 0.197297\n",
            "[89]\tvalid_0's binary_logloss: 0.197185\tvalid_0's binary_logloss: 0.197185\n",
            "[90]\tvalid_0's binary_logloss: 0.197095\tvalid_0's binary_logloss: 0.197095\n",
            "[91]\tvalid_0's binary_logloss: 0.197013\tvalid_0's binary_logloss: 0.197013\n",
            "[92]\tvalid_0's binary_logloss: 0.196945\tvalid_0's binary_logloss: 0.196945\n",
            "[93]\tvalid_0's binary_logloss: 0.196865\tvalid_0's binary_logloss: 0.196865\n",
            "[94]\tvalid_0's binary_logloss: 0.196807\tvalid_0's binary_logloss: 0.196807\n",
            "[95]\tvalid_0's binary_logloss: 0.196769\tvalid_0's binary_logloss: 0.196769\n",
            "[96]\tvalid_0's binary_logloss: 0.196745\tvalid_0's binary_logloss: 0.196745\n",
            "[97]\tvalid_0's binary_logloss: 0.196676\tvalid_0's binary_logloss: 0.196676\n",
            "[98]\tvalid_0's binary_logloss: 0.196603\tvalid_0's binary_logloss: 0.196603\n",
            "[99]\tvalid_0's binary_logloss: 0.19655\tvalid_0's binary_logloss: 0.19655\n",
            "[100]\tvalid_0's binary_logloss: 0.196484\tvalid_0's binary_logloss: 0.196484\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's binary_logloss: 0.196484\tvalid_0's binary_logloss: 0.196484\n",
            "Test dataset:\n",
            "predictions are  [0 0 1 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8910579959163466\n",
            "Test accuracy score: 0.9241260285870452\n",
            "Confusion matrix is  [[181398   4598]\n",
            " [ 15669  65449]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95    185996\n",
            "           1       0.93      0.81      0.87     81118\n",
            "\n",
            "    accuracy                           0.92    267114\n",
            "   macro avg       0.93      0.89      0.91    267114\n",
            "weighted avg       0.92      0.92      0.92    267114\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation dataset:\n",
            "predictions are  [0 1 1 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8913651750338425\n",
            "Test accuracy score: 0.923998370178757\n",
            "Confusion matrix is  [[362737   9364]\n",
            " [ 31299 131628]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95    372101\n",
            "           1       0.93      0.81      0.87    162927\n",
            "\n",
            "    accuracy                           0.92    535028\n",
            "   macro avg       0.93      0.89      0.91    535028\n",
            "weighted avg       0.92      0.92      0.92    535028\n",
            "\n",
            "\n",
            "\n",
            "[2567 2509 3024 2097 2795 3559 3452 2770 2351 2132   49 1632  963]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([23.67290545, 23.70847654, 23.7755034 , 23.71885538, 23.59588957]), 'score_time': array([2.85235906, 2.9614861 , 2.92092037, 2.92773962, 2.87094069]), 'test_accuracy': array([0.92452033, 0.92354332, 0.92421013, 0.92376447, 0.92422571]), 'test_roc_auc': array([0.89137046, 0.89001012, 0.89071878, 0.88994231, 0.8910679 ])}\n",
            "cross for accuracy [0.92452033 0.92354332 0.92421013 0.92376447 0.92422571]\n",
            "cross for roc-auc [0.89137046 0.89001012 0.89071878 0.88994231 0.8910679 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSa_F5DdiZ-e",
        "colab_type": "code",
        "outputId": "a4537683-636b-49fa-875c-6ac3ef31e66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "cols[8:13]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AIRLINE_DELAY',\n",
              " 'LATE_AIRCRAFT_DELAY',\n",
              " 'WEATHER_DELAY',\n",
              " 'SECURITY_DELAY',\n",
              " 'AIRLINE_ORIGIN_AIRPORT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-CSFvCpux_B8",
        "outputId": "602e982a-44da-424e-e3a5-66927d16f678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "source": [
        "def runXGBoostModel():\n",
        "  # fit model no training data\n",
        "  model = XGBClassifier(learning_rate=0.01,  \n",
        "                      colsample_bytree = 0.4,\n",
        "                      subsample = 0.8,\n",
        "                      objective='binary:logistic', \n",
        "                      n_estimators=300, \n",
        "                      reg_alpha = 0.3,\n",
        "                      max_depth=4,\n",
        "                      n_jobs=10,\n",
        "                      gamma=10)\n",
        "  model.fit(X_train, Y_train)\n",
        "  # make predictions for test data\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"Initial predictions are \",y_pred)\n",
        "  predictions = [round(value) for value in y_pred]\n",
        "  # evaluate predictions\n",
        "  report(Y_test,predictions)\n",
        "  X=pd.concat([X_train,X_test])\n",
        "  y=pd.concat([Y_train,Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "  \n",
        "runXGBoostModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[08:09:19] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
            "Initial predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.86731179532437\n",
            "Test accuracy score: 0.9062176437849815\n",
            "Confusion matrix is  [[970241  38777]\n",
            " [ 95185 324232]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.94   1009018\n",
            "           1       0.89      0.77      0.83    419417\n",
            "\n",
            "    accuracy                           0.91   1428435\n",
            "   macro avg       0.90      0.87      0.88   1428435\n",
            "weighted avg       0.91      0.91      0.90   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c398b2e8416e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgbclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mrunXGBoostModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-c398b2e8416e>\u001b[0m in \u001b[0;36mrunXGBoostModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgbclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mrunXGBoostModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lgbclassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p2HsWMEd3adP",
        "colab": {}
      },
      "source": [
        "def runXGBoostModel():\n",
        "  # fit model no training data\n",
        "  model = XGBClassifier()\n",
        "  eval_set = [(X_test, Y_test)]\n",
        "  model.fit(X_train, Y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
        "  # make predictions for test data\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"Initial predictions are \",y_pred)\n",
        "  predictions = [round(value) for value in y_pred]\n",
        "  # evaluate predictions\n",
        "  report(Y_test,predictions)\n",
        "  X=pd.concat([X_train,X_test])\n",
        "  y=pd.concat([Y_train,Y_test])\n",
        "  cross_validation(lgbclassifier,X,y)\n",
        "  \n",
        "runXGBoostModel()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}