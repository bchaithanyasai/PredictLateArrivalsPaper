{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Selection and Predictive Modelling-2015",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOBuB1JOjL9eB5zh1+AuiWm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bchaithanyasai/PredictLateArrivalsPaper/blob/master/Feature_Selection_and_Predictive_Modelling_2015.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zk626ZMKEedL",
        "outputId": "931e6d9d-d70d-4a2e-f88b-039f5363d596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4mJaM6qcFABM",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data=pd.read_csv(\"/content/drive/My Drive/train_data.csv\")\n",
        "test_data=pd.read_csv(\"/content/drive/My Drive/test_data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mQQWbYz2gMIN",
        "outputId": "9982aaaf-1a4a-43b9-9b70-b1fa82d1ad96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_data.OUTCOME.mean(),test_data.OUTCOME.mean())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5 0.2936199407043373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8nFtnzW2ZDo_",
        "outputId": "f387f589-949b-485e-b0f0-4b248c84b5c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "train_data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.308508</td>\n",
              "      <td>0.341235</td>\n",
              "      <td>0.082088</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>337.00000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1226.0</td>\n",
              "      <td>1219.000000</td>\n",
              "      <td>4225.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.304283</td>\n",
              "      <td>0.294836</td>\n",
              "      <td>0.130962</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>480.00000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1309.0</td>\n",
              "      <td>1302.000000</td>\n",
              "      <td>4446.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.257698</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.998464</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>425.00000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1282.0</td>\n",
              "      <td>1232.000000</td>\n",
              "      <td>3175.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.282126</td>\n",
              "      <td>0.305712</td>\n",
              "      <td>0.070847</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>306.000000</td>\n",
              "      <td>2370.00000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.0</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>4025.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.316538</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.076309</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>545.00000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>343.0</td>\n",
              "      <td>237.000000</td>\n",
              "      <td>3545.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054813</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.127057</td>\n",
              "      <td>18.602376</td>\n",
              "      <td>3.872943</td>\n",
              "      <td>0.254685</td>\n",
              "      <td>0.305712</td>\n",
              "      <td>0.290665</td>\n",
              "      <td>17.127057</td>\n",
              "      <td>120.508227</td>\n",
              "      <td>666.00000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>237.0</td>\n",
              "      <td>346.000000</td>\n",
              "      <td>236.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>55.127057</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>50.508227</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>12.254113</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054814</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.512993</td>\n",
              "      <td>24.922040</td>\n",
              "      <td>2.487007</td>\n",
              "      <td>0.273511</td>\n",
              "      <td>0.323033</td>\n",
              "      <td>0.080605</td>\n",
              "      <td>20.948027</td>\n",
              "      <td>174.974013</td>\n",
              "      <td>1075.53898</td>\n",
              "      <td>155.821463</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>310.051973</td>\n",
              "      <td>3973.512993</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>45.282483</td>\n",
              "      <td>50.795477</td>\n",
              "      <td>45.769490</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>6.230510</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054815</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>6.751592</td>\n",
              "      <td>8.745223</td>\n",
              "      <td>3.165605</td>\n",
              "      <td>0.202012</td>\n",
              "      <td>0.299325</td>\n",
              "      <td>0.999615</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>74.834395</td>\n",
              "      <td>295.00000</td>\n",
              "      <td>50.503185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.165605</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>477.0</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>1964.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>11.585987</td>\n",
              "      <td>11.254777</td>\n",
              "      <td>26.089172</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>20.585987</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054816</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>13.349001</td>\n",
              "      <td>4.941833</td>\n",
              "      <td>0.319731</td>\n",
              "      <td>0.319792</td>\n",
              "      <td>0.990391</td>\n",
              "      <td>13.587250</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>946.00000</td>\n",
              "      <td>109.116334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.529083</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.290834</td>\n",
              "      <td>32.116334</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>441.0</td>\n",
              "      <td>432.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>36.174500</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>49.761750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054817</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>6.210935</td>\n",
              "      <td>15.734391</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.328592</td>\n",
              "      <td>0.305712</td>\n",
              "      <td>0.999968</td>\n",
              "      <td>25.839858</td>\n",
              "      <td>212.789065</td>\n",
              "      <td>1325.00000</td>\n",
              "      <td>158.894533</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.792947</td>\n",
              "      <td>20.265609</td>\n",
              "      <td>21.468781</td>\n",
              "      <td>1072.0</td>\n",
              "      <td>1103.000000</td>\n",
              "      <td>2136.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.316402</td>\n",
              "      <td>16.316402</td>\n",
              "      <td>18.785184</td>\n",
              "      <td>44.476544</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>14.789065</td>\n",
              "      <td>18.316402</td>\n",
              "      <td>10.316402</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6054818 rows × 48 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR      MONTH  ...  WEATHER_DELAY_is_missing  OUTCOME\n",
              "0        2015.0   4.000000  ...                       1.0        0\n",
              "1        2015.0   7.000000  ...                       1.0        0\n",
              "2        2015.0   5.000000  ...                       0.0        1\n",
              "3        2015.0  11.000000  ...                       1.0        0\n",
              "4        2015.0   8.000000  ...                       1.0        0\n",
              "...         ...        ...  ...                       ...      ...\n",
              "6054813  2015.0   8.127057  ...                       1.0        1\n",
              "6054814  2015.0   1.512993  ...                       1.0        1\n",
              "6054815  2015.0   6.751592  ...                       0.0        1\n",
              "6054816  2015.0   3.000000  ...                       0.0        1\n",
              "6054817  2015.0   6.210935  ...                       0.0        1\n",
              "\n",
              "[6054818 rows x 48 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vvUpEEFbZGZ9",
        "outputId": "979d7915-4ee2-40e1-83a2-7d31bc9da655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "test_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>0.261397</td>\n",
              "      <td>0.277054</td>\n",
              "      <td>0.889772</td>\n",
              "      <td>23.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>930</td>\n",
              "      <td>124.0</td>\n",
              "      <td>0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57</td>\n",
              "      <td>15</td>\n",
              "      <td>3078</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>21</td>\n",
              "      <td>59</td>\n",
              "      <td>35</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.276077</td>\n",
              "      <td>0.306426</td>\n",
              "      <td>0.160310</td>\n",
              "      <td>14.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>612</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "      <td>65</td>\n",
              "      <td>1082</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>39</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.254685</td>\n",
              "      <td>0.353796</td>\n",
              "      <td>0.082088</td>\n",
              "      <td>24.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>152</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>237</td>\n",
              "      <td>386</td>\n",
              "      <td>277</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>52</td>\n",
              "      <td>13</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>0.319731</td>\n",
              "      <td>0.283453</td>\n",
              "      <td>0.996226</td>\n",
              "      <td>16.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>550</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>21</td>\n",
              "      <td>91</td>\n",
              "      <td>1380</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>57</td>\n",
              "      <td>9</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0.282126</td>\n",
              "      <td>0.287523</td>\n",
              "      <td>0.113494</td>\n",
              "      <td>8.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>1050</td>\n",
              "      <td>129.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1301</td>\n",
              "      <td>1305</td>\n",
              "      <td>4029</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>20</td>\n",
              "      <td>28</td>\n",
              "      <td>30</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428430</th>\n",
              "      <td>2015</td>\n",
              "      <td>11</td>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>0.308508</td>\n",
              "      <td>0.284717</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>1464</td>\n",
              "      <td>167.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85</td>\n",
              "      <td>21</td>\n",
              "      <td>4210</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "      <td>49</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428431</th>\n",
              "      <td>2015</td>\n",
              "      <td>10</td>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>0.201649</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.975365</td>\n",
              "      <td>50.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>813</td>\n",
              "      <td>99.0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>250</td>\n",
              "      <td>237</td>\n",
              "      <td>547</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>17</td>\n",
              "      <td>55</td>\n",
              "      <td>21</td>\n",
              "      <td>34</td>\n",
              "      <td>15</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428432</th>\n",
              "      <td>2015</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "      <td>0.318843</td>\n",
              "      <td>0.288808</td>\n",
              "      <td>0.099772</td>\n",
              "      <td>9.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>255</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1159</td>\n",
              "      <td>1183</td>\n",
              "      <td>2431</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>32</td>\n",
              "      <td>35</td>\n",
              "      <td>44</td>\n",
              "      <td>16</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428433</th>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>0.282422</td>\n",
              "      <td>0.358423</td>\n",
              "      <td>0.063157</td>\n",
              "      <td>10.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>764</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>410</td>\n",
              "      <td>495</td>\n",
              "      <td>432</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>35</td>\n",
              "      <td>47</td>\n",
              "      <td>13</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428434</th>\n",
              "      <td>2015</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0.231242</td>\n",
              "      <td>0.268731</td>\n",
              "      <td>0.113494</td>\n",
              "      <td>15.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>468</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1239</td>\n",
              "      <td>1278</td>\n",
              "      <td>610</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1428435 rows × 48 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         YEAR  MONTH  ...  WEATHER_DELAY_is_missing  OUTCOME\n",
              "0        2015      8  ...                         0        1\n",
              "1        2015     11  ...                         1        0\n",
              "2        2015      1  ...                         1        0\n",
              "3        2015      3  ...                         0        1\n",
              "4        2015      6  ...                         1        0\n",
              "...       ...    ...  ...                       ...      ...\n",
              "1428430  2015     11  ...                         0        1\n",
              "1428431  2015     10  ...                         0        1\n",
              "1428432  2015      4  ...                         1        0\n",
              "1428433  2015     12  ...                         1        0\n",
              "1428434  2015      4  ...                         1        1\n",
              "\n",
              "[1428435 rows x 48 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aigROTKhFYB6",
        "colab": {}
      },
      "source": [
        "Y_train=pd.DataFrame(train_data['OUTCOME'])\n",
        "X_train=train_data.drop(\"OUTCOME\",axis=1)\n",
        "\n",
        "Y_test=pd.DataFrame(test_data['OUTCOME'])\n",
        "X_test=test_data.drop(\"OUTCOME\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T6ZfhIrJFoAo",
        "outputId": "1511cce1-bd80-4420-ea53-e4f7d445f72f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.308508</td>\n",
              "      <td>0.341235</td>\n",
              "      <td>0.082088</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>337.00000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1226.0</td>\n",
              "      <td>1219.000000</td>\n",
              "      <td>4225.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.304283</td>\n",
              "      <td>0.294836</td>\n",
              "      <td>0.130962</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>480.00000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1309.0</td>\n",
              "      <td>1302.000000</td>\n",
              "      <td>4446.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.257698</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.998464</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>425.00000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1282.0</td>\n",
              "      <td>1232.000000</td>\n",
              "      <td>3175.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.282126</td>\n",
              "      <td>0.305712</td>\n",
              "      <td>0.070847</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>306.000000</td>\n",
              "      <td>2370.00000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.0</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>4025.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.316538</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.076309</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>545.00000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>343.0</td>\n",
              "      <td>237.000000</td>\n",
              "      <td>3545.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054813</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.127057</td>\n",
              "      <td>18.602376</td>\n",
              "      <td>3.872943</td>\n",
              "      <td>0.254685</td>\n",
              "      <td>0.305712</td>\n",
              "      <td>0.290665</td>\n",
              "      <td>17.127057</td>\n",
              "      <td>120.508227</td>\n",
              "      <td>666.00000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>237.0</td>\n",
              "      <td>346.000000</td>\n",
              "      <td>236.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>55.127057</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>50.508227</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>12.254113</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054814</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.512993</td>\n",
              "      <td>24.922040</td>\n",
              "      <td>2.487007</td>\n",
              "      <td>0.273511</td>\n",
              "      <td>0.323033</td>\n",
              "      <td>0.080605</td>\n",
              "      <td>20.948027</td>\n",
              "      <td>174.974013</td>\n",
              "      <td>1075.53898</td>\n",
              "      <td>155.821463</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>310.051973</td>\n",
              "      <td>3973.512993</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>45.282483</td>\n",
              "      <td>50.795477</td>\n",
              "      <td>45.769490</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>6.230510</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054815</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>6.751592</td>\n",
              "      <td>8.745223</td>\n",
              "      <td>3.165605</td>\n",
              "      <td>0.202012</td>\n",
              "      <td>0.299325</td>\n",
              "      <td>0.999615</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>74.834395</td>\n",
              "      <td>295.00000</td>\n",
              "      <td>50.503185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.165605</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>477.0</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>1964.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>11.585987</td>\n",
              "      <td>11.254777</td>\n",
              "      <td>26.089172</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>20.585987</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054816</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>13.349001</td>\n",
              "      <td>4.941833</td>\n",
              "      <td>0.319731</td>\n",
              "      <td>0.319792</td>\n",
              "      <td>0.990391</td>\n",
              "      <td>13.587250</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>946.00000</td>\n",
              "      <td>109.116334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.529083</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.290834</td>\n",
              "      <td>32.116334</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>441.0</td>\n",
              "      <td>432.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>36.174500</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>49.761750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054817</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>6.210935</td>\n",
              "      <td>15.734391</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.328592</td>\n",
              "      <td>0.305712</td>\n",
              "      <td>0.999968</td>\n",
              "      <td>25.839858</td>\n",
              "      <td>212.789065</td>\n",
              "      <td>1325.00000</td>\n",
              "      <td>158.894533</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.792947</td>\n",
              "      <td>20.265609</td>\n",
              "      <td>21.468781</td>\n",
              "      <td>1072.0</td>\n",
              "      <td>1103.000000</td>\n",
              "      <td>2136.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.316402</td>\n",
              "      <td>16.316402</td>\n",
              "      <td>18.785184</td>\n",
              "      <td>44.476544</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>14.789065</td>\n",
              "      <td>18.316402</td>\n",
              "      <td>10.316402</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6054818 rows × 47 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR  ...  WEATHER_DELAY_is_missing\n",
              "0        2015.0  ...                       1.0\n",
              "1        2015.0  ...                       1.0\n",
              "2        2015.0  ...                       0.0\n",
              "3        2015.0  ...                       1.0\n",
              "4        2015.0  ...                       1.0\n",
              "...         ...  ...                       ...\n",
              "6054813  2015.0  ...                       1.0\n",
              "6054814  2015.0  ...                       1.0\n",
              "6054815  2015.0  ...                       0.0\n",
              "6054816  2015.0  ...                       0.0\n",
              "6054817  2015.0  ...                       0.0\n",
              "\n",
              "[6054818 rows x 47 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RIeo9LwFZl6W",
        "outputId": "fe542512-20b4-4c7e-8925-23a6a2f380f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_train[:4285507]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.308508</td>\n",
              "      <td>0.341235</td>\n",
              "      <td>0.082088</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>80.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1226.0</td>\n",
              "      <td>1219.0</td>\n",
              "      <td>4225.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>30.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.304283</td>\n",
              "      <td>0.294836</td>\n",
              "      <td>0.130962</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>85.0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1309.0</td>\n",
              "      <td>1302.0</td>\n",
              "      <td>4446.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.257698</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.998464</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>90.0</td>\n",
              "      <td>425.0</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1282.0</td>\n",
              "      <td>1232.0</td>\n",
              "      <td>3175.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>20.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.282126</td>\n",
              "      <td>0.305712</td>\n",
              "      <td>0.070847</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>306.0</td>\n",
              "      <td>2370.0</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>4025.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>35.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.316538</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.076309</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>120.0</td>\n",
              "      <td>545.0</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>343.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>3545.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4285502</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.276684</td>\n",
              "      <td>0.340097</td>\n",
              "      <td>0.130962</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1092.0</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1257.0</td>\n",
              "      <td>1268.0</td>\n",
              "      <td>1722.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4285503</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>22.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.254685</td>\n",
              "      <td>0.300638</td>\n",
              "      <td>0.082088</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>136.0</td>\n",
              "      <td>821.0</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>397.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>55.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4285504</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.298798</td>\n",
              "      <td>0.341235</td>\n",
              "      <td>0.070847</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>163.0</td>\n",
              "      <td>954.0</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1005.0</td>\n",
              "      <td>935.0</td>\n",
              "      <td>4154.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>55.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4285505</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.205637</td>\n",
              "      <td>0.313753</td>\n",
              "      <td>0.091677</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>52.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>636.0</td>\n",
              "      <td>637.0</td>\n",
              "      <td>2231.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4285506</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>6.212617</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.480307</td>\n",
              "      <td>0.248783</td>\n",
              "      <td>0.294836</td>\n",
              "      <td>0.127936</td>\n",
              "      <td>12.692924</td>\n",
              "      <td>75.0</td>\n",
              "      <td>368.0</td>\n",
              "      <td>62.173231</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1314.0</td>\n",
              "      <td>1302.0</td>\n",
              "      <td>4688.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.133845</td>\n",
              "      <td>10.133845</td>\n",
              "      <td>10.960614</td>\n",
              "      <td>23.826769</td>\n",
              "      <td>25.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10.133845</td>\n",
              "      <td>36.519693</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4285507 rows × 47 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR  ...  WEATHER_DELAY_is_missing\n",
              "0        2015.0  ...                       1.0\n",
              "1        2015.0  ...                       1.0\n",
              "2        2015.0  ...                       0.0\n",
              "3        2015.0  ...                       1.0\n",
              "4        2015.0  ...                       1.0\n",
              "...         ...  ...                       ...\n",
              "4285502  2015.0  ...                       1.0\n",
              "4285503  2015.0  ...                       1.0\n",
              "4285504  2015.0  ...                       0.0\n",
              "4285505  2015.0  ...                       1.0\n",
              "4285506  2015.0  ...                       1.0\n",
              "\n",
              "[4285507 rows x 47 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XDNQRu46FrIu",
        "outputId": "217bab1c-9936-4ed3-f179-d8d201d256b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "Y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054813</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054814</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054815</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054816</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054817</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6054818 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         OUTCOME\n",
              "0              0\n",
              "1              0\n",
              "2              1\n",
              "3              0\n",
              "4              0\n",
              "...          ...\n",
              "6054813        1\n",
              "6054814        1\n",
              "6054815        1\n",
              "6054816        1\n",
              "6054817        1\n",
              "\n",
              "[6054818 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B5vXc6IeFrS4",
        "outputId": "16ff99a5-6c69-44d0-cde5-e49e9ba7eaf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>0.261397</td>\n",
              "      <td>0.277054</td>\n",
              "      <td>0.889772</td>\n",
              "      <td>23.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>930</td>\n",
              "      <td>124.0</td>\n",
              "      <td>0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57</td>\n",
              "      <td>15</td>\n",
              "      <td>3078</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>21</td>\n",
              "      <td>59</td>\n",
              "      <td>35</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.276077</td>\n",
              "      <td>0.306426</td>\n",
              "      <td>0.160310</td>\n",
              "      <td>14.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>612</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "      <td>65</td>\n",
              "      <td>1082</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>39</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.254685</td>\n",
              "      <td>0.353796</td>\n",
              "      <td>0.082088</td>\n",
              "      <td>24.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>152</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>237</td>\n",
              "      <td>386</td>\n",
              "      <td>277</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>52</td>\n",
              "      <td>13</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>0.319731</td>\n",
              "      <td>0.283453</td>\n",
              "      <td>0.996226</td>\n",
              "      <td>16.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>550</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>21</td>\n",
              "      <td>91</td>\n",
              "      <td>1380</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>57</td>\n",
              "      <td>9</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0.282126</td>\n",
              "      <td>0.287523</td>\n",
              "      <td>0.113494</td>\n",
              "      <td>8.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>1050</td>\n",
              "      <td>129.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1301</td>\n",
              "      <td>1305</td>\n",
              "      <td>4029</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>20</td>\n",
              "      <td>28</td>\n",
              "      <td>30</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428430</th>\n",
              "      <td>2015</td>\n",
              "      <td>11</td>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>0.308508</td>\n",
              "      <td>0.284717</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>1464</td>\n",
              "      <td>167.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85</td>\n",
              "      <td>21</td>\n",
              "      <td>4210</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "      <td>49</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428431</th>\n",
              "      <td>2015</td>\n",
              "      <td>10</td>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>0.201649</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.975365</td>\n",
              "      <td>50.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>813</td>\n",
              "      <td>99.0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>250</td>\n",
              "      <td>237</td>\n",
              "      <td>547</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>17</td>\n",
              "      <td>55</td>\n",
              "      <td>21</td>\n",
              "      <td>34</td>\n",
              "      <td>15</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428432</th>\n",
              "      <td>2015</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "      <td>0.318843</td>\n",
              "      <td>0.288808</td>\n",
              "      <td>0.099772</td>\n",
              "      <td>9.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>255</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1159</td>\n",
              "      <td>1183</td>\n",
              "      <td>2431</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>32</td>\n",
              "      <td>35</td>\n",
              "      <td>44</td>\n",
              "      <td>16</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428433</th>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>0.282422</td>\n",
              "      <td>0.358423</td>\n",
              "      <td>0.063157</td>\n",
              "      <td>10.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>764</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>410</td>\n",
              "      <td>495</td>\n",
              "      <td>432</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>35</td>\n",
              "      <td>47</td>\n",
              "      <td>13</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428434</th>\n",
              "      <td>2015</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0.231242</td>\n",
              "      <td>0.268731</td>\n",
              "      <td>0.113494</td>\n",
              "      <td>15.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>468</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1239</td>\n",
              "      <td>1278</td>\n",
              "      <td>610</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1428435 rows × 47 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         YEAR  MONTH  ...  LATE_AIRCRAFT_DELAY_is_missing  WEATHER_DELAY_is_missing\n",
              "0        2015      8  ...                               0                         0\n",
              "1        2015     11  ...                               1                         1\n",
              "2        2015      1  ...                               1                         1\n",
              "3        2015      3  ...                               0                         0\n",
              "4        2015      6  ...                               1                         1\n",
              "...       ...    ...  ...                             ...                       ...\n",
              "1428430  2015     11  ...                               0                         0\n",
              "1428431  2015     10  ...                               0                         0\n",
              "1428432  2015      4  ...                               1                         1\n",
              "1428433  2015     12  ...                               1                         1\n",
              "1428434  2015      4  ...                               1                         1\n",
              "\n",
              "[1428435 rows x 47 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KrZdDvSZFrcm",
        "outputId": "3f196928-c9ce-4d7f-cd58-b11d1e4767b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428430</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428431</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428432</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428433</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428434</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1428435 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         OUTCOME\n",
              "0              1\n",
              "1              0\n",
              "2              0\n",
              "3              1\n",
              "4              0\n",
              "...          ...\n",
              "1428430        1\n",
              "1428431        1\n",
              "1428432        0\n",
              "1428433        0\n",
              "1428434        1\n",
              "\n",
              "[1428435 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FO3YyADUn0UN",
        "colab": {}
      },
      "source": [
        "####Unused as it would be used for regression problems\n",
        "from sklearn.feature_selection import SelectPercentile, f_regression                      \n",
        "Selector_f = SelectPercentile(f_regression, percentile=25)\n",
        "Selector_f.fit(X,y)\n",
        "for n,s in zip(Unhandled_data.feature_names,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s \" % (s,n))\n",
        "Selector_f.get_support(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SpVyYrOyGYoH",
        "outputId": "789eed14-ccd1-42b7-c4d6-6491c12ee407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "X_train.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT',\n",
              "       'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'SCHEDULED_TIME',\n",
              "       'DISTANCE', 'AIR_TIME', 'DIVERTED', 'AIR_SYSTEM_DELAY',\n",
              "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
              "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
              "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
              "       'AA', 'AS', 'B6', 'DL', 'EV', 'F9', 'HA', 'MQ', 'NK', 'OO', 'UA', 'US',\n",
              "       'VX', 'WN', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR',\n",
              "       'SCHEDULED_ARRIVAL_HOUR', 'DEPARTURE_TIME_MINUTE',\n",
              "       'SCHEDULED_DEPARTURE_MINUTE', 'SCHEDULED_ARRIVAL_MINUTE',\n",
              "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
              "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
              "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ubU8RqqzAvk",
        "colab_type": "code",
        "outputId": "a4f51284-070d-4ab8-c071-8377133fc413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=25)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 20994.57t for feature MONTH\n",
            "F-score: 465.26t for feature DAY\n",
            "F-score: 1357.67t for feature DAY_OF_WEEK\n",
            "F-score: 45887.35t for feature ORIGIN_AIRPORT\n",
            "F-score: 31786.85t for feature DESTINATION_AIRPORT\n",
            "F-score: 5060519.01t for feature DEPARTURE_DELAY\n",
            "F-score: 436147.33t for feature TAXI_OUT\n",
            "F-score: 30.21t for feature SCHEDULED_TIME\n",
            "F-score: 319.48t for feature DISTANCE\n",
            "F-score: 6958.08t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 394931.17t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 2366.62t for feature SECURITY_DELAY\n",
            "F-score: 274327.67t for feature AIRLINE_DELAY\n",
            "F-score: 507572.07t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 34800.73t for feature WEATHER_DELAY\n",
            "F-score: 8031.96t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 8412.68t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 11.39t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 216.02t for feature AA\n",
            "F-score: 2326.96t for feature AS\n",
            "F-score: 1905.15t for feature B6\n",
            "F-score: 32498.08t for feature DL\n",
            "F-score: 846.38t for feature EV\n",
            "F-score: 3963.47t for feature F9\n",
            "F-score: 355.71t for feature HA\n",
            "F-score: 621.28t for feature MQ\n",
            "F-score: 10689.09t for feature NK\n",
            "F-score: 489.94t for feature OO\n",
            "F-score: 396.72t for feature UA\n",
            "F-score: 476.43t for feature US\n",
            "F-score: 174.41t for feature VX\n",
            "F-score: 992.70t for feature WN\n",
            "F-score: 235595.84t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 143114.70t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 115483.34t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 4747.94t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 2509.46t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 2.40t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 237523.33t for feature WHEELS_OFF_HOUR\n",
            "F-score: 6690.01t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 5150156.46t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature WEATHER_DELAY_is_missing\n",
            "Index(['DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'DEPARTURE_TIME_HOUR', 'WHEELS_OFF_HOUR',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
            "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
            "       'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DMVewQKgHfpC",
        "outputId": "60d9769a-7700-4bbb-9cfc-67c32c8131d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=50)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 20994.57t for feature MONTH\n",
            "F-score: 465.26t for feature DAY\n",
            "F-score: 1357.67t for feature DAY_OF_WEEK\n",
            "F-score: 45887.35t for feature ORIGIN_AIRPORT\n",
            "F-score: 31786.85t for feature DESTINATION_AIRPORT\n",
            "F-score: 5060519.01t for feature DEPARTURE_DELAY\n",
            "F-score: 436147.33t for feature TAXI_OUT\n",
            "F-score: 30.21t for feature SCHEDULED_TIME\n",
            "F-score: 319.48t for feature DISTANCE\n",
            "F-score: 6958.08t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 394931.17t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 2366.62t for feature SECURITY_DELAY\n",
            "F-score: 274327.67t for feature AIRLINE_DELAY\n",
            "F-score: 507572.07t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 34800.73t for feature WEATHER_DELAY\n",
            "F-score: 8031.96t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 8412.68t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 11.39t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 216.02t for feature AA\n",
            "F-score: 2326.96t for feature AS\n",
            "F-score: 1905.15t for feature B6\n",
            "F-score: 32498.08t for feature DL\n",
            "F-score: 846.38t for feature EV\n",
            "F-score: 3963.47t for feature F9\n",
            "F-score: 355.71t for feature HA\n",
            "F-score: 621.28t for feature MQ\n",
            "F-score: 10689.09t for feature NK\n",
            "F-score: 489.94t for feature OO\n",
            "F-score: 396.72t for feature UA\n",
            "F-score: 476.43t for feature US\n",
            "F-score: 174.41t for feature VX\n",
            "F-score: 992.70t for feature WN\n",
            "F-score: 235595.84t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 143114.70t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 115483.34t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 4747.94t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 2509.46t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 2.40t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 237523.33t for feature WHEELS_OFF_HOUR\n",
            "F-score: 6690.01t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 5150156.46t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature WEATHER_DELAY_is_missing\n",
            "Index(['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
            "       'TAXI_OUT', 'AIR_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'DL', 'NK', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
            "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
            "       'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TyOUNz2dgJAq",
        "outputId": "482c14e5-ec82-4f80-b8b6-d633428f8f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=75)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 20994.57t for feature MONTH\n",
            "F-score: 465.26t for feature DAY\n",
            "F-score: 1357.67t for feature DAY_OF_WEEK\n",
            "F-score: 45887.35t for feature ORIGIN_AIRPORT\n",
            "F-score: 31786.85t for feature DESTINATION_AIRPORT\n",
            "F-score: 5060519.01t for feature DEPARTURE_DELAY\n",
            "F-score: 436147.33t for feature TAXI_OUT\n",
            "F-score: 30.21t for feature SCHEDULED_TIME\n",
            "F-score: 319.48t for feature DISTANCE\n",
            "F-score: 6958.08t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 394931.17t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 2366.62t for feature SECURITY_DELAY\n",
            "F-score: 274327.67t for feature AIRLINE_DELAY\n",
            "F-score: 507572.07t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 34800.73t for feature WEATHER_DELAY\n",
            "F-score: 8031.96t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 8412.68t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 11.39t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 216.02t for feature AA\n",
            "F-score: 2326.96t for feature AS\n",
            "F-score: 1905.15t for feature B6\n",
            "F-score: 32498.08t for feature DL\n",
            "F-score: 846.38t for feature EV\n",
            "F-score: 3963.47t for feature F9\n",
            "F-score: 355.71t for feature HA\n",
            "F-score: 621.28t for feature MQ\n",
            "F-score: 10689.09t for feature NK\n",
            "F-score: 489.94t for feature OO\n",
            "F-score: 396.72t for feature UA\n",
            "F-score: 476.43t for feature US\n",
            "F-score: 174.41t for feature VX\n",
            "F-score: 992.70t for feature WN\n",
            "F-score: 235595.84t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 143114.70t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 115483.34t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 4747.94t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 2509.46t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 2.40t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 237523.33t for feature WHEELS_OFF_HOUR\n",
            "F-score: 6690.01t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 5150156.46t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature WEATHER_DELAY_is_missing\n",
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'AS', 'B6', 'DL', 'EV', 'F9', 'MQ', 'NK',\n",
            "       'OO', 'WN', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR',\n",
            "       'SCHEDULED_ARRIVAL_HOUR', 'DEPARTURE_TIME_MINUTE',\n",
            "       'SCHEDULED_DEPARTURE_MINUTE', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
            "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
            "       'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H3DVM-Qtu-Fo",
        "outputId": "e494dde8-9894-4412-8d7e-968e9be856aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=25)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 35026.84t for feature MONTH \n",
            "F-score: 2123.78t for feature DAY \n",
            "F-score: 1232.63t for feature DAY_OF_WEEK \n",
            "F-score: 190.28t for feature ORIGIN_AIRPORT \n",
            "F-score: 92.66t for feature DESTINATION_AIRPORT \n",
            "F-score: 940956.15t for feature DEPARTURE_DELAY \n",
            "F-score: 2344154.23t for feature TAXI_OUT \n",
            "F-score: 1208.02t for feature SCHEDULED_TIME \n",
            "F-score: 143425.28t for feature DISTANCE \n",
            "F-score: 321832.48t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 24114100.87t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 113239.16t for feature SECURITY_DELAY \n",
            "F-score: 34816756.63t for feature AIRLINE_DELAY \n",
            "F-score: 43592722.61t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 5045192.67t for feature WEATHER_DELAY \n",
            "F-score: 2340246.60t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 2452913.37t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 8882.95t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 189.26t for feature AA \n",
            "F-score: 2258.94t for feature AS \n",
            "F-score: 1813.79t for feature B6 \n",
            "F-score: 27740.16t for feature DL \n",
            "F-score: 762.97t for feature EV \n",
            "F-score: 3892.20t for feature F9 \n",
            "F-score: 351.08t for feature HA \n",
            "F-score: 590.27t for feature MQ \n",
            "F-score: 10425.18t for feature NK \n",
            "F-score: 439.82t for feature OO \n",
            "F-score: 361.05t for feature UA \n",
            "F-score: 459.79t for feature US \n",
            "F-score: 172.41t for feature VX \n",
            "F-score: 774.31t for feature WN \n",
            "F-score: 406109.74t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 232819.79t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 188495.14t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 49159.15t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 30271.30t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 25.49t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 403800.18t for feature WHEELS_OFF_HOUR \n",
            "F-score: 66352.63t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 832561.49t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 832561.49t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 832561.49t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 832561.49t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 832561.49t for feature WEATHER_DELAY_is_missing \n",
            "Index(['DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iZMAvNE7E9NS",
        "outputId": "89cf3f7b-b547-4ad8-86fc-3a42b120cb88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=50)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 35026.84t for feature MONTH \n",
            "F-score: 2123.78t for feature DAY \n",
            "F-score: 1232.63t for feature DAY_OF_WEEK \n",
            "F-score: 190.28t for feature ORIGIN_AIRPORT \n",
            "F-score: 92.66t for feature DESTINATION_AIRPORT \n",
            "F-score: 940956.15t for feature DEPARTURE_DELAY \n",
            "F-score: 2344154.23t for feature TAXI_OUT \n",
            "F-score: 1208.02t for feature SCHEDULED_TIME \n",
            "F-score: 143425.28t for feature DISTANCE \n",
            "F-score: 321832.48t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 24114100.87t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 113239.16t for feature SECURITY_DELAY \n",
            "F-score: 34816756.63t for feature AIRLINE_DELAY \n",
            "F-score: 43592722.61t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 5045192.67t for feature WEATHER_DELAY \n",
            "F-score: 2340246.60t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 2452913.37t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 8882.95t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 189.26t for feature AA \n",
            "F-score: 2258.94t for feature AS \n",
            "F-score: 1813.79t for feature B6 \n",
            "F-score: 27740.16t for feature DL \n",
            "F-score: 762.97t for feature EV \n",
            "F-score: 3892.20t for feature F9 \n",
            "F-score: 351.08t for feature HA \n",
            "F-score: 590.27t for feature MQ \n",
            "F-score: 10425.18t for feature NK \n",
            "F-score: 439.82t for feature OO \n",
            "F-score: 361.05t for feature UA \n",
            "F-score: 459.79t for feature US \n",
            "F-score: 172.41t for feature VX \n",
            "F-score: 774.31t for feature WN \n",
            "F-score: 406109.74t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 232819.79t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 188495.14t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 49159.15t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 30271.30t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 25.49t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 403800.18t for feature WHEELS_OFF_HOUR \n",
            "F-score: 66352.63t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 832561.49t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 832561.49t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 832561.49t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 832561.49t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 832561.49t for feature WEATHER_DELAY_is_missing \n",
            "Index(['MONTH', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'AIR_TIME',\n",
            "       'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR',\n",
            "       'DEPARTURE_TIME_MINUTE', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
            "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
            "       'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5E3V06WmE_4l",
        "outputId": "8e141de8-ccee-4f42-a527-0feb9902801a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=75)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 35026.84t for feature MONTH \n",
            "F-score: 2123.78t for feature DAY \n",
            "F-score: 1232.63t for feature DAY_OF_WEEK \n",
            "F-score: 190.28t for feature ORIGIN_AIRPORT \n",
            "F-score: 92.66t for feature DESTINATION_AIRPORT \n",
            "F-score: 940956.15t for feature DEPARTURE_DELAY \n",
            "F-score: 2344154.23t for feature TAXI_OUT \n",
            "F-score: 1208.02t for feature SCHEDULED_TIME \n",
            "F-score: 143425.28t for feature DISTANCE \n",
            "F-score: 321832.48t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 24114100.87t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 113239.16t for feature SECURITY_DELAY \n",
            "F-score: 34816756.63t for feature AIRLINE_DELAY \n",
            "F-score: 43592722.61t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 5045192.67t for feature WEATHER_DELAY \n",
            "F-score: 2340246.60t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 2452913.37t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 8882.95t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 189.26t for feature AA \n",
            "F-score: 2258.94t for feature AS \n",
            "F-score: 1813.79t for feature B6 \n",
            "F-score: 27740.16t for feature DL \n",
            "F-score: 762.97t for feature EV \n",
            "F-score: 3892.20t for feature F9 \n",
            "F-score: 351.08t for feature HA \n",
            "F-score: 590.27t for feature MQ \n",
            "F-score: 10425.18t for feature NK \n",
            "F-score: 439.82t for feature OO \n",
            "F-score: 361.05t for feature UA \n",
            "F-score: 459.79t for feature US \n",
            "F-score: 172.41t for feature VX \n",
            "F-score: 774.31t for feature WN \n",
            "F-score: 406109.74t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 232819.79t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 188495.14t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 49159.15t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 30271.30t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 25.49t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 403800.18t for feature WHEELS_OFF_HOUR \n",
            "F-score: 66352.63t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 832561.49t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 832561.49t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 832561.49t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 832561.49t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 832561.49t for feature WEATHER_DELAY_is_missing \n",
            "Index(['MONTH', 'DAY', 'DAY_OF_WEEK', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'SCHEDULED_TIME', 'DISTANCE', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
            "       'AS', 'B6', 'DL', 'EV', 'F9', 'NK', 'WN', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR',\n",
            "       'DEPARTURE_TIME_MINUTE', 'SCHEDULED_DEPARTURE_MINUTE',\n",
            "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
            "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nnPzt_pvDJs6",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "val_df, test_df = train_test_split(test_data, test_size=0.333, random_state=0)\n",
        "\n",
        "#Y_train=pd.DataFrame(train_data['OUTCOME'])\n",
        "#X_train=train_data.drop(\"OUTCOME\",axis=1)\n",
        "\n",
        "Y_test=pd.DataFrame(test_df['OUTCOME'])\n",
        "X_test=test_df.drop(\"OUTCOME\",axis=1)\n",
        "\n",
        "Y_valid=pd.DataFrame(val_df['OUTCOME'])\n",
        "X_valid=val_df.drop(\"OUTCOME\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s_vLx-nobFzs",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer,accuracy_score,roc_auc_score\n",
        "from sklearn import metrics\n",
        "\n",
        "def cross_validation(model,X,y):\n",
        "  scores = cross_validate(model, X, y, scoring={'accuracy':make_scorer(accuracy_score),'roc_auc':make_scorer(roc_auc_score)},cv=5)\n",
        "  print(\"Cross-validated scores:\", scores)\n",
        "  print(\"cross for accuracy\",scores['test_accuracy'])\n",
        "  print(\"cross for roc-auc\",scores['test_roc_auc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZIBZy8h6bUmh",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "def report(Y_test,pred):\n",
        "  score1=metrics.roc_auc_score(Y_test,pred)\n",
        "  score2=metrics.accuracy_score(Y_test,pred)\n",
        "\n",
        "  print(f\"Test ROC AUC score: {score1}\")\n",
        "  print(f\"Test accuracy score: {score2}\")\n",
        "  print(\"Confusion matrix is \",metrics.confusion_matrix(Y_test,pred))\n",
        "  print(\"Classification report is \\n\",metrics.classification_report(Y_test,pred))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "REAFrlKudcHT",
        "colab": {}
      },
      "source": [
        "from math import log\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def calculate_aic(n, mse, num_params):\n",
        "\taic = n * log(mse) + 2 * num_params\n",
        "\treturn aic\n",
        "\n",
        "def calculate_bic(n, mse, num_params):\n",
        "\tbic = n * log(mse) + num_params * log(n)\n",
        "\treturn bic\n",
        "  \n",
        "def aic_and_bic(Y_test,pred,num_params):\n",
        "  mse=mean_squared_error(Y_test,pred)\n",
        "  print(pred)\n",
        "  print('Number of parameters: %d' % (num_params))\n",
        "  aic=calculate_aic(len(Y_train), mse, num_params)\n",
        "  print('AIC: %.3f' % aic)\n",
        "  bic = calculate_bic(len(y), mse, num_params)\n",
        "  print('BIC: %.3f' % bic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0jLcuAH-cSKo",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.svm import *\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iePhsaLZ50Im",
        "colab_type": "code",
        "outputId": "e252d9a9-e01f-4541-d8af-ca95843159ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "cols=['MONTH','ORIGIN_AIRPORT','DESTINATION_AIRPORT','DEPARTURE_DELAY','TAXI_OUT','DISTANCE','SCHEDULED_TIME',\n",
        "'AIR_SYSTEM_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY','SECURITY_DELAY','AIRLINE_ORIGIN_AIRPORT','AIRLINE_DESTINATION_AIRPORT',\n",
        "'DEPARTURE_TIME_HOUR','WHEELS_OFF_MINUTE','SCHEDULED_DEPARTURE_HOUR','SCHEDULED_ARRIVAL_HOUR','WHEELS_OFF_HOUR',\n",
        "'AIR_SYSTEM_DELAY_is_missing','SECURITY_DELAY_is_missing','AIRLINE_DELAY_is_missing','LATE_AIRCRAFT_DELAY_is_missing','WEATHER_DELAY_is_missing']\n",
        "print(cols)\n",
        "print(len(cols))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'WHEELS_OFF_MINUTE', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n",
            "24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Qio4-8g6aQJ",
        "outputId": "49ca6d86-2bfc-4b81-fd5e-fb26759e3aa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "selected_X_train=X_train[cols]\n",
        "print(selected_X_train)\n",
        "\n",
        "lgbmclassifier=LGBMClassifier()\n",
        "selector = RFECV(estimator=lgbmclassifier, cv=5,scoring='accuracy',n_jobs=1)\n",
        "selector.fit(selected_X_train,Y_train)\n",
        "print(\"Optimal number of features: %d\" % selector.n_features_)\n",
        "print(selected_X_train.columns[selector.support_])\n",
        "print(selector.ranking_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             MONTH  ...  WEATHER_DELAY_is_missing\n",
            "0         4.000000  ...                       1.0\n",
            "1         7.000000  ...                       1.0\n",
            "2         5.000000  ...                       0.0\n",
            "3        11.000000  ...                       1.0\n",
            "4         8.000000  ...                       1.0\n",
            "...            ...  ...                       ...\n",
            "6054813   8.127057  ...                       1.0\n",
            "6054814   1.512993  ...                       1.0\n",
            "6054815   6.751592  ...                       0.0\n",
            "6054816   3.000000  ...                       0.0\n",
            "6054817   6.210935  ...                       0.0\n",
            "\n",
            "[6054818 rows x 24 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimal number of features: 13\n",
            "Index(['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
            "       'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE_HOUR',\n",
            "       'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR',\n",
            "       'AIR_SYSTEM_DELAY_is_missing'],\n",
            "      dtype='object')\n",
            "[ 1  1  1  1  1  1  1  4  6  8 10 12  1  1  2  1  1  1  3  1  5  7  9 11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "raZFbf_bIrHa",
        "outputId": "7bb25f49-4095-4485-c992-c99538e5d0af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "selected_X_train=X_train[cols]\n",
        "print(selected_X_train)\n",
        "\n",
        "model = LGBMClassifier()\n",
        "model.fit(selected_X_train,Y_train)\n",
        "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "#plot graph of feature importances for better visualization\n",
        "feat_importances = pd.Series(model.feature_importances_, index=selected_X_train.columns)\n",
        "feat_importances.nlargest(24).plot(kind='barh')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             MONTH  ...  WEATHER_DELAY_is_missing\n",
            "0         4.000000  ...                       1.0\n",
            "1         7.000000  ...                       1.0\n",
            "2         5.000000  ...                       0.0\n",
            "3        11.000000  ...                       1.0\n",
            "4         8.000000  ...                       1.0\n",
            "...            ...  ...                       ...\n",
            "6054813   8.127057  ...                       1.0\n",
            "6054814   1.512993  ...                       1.0\n",
            "6054815   6.751592  ...                       0.0\n",
            "6054816   3.000000  ...                       0.0\n",
            "6054817   6.210935  ...                       0.0\n",
            "\n",
            "[6054818 rows x 24 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[238 213  42 704 747 284 360   0   0   0   0   0 196  72  10  12  28  14\n",
            "   0  80   0   0   0   0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEoNAdnTL873",
        "colab_type": "code",
        "outputId": "ff03bcf3-21a1-440a-f247-c36f964aa541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cols_after_removing_recursive=['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
        "       'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT',\n",
        "       'AIRLINE_DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE_HOUR',\n",
        "       'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR',\n",
        "       'AIR_SYSTEM_DELAY_is_missing']\n",
        "print(len(cols_after_removing_recursive))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5pi4gQReHbqt",
        "outputId": "c1150a4d-2c49-4fa1-c709-955bdbe9366a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpBernoulliNBModel():\n",
        "  model = BernoulliNB()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpBernoulliNBModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8176742955101963\n",
            "Test accuracy score: 0.8929310749176547\n",
            "Confusion matrix is  [[1009018       0]\n",
            " [ 152941  266476]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93   1009018\n",
            "           1       1.00      0.64      0.78    419417\n",
            "\n",
            "    accuracy                           0.89   1428435\n",
            "   macro avg       0.93      0.82      0.85   1428435\n",
            "weighted avg       0.91      0.89      0.88   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([4.02533007, 2.54916596, 2.55393291, 2.55440617, 2.59539628]), 'score_time': array([0.74628329, 0.73334026, 0.73816514, 0.75022101, 0.73059821]), 'test_accuracy': array([0.89224958, 0.89253475, 0.89226873, 0.89243149, 0.89311053]), 'test_roc_auc': array([0.81649046, 0.81697576, 0.81652325, 0.81680045, 0.81795692])}\n",
            "cross for accuracy [0.89224958 0.89253475 0.89226873 0.89243149 0.89311053]\n",
            "cross for roc-auc [0.81649046 0.81697576 0.81652325 0.81680045 0.81795692]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y5T6_ef4OO_u",
        "outputId": "42f8f237-7925-40ae-9908-09e5360082f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpLinearSVCModel():\n",
        "  model = LinearSVC()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpLinearSVCModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8702226924092784\n",
            "Test accuracy score: 0.8776304137045088\n",
            "Confusion matrix is  [[896179 112839]\n",
            " [ 61958 357459]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.89      0.91   1009018\n",
            "           1       0.76      0.85      0.80    419417\n",
            "\n",
            "    accuracy                           0.88   1428435\n",
            "   macro avg       0.85      0.87      0.86   1428435\n",
            "weighted avg       0.88      0.88      0.88   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([3081.71970844, 3051.46147275, 2886.84516859, 2654.25043535,\n",
            "       2552.9044137 ]), 'score_time': array([0.54690695, 0.55531693, 0.58428001, 0.71781397, 0.70923042]), 'test_accuracy': array([0.87662639, 0.90151542, 0.89231336, 0.91299524, 0.73374327]), 'test_roc_auc': array([0.84201889, 0.83442459, 0.81856845, 0.87189416, 0.76420607])}\n",
            "cross for accuracy [0.87662639 0.90151542 0.89231336 0.91299524 0.73374327]\n",
            "cross for roc-auc [0.84201889 0.83442459 0.81856845 0.87189416 0.76420607]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Pfvps8ZPgE2",
        "outputId": "a21eddad-9038-4f87-ba9d-682cb16f5de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpLGBMClassifierModel():\n",
        "  model = LGBMClassifier(random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8835184663748327\n",
            "Test accuracy score: 0.9192360870463129\n",
            "Confusion matrix is  [[978800  30218]\n",
            " [ 85148 334269]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94   1009018\n",
            "           1       0.92      0.80      0.85    419417\n",
            "\n",
            "    accuracy                           0.92   1428435\n",
            "   macro avg       0.92      0.88      0.90   1428435\n",
            "weighted avg       0.92      0.92      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([41.22812128, 40.24779701, 39.54788852, 39.78039384, 39.87078381]), 'score_time': array([3.31302762, 3.32302547, 3.34789038, 3.37988997, 3.29774284]), 'test_accuracy': array([0.9203335 , 0.92077008, 0.92059507, 0.92129774, 0.92163113]), 'test_roc_auc': array([0.87939089, 0.88030232, 0.87978335, 0.88089036, 0.88147384])}\n",
            "cross for accuracy [0.9203335  0.92077008 0.92059507 0.92129774 0.92163113]\n",
            "cross for roc-auc [0.87939089 0.88030232 0.87978335 0.88089036 0.88147384]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W-dq1z4DYbE7",
        "outputId": "0328fe72-2abd-4299-fef0-688518f60333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpDecisionTreeModel():\n",
        "  tree = DecisionTreeClassifier(random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  tree.fit(sel_X_train, Y_train)\n",
        "  pred=tree.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(tree,X,y)\n",
        "\n",
        "runexpDecisionTreeModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n",
            "predictions are  [0 1 0 ... 0 0 1]\n",
            "Test ROC AUC score: 0.8534604689864477\n",
            "Test accuracy score: 0.8752767155311781\n",
            "Confusion matrix is  [[304381  31424]\n",
            " [ 27903 111961]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.91      0.91    335805\n",
            "           1       0.78      0.80      0.79    139864\n",
            "\n",
            "    accuracy                           0.88    475669\n",
            "   macro avg       0.85      0.85      0.85    475669\n",
            "weighted avg       0.88      0.88      0.88    475669\n",
            "\n",
            "\n",
            "\n",
            "Cross-validated scores: {'fit_time': array([98.33280826, 98.03923869, 96.89853787, 98.87323689, 96.7072258 ]), 'score_time': array([0.79567885, 0.80918908, 0.79715633, 0.79890203, 0.79836798]), 'test_accuracy': array([0.87706396, 0.87722568, 0.8766859 , 0.87769196, 0.87768776]), 'test_roc_auc': array([0.85492068, 0.85549495, 0.85448066, 0.85580723, 0.85612326])}\n",
            "cross for accuracy [0.87706396 0.87722568 0.8766859  0.87769196 0.87768776]\n",
            "cross for roc-auc [0.85492068 0.85549495 0.85448066 0.85580723 0.85612326]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1T8qD_h5S9mU",
        "outputId": "9cd5a4f6-05a8-436f-a54c-56f19432fadc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpRandomForestModel():\n",
        "  forest = RandomForestClassifier(max_features=16,max_depth=25,min_samples_leaf=10,random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  forest.fit(sel_X_train, Y_train)\n",
        "  pred=forest.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)                                         #91.87\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(forest,X,y)\n",
        "\n",
        "runexpRandomForestModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8820867826754215\n",
            "Test accuracy score: 0.9205585133380237\n",
            "Confusion matrix is  [[984088  24930]\n",
            " [ 88547 330870]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95   1009018\n",
            "           1       0.93      0.79      0.85    419417\n",
            "\n",
            "    accuracy                           0.92   1428435\n",
            "   macro avg       0.92      0.88      0.90   1428435\n",
            "weighted avg       0.92      0.92      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([6110.38994956, 4488.80710149, 4275.5737865 , 4204.35399055,\n",
            "       4153.96794605]), 'score_time': array([41.55245614, 41.19122052, 39.72275329, 41.90458846, 40.24595284]), 'test_accuracy': array([0.92165833, 0.92206779, 0.92205903, 0.92246593, 0.92285358]), 'test_roc_auc': array([0.88105758, 0.88187055, 0.8817018 , 0.88237476, 0.88290781])}\n",
            "cross for accuracy [0.92165833 0.92206779 0.92205903 0.92246593 0.92285358]\n",
            "cross for roc-auc [0.88105758 0.88187055 0.8817018  0.88237476 0.88290781]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "guOphXVvu15j",
        "outputId": "b6095b5e-7499-4bab-c256-0fa748a3c3ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLogisticRegressionModel():\n",
        "  lrmodel=LogisticRegression()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  lrmodel.fit(sel_X_train, Y_train)\n",
        "  pred=lrmodel.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(lrmodel,X,y)\n",
        "  num_params = len(lrmodel.coef_) + 1\n",
        "  aic_and_bic(Y_test,pred,num_params)\n",
        "\n",
        "runLogisticRegressionModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [0 1 0 ... 0 0 1]\n",
            "Test ROC AUC score: 0.8296774206409845\n",
            "Test accuracy score: 0.8885107080764145\n",
            "Confusion matrix is  [[326571   9234]\n",
            " [ 43798  96066]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92    335805\n",
            "           1       0.91      0.69      0.78    139864\n",
            "\n",
            "    accuracy                           0.89    475669\n",
            "   macro avg       0.90      0.83      0.85    475669\n",
            "weighted avg       0.89      0.89      0.88    475669\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([67.50734687, 65.93810582, 66.96874094, 66.1269958 , 65.12360954]), 'score_time': array([0.41015744, 0.42351747, 0.41843605, 0.40717268, 0.41280127]), 'test_accuracy': array([0.8936544 , 0.89500911, 0.89364285, 0.89404716, 0.8939663 ]), 'test_roc_auc': array([0.82146836, 0.82712552, 0.82564117, 0.82180698, 0.82085378])}\n",
            "cross for accuracy [0.8936544  0.89500911 0.89364285 0.89404716 0.8939663 ]\n",
            "cross for roc-auc [0.82146836 0.82712552 0.82564117 0.82180698 0.82085378]\n",
            "[0 1 0 ... 0 0 1]\n",
            "Number of parameters: 2\n",
            "AIC: -13283217.569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c89c4cf15e04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0maic_and_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrunLogisticRegressionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-c89c4cf15e04>\u001b[0m in \u001b[0;36mrunLogisticRegressionModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mnum_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0maic_and_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mrunLogisticRegressionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-15c7f88bee80>\u001b[0m in \u001b[0;36maic_and_bic\u001b[0;34m(Y_test, pred, num_params)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0maic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalculate_aic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AIC: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mbic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BIC: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBxc3eE0YXL8",
        "colab_type": "code",
        "outputId": "d218e3c2-23c8-4191-ebb4-8aa7d7f8ee2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runXGBClassifierModel():\n",
        "  model=XGBClassifier()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runXGBClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[12:14:03] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8799539221752859\n",
            "Test accuracy score: 0.9069905175944303\n",
            "Confusion matrix is  [[953982  55036]\n",
            " [ 77822 341595]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93   1009018\n",
            "           1       0.86      0.81      0.84    419417\n",
            "\n",
            "    accuracy                           0.91   1428435\n",
            "   macro avg       0.89      0.88      0.89   1428435\n",
            "weighted avg       0.91      0.91      0.91   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[13:00:04] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[13:33:07] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[14:06:18] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[14:39:28] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[15:12:40] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
            "Cross-validated scores: {'fit_time': array([1982.48600912, 1986.70746088, 1986.53589177, 1987.457937  ,\n",
            "       1982.43312955]), 'score_time': array([3.77771521, 3.85807991, 3.84304357, 3.85526156, 3.86914086]), 'test_accuracy': array([0.91359997, 0.91408205, 0.91418706, 0.91419406, 0.91461583]), 'test_roc_auc': array([0.8665095 , 0.86698104, 0.86721075, 0.86698055, 0.86812215])}\n",
            "cross for accuracy [0.91359997 0.91408205 0.91418706 0.91419406 0.91461583]\n",
            "cross for roc-auc [0.8665095  0.86698104 0.86721075 0.86698055 0.86812215]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VEX6VSX0SbJT",
        "outputId": "fc44a228-a295-424f-e7d2-8c09c057b98f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(max_bin=175,num_leaves=150,lambda_l1=2,lambda_l2=2,max_depth=100)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8864658355968845\n",
            "Test accuracy score: 0.9229394407165884\n",
            "Confusion matrix is  [[983622  25396]\n",
            " [ 84680 334737]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95   1009018\n",
            "           1       0.93      0.80      0.86    419417\n",
            "\n",
            "    accuracy                           0.92   1428435\n",
            "   macro avg       0.93      0.89      0.90   1428435\n",
            "weighted avg       0.92      0.92      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([60.28556156, 58.70853829, 59.37966013, 59.14075065, 58.98669577]), 'score_time': array([4.36771607, 4.28731585, 4.35411382, 4.39645362, 4.26688361]), 'test_accuracy': array([0.92274514, 0.92301722, 0.92293759, 0.92366826, 0.92380564]), 'test_roc_auc': array([0.8837847 , 0.88449522, 0.88409949, 0.8850948 , 0.88547858])}\n",
            "cross for accuracy [0.92274514 0.92301722 0.92293759 0.92366826 0.92380564]\n",
            "cross for roc-auc [0.8837847  0.88449522 0.88409949 0.8850948  0.88547858]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E9wkWA2b1USV",
        "outputId": "18a12aee-b2d9-4987-abc5-25604d1a0aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(max_bin=150,num_leaves=150,lambda_l1=5,lambda_l2=5,max_depth=90,bagging_fraction=0.8)#decrease bagging_fraction\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8863051495392817\n",
            "Test accuracy score: 0.9228610332286733\n",
            "Confusion matrix is  [[983661  25357]\n",
            " [ 84831 334586]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95   1009018\n",
            "           1       0.93      0.80      0.86    419417\n",
            "\n",
            "    accuracy                           0.92   1428435\n",
            "   macro avg       0.93      0.89      0.90   1428435\n",
            "weighted avg       0.92      0.92      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([59.39565849, 59.75253558, 58.57243896, 58.77869701, 60.90981364]), 'score_time': array([4.42929626, 4.32503486, 4.49348521, 4.35506034, 4.42180252]), 'test_accuracy': array([0.92274339, 0.92305047, 0.92290084, 0.923509  , 0.92384327]), 'test_roc_auc': array([0.88380785, 0.88453791, 0.88411963, 0.88505175, 0.88558011])}\n",
            "cross for accuracy [0.92274339 0.92305047 0.92290084 0.923509   0.92384327]\n",
            "cross for roc-auc [0.88380785 0.88453791 0.88411963 0.88505175 0.88558011]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OQQEenwR-EHf",
        "outputId": "3b88bfe8-75a1-4684-83bf-7406926d3a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(learning_rate=0.2,max_bin=150,num_leaves=250,min_data_in_leaf=300,lambda_l1=4,lambda_l2=4,max_depth=80,bagging_fraction=0.7)#decrease bagging_fraction\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8896156328262435\n",
            "Test accuracy score: 0.9252370601392433\n",
            "Confusion matrix is  [[984717  24301]\n",
            " [ 82493 336924]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95   1009018\n",
            "           1       0.93      0.80      0.86    419417\n",
            "\n",
            "    accuracy                           0.93   1428435\n",
            "   macro avg       0.93      0.89      0.91   1428435\n",
            "weighted avg       0.93      0.93      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([67.17893696, 66.94291735, 65.40629935, 65.40760207, 64.98969841]), 'score_time': array([5.00798702, 5.02646971, 5.04435062, 5.04537511, 4.97464848]), 'test_accuracy': array([0.92467201, 0.92484083, 0.92466494, 0.92539649, 0.92560387]), 'test_roc_auc': array([0.88757584, 0.88820022, 0.88781038, 0.88874621, 0.88905413])}\n",
            "cross for accuracy [0.92467201 0.92484083 0.92466494 0.92539649 0.92560387]\n",
            "cross for roc-auc [0.88757584 0.88820022 0.88781038 0.88874621 0.88905413]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ixe9qVM6_pj5",
        "outputId": "b46eb36d-7db1-411c-a57e-0868a0f73355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'max_bin':(125,150),#               #'learning_rate':(0.2,0.3),\n",
        "     'feature_fraction':(0.6,0.7),\n",
        "     'num_leaves':(250,300),#\n",
        "     'min_data_in_leaf':(300,400),\n",
        "     'lambda_l1':(1,2),#--6                    #'lambda_l2':(2,4,6),     #'max_depth':(60,80,90),\n",
        "     'bagging_fraction':(0.4,0.5)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=3,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  6.0min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed:  9.1min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 17.3min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 18.5min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 19.9min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 20.7min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 21.4min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 22.5min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 24.2min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 24.3min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 25.4min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 26.6min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 27.2min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 28.5min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 29.4min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 30.6min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 32.5min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 33.0min\n",
            "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed: 34.2min\n",
            "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed: 35.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed: 36.3min\n",
            "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed: 37.0min\n",
            "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed: 38.4min\n",
            "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed: 38.7min\n",
            "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed: 40.1min\n",
            "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed: 42.0min\n",
            "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed: 42.1min\n",
            "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed: 42.3min\n",
            "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 44.9min\n",
            "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed: 45.2min\n",
            "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed: 45.3min\n",
            "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed: 47.7min\n",
            "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed: 48.5min\n",
            "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed: 48.7min\n",
            "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed: 50.5min\n",
            "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed: 51.4min\n",
            "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed: 52.0min\n",
            "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed: 53.5min\n",
            "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed: 54.7min\n",
            "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed: 54.9min\n",
            "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed: 56.2min\n",
            "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed: 57.5min\n",
            "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed: 58.1min\n",
            "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed: 59.7min\n",
            "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed: 60.4min\n",
            "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed: 61.0min\n",
            "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed: 62.6min\n",
            "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed: 63.2min\n",
            "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed: 64.2min\n",
            "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed: 65.8min\n",
            "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed: 66.5min\n",
            "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed: 67.0min\n",
            "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed: 68.6min\n",
            "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed: 69.3min\n",
            "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed: 70.0min\n",
            "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed: 71.9min\n",
            "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed: 72.5min\n",
            "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed: 73.1min\n",
            "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed: 74.3min\n",
            "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed: 75.8min\n",
            "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed: 76.3min\n",
            "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed: 77.3min\n",
            "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed: 78.9min\n",
            "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed: 79.2min\n",
            "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed: 80.2min\n",
            "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed: 82.1min\n",
            "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed: 82.4min\n",
            "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed: 83.2min\n",
            "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed: 85.2min\n",
            "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed: 85.7min\n",
            "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed: 85.9min\n",
            "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed: 88.0min\n",
            "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed: 88.7min\n",
            "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed: 89.3min\n",
            "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed: 91.3min\n",
            "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed: 92.3min\n",
            "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed: 94.2min\n",
            "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed: 94.7min\n",
            "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed: 95.5min\n",
            "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed: 97.3min\n",
            "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed: 97.6min\n",
            "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed: 98.3min\n",
            "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed: 100.2min\n",
            "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed: 100.3min\n",
            "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed: 101.7min\n",
            "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed: 103.1min\n",
            "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed: 103.3min\n",
            "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed: 104.6min\n",
            "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed: 106.1min\n",
            "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed: 106.2min\n",
            "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed: 107.7min\n",
            "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed: 108.7min\n",
            "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed: 109.5min\n",
            "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed: 110.6min\n",
            "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed: 111.6min\n",
            "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed: 112.4min\n",
            "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed: 114.1min\n",
            "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed: 114.8min\n",
            "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed: 114.9min\n",
            "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed: 116.9min\n",
            "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed: 117.6min\n",
            "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed: 117.9min\n",
            "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed: 120.0min\n",
            "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed: 120.7min\n",
            "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed: 120.9min\n",
            "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed: 122.5min\n",
            "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed: 123.8min\n",
            "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed: 123.9min\n",
            "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed: 125.4min\n",
            "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed: 126.7min\n",
            "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed: 127.1min\n",
            "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed: 127.9min\n",
            "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed: 129.5min\n",
            "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed: 130.1min\n",
            "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed: 131.0min\n",
            "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed: 132.7min\n",
            "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed: 132.8min\n",
            "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed: 133.5min\n",
            "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed: 135.6min\n",
            "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed: 136.0min\n",
            "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed: 136.8min\n",
            "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed: 139.2min\n",
            "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed: 141.7min\n",
            "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed: 142.0min\n",
            "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed: 142.2min\n",
            "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed: 145.3min\n",
            "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed: 147.5min\n",
            "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed: 148.2min\n",
            "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed: 148.8min\n",
            "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed: 150.8min\n",
            "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed: 151.2min\n",
            "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed: 151.6min\n",
            "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed: 153.7min\n",
            "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed: 154.1min\n",
            "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed: 155.1min\n",
            "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 156.8min\n",
            "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed: 156.9min\n",
            "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed: 158.3min\n",
            "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed: 159.7min\n",
            "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed: 159.9min\n",
            "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed: 161.6min\n",
            "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed: 162.8min\n",
            "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed: 163.0min\n",
            "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed: 164.7min\n",
            "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed: 165.7min\n",
            "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed: 166.1min\n",
            "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed: 168.0min\n",
            "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed: 168.9min\n",
            "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed: 169.4min\n",
            "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed: 170.8min\n",
            "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed: 171.8min\n",
            "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed: 172.5min\n",
            "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed: 174.2min\n",
            "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed: 177.0min\n",
            "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed: 177.8min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  6.0min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed:  9.1min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 17.3min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 18.5min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 19.9min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 20.7min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 21.4min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 22.5min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 24.2min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 24.3min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 25.4min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 26.6min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 27.2min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 28.5min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 29.4min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 30.6min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 32.5min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 33.0min\n",
            "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed: 34.2min\n",
            "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed: 35.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed: 36.3min\n",
            "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed: 37.0min\n",
            "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed: 38.4min\n",
            "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed: 38.7min\n",
            "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed: 40.1min\n",
            "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed: 42.0min\n",
            "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed: 42.1min\n",
            "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed: 42.3min\n",
            "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 44.9min\n",
            "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed: 45.2min\n",
            "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed: 45.3min\n",
            "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed: 47.7min\n",
            "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed: 48.5min\n",
            "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed: 48.7min\n",
            "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed: 50.5min\n",
            "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed: 51.4min\n",
            "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed: 52.0min\n",
            "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed: 53.5min\n",
            "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed: 54.7min\n",
            "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed: 54.9min\n",
            "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed: 56.2min\n",
            "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed: 57.5min\n",
            "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed: 58.1min\n",
            "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed: 59.7min\n",
            "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed: 60.4min\n",
            "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed: 61.0min\n",
            "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed: 62.6min\n",
            "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed: 63.2min\n",
            "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed: 64.2min\n",
            "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed: 65.8min\n",
            "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed: 66.5min\n",
            "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed: 67.0min\n",
            "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed: 68.6min\n",
            "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed: 69.3min\n",
            "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed: 70.0min\n",
            "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed: 71.9min\n",
            "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed: 72.5min\n",
            "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed: 73.1min\n",
            "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed: 74.3min\n",
            "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed: 75.8min\n",
            "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed: 76.3min\n",
            "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed: 77.3min\n",
            "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed: 78.9min\n",
            "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed: 79.2min\n",
            "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed: 80.2min\n",
            "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed: 82.1min\n",
            "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed: 82.4min\n",
            "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed: 83.2min\n",
            "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed: 85.2min\n",
            "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed: 85.7min\n",
            "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed: 85.9min\n",
            "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed: 88.0min\n",
            "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed: 88.7min\n",
            "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed: 89.3min\n",
            "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed: 91.3min\n",
            "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed: 92.3min\n",
            "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed: 94.2min\n",
            "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed: 94.7min\n",
            "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed: 95.5min\n",
            "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed: 97.3min\n",
            "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed: 97.6min\n",
            "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed: 98.3min\n",
            "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed: 100.2min\n",
            "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed: 100.3min\n",
            "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed: 101.7min\n",
            "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed: 103.1min\n",
            "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed: 103.3min\n",
            "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed: 104.6min\n",
            "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed: 106.1min\n",
            "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed: 106.2min\n",
            "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed: 107.7min\n",
            "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed: 108.7min\n",
            "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed: 109.5min\n",
            "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed: 110.6min\n",
            "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed: 111.6min\n",
            "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed: 112.4min\n",
            "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed: 114.1min\n",
            "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed: 114.8min\n",
            "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed: 114.9min\n",
            "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed: 116.9min\n",
            "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed: 117.6min\n",
            "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed: 117.9min\n",
            "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed: 120.0min\n",
            "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed: 120.7min\n",
            "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed: 120.9min\n",
            "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed: 122.5min\n",
            "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed: 123.8min\n",
            "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed: 123.9min\n",
            "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed: 125.4min\n",
            "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed: 126.7min\n",
            "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed: 127.1min\n",
            "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed: 127.9min\n",
            "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed: 129.5min\n",
            "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed: 130.1min\n",
            "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed: 131.0min\n",
            "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed: 132.7min\n",
            "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed: 132.8min\n",
            "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed: 133.5min\n",
            "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed: 135.6min\n",
            "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed: 136.0min\n",
            "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed: 136.8min\n",
            "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed: 139.2min\n",
            "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed: 141.7min\n",
            "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed: 142.0min\n",
            "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed: 142.2min\n",
            "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed: 145.3min\n",
            "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed: 147.5min\n",
            "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed: 148.2min\n",
            "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed: 148.8min\n",
            "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed: 150.8min\n",
            "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed: 151.2min\n",
            "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed: 151.6min\n",
            "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed: 153.7min\n",
            "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed: 154.1min\n",
            "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed: 155.1min\n",
            "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 156.8min\n",
            "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed: 156.9min\n",
            "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed: 158.3min\n",
            "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed: 159.7min\n",
            "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed: 159.9min\n",
            "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed: 161.6min\n",
            "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed: 162.8min\n",
            "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed: 163.0min\n",
            "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed: 164.7min\n",
            "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed: 165.7min\n",
            "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed: 166.1min\n",
            "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed: 168.0min\n",
            "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed: 168.9min\n",
            "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed: 169.4min\n",
            "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed: 170.8min\n",
            "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed: 171.8min\n",
            "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed: 172.5min\n",
            "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed: 174.2min\n",
            "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed: 177.0min\n",
            "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed: 177.8min\n",
            "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed: 178.6min\n",
            "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed: 178.6min\n",
            "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed: 180.3min\n",
            "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed: 180.3min\n",
            "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed: 181.1min\n",
            "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed: 181.1min\n",
            "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed: 181.4min\n",
            "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed: 181.4min\n",
            "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed: 183.1min\n",
            "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed: 183.1min\n",
            "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed: 184.1min\n",
            "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed: 184.1min\n",
            "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed: 184.5min\n",
            "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed: 184.5min\n",
            "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed: 186.1min\n",
            "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed: 186.1min\n",
            "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed: 187.2min\n",
            "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed: 187.2min\n",
            "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed: 187.5min\n",
            "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed: 187.5min\n",
            "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed: 189.1min\n",
            "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed: 189.1min\n",
            "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed: 190.1min\n",
            "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed: 190.1min\n",
            "[Parallel(n_jobs=3)]: Done 192 out of 192 | elapsed: 192.8min finished\n",
            "[Parallel(n_jobs=3)]: Done 192 out of 192 | elapsed: 192.8min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split',\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=90,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_state=None, reg_...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'bagging_fraction': (0.5, 0.6),\n",
            "                         'feature_fraction': (0.5, 0.6), 'lambda_l1': (2, 4),\n",
            "                         'max_bin': (100, 125), 'min_data_in_leaf': (200, 300),\n",
            "                         'num_leaves': (150, 250)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9267652722511871\n",
            "{'bagging_fraction': 0.5, 'feature_fraction': 0.6, 'lambda_l1': 2, 'max_bin': 125, 'min_data_in_leaf': 300, 'num_leaves': 250}\n",
            "LGBMClassifier(bagging_fraction=0.5, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.6,\n",
            "               importance_type='split', lambda_l1=2, learning_rate=0.1,\n",
            "               max_bin=125, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=300, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=90, num_leaves=250,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n",
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split',\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=90,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_state=None, reg_...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'bagging_fraction': (0.5, 0.6),\n",
            "                         'feature_fraction': (0.5, 0.6), 'lambda_l1': (2, 4),\n",
            "                         'max_bin': (100, 125), 'min_data_in_leaf': (200, 300),\n",
            "                         'num_leaves': (150, 250)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9267652722511871\n",
            "{'bagging_fraction': 0.5, 'feature_fraction': 0.6, 'lambda_l1': 2, 'max_bin': 125, 'min_data_in_leaf': 300, 'num_leaves': 250}\n",
            "LGBMClassifier(bagging_fraction=0.5, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.6,\n",
            "               importance_type='split', lambda_l1=2, learning_rate=0.1,\n",
            "               max_bin=125, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=300, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=90, num_leaves=250,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "52sUc9Uswc1x",
        "outputId": "7dfa9c3b-227e-437f-fe7a-d88372d8a4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'max_bin':(100,125),#               #'learning_rate':(0.2,0.3),\n",
        "     'feature_fraction':(0.7,0.8),\n",
        "     'num_leaves':(300,350),#\n",
        "     'min_data_in_leaf':(300),\n",
        "     'lambda_l1':(1),#                    #'lambda_l2':(2,4,6),     #'max_depth':(60,80,90),\n",
        "     'bagging_fraction':(0.3,0.4)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=3,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  7.0min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  7.3min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed: 10.3min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed: 10.9min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 13.8min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 13.9min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 17.0min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 17.2min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 18.2min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 20.4min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 20.9min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 21.9min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 23.5min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 24.5min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 25.2min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 26.9min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 27.8min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 29.1min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 30.4min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 32.5min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 33.5min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 34.5min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 36.2min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 36.7min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 37.8min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 39.6min\n",
            "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed: 39.8min\n",
            "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed: 41.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed: 43.1min\n",
            "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed: 43.2min\n",
            "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed: 44.4min\n",
            "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed: 46.1min\n",
            "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed: 46.7min\n",
            "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed: 48.2min\n",
            "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed: 49.6min\n",
            "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed: 49.7min\n",
            "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 51.6min\n",
            "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed: 53.0min\n",
            "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed: 53.0min\n",
            "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed: 55.0min\n",
            "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed: 56.0min\n",
            "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed: 56.6min\n",
            "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed: 58.7min\n",
            "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed: 59.6min\n",
            "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed: 60.1min\n",
            "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed: 62.7min\n",
            "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed: 62.9min\n",
            "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed: 63.6min\n",
            "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed: 66.1min\n",
            "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed: 66.4min\n",
            "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed: 67.2min\n",
            "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed: 69.8min\n",
            "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed: 70.3min\n",
            "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed: 70.5min\n",
            "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed: 73.2min\n",
            "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed: 74.1min\n",
            "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed: 74.2min\n",
            "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed: 76.9min\n",
            "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed: 77.7min\n",
            "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed: 77.8min\n",
            "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed: 80.7min\n",
            "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed: 81.0min\n",
            "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed: 81.4min\n",
            "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed: 84.1min\n",
            "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed: 84.8min\n",
            "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed: 84.9min\n",
            "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed: 87.8min\n",
            "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed: 88.4min\n",
            "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed: 88.4min\n",
            "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed: 92.1min\n",
            "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed: 95.0min\n",
            "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed: 95.2min\n",
            "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed: 95.9min\n",
            "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed: 98.8min\n",
            "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed: 99.0min\n",
            "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed: 99.1min\n",
            "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed: 101.9min\n",
            "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed: 102.9min\n",
            "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed: 102.9min\n",
            "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed: 105.4min\n",
            "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed: 106.4min\n",
            "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed: 106.8min\n",
            "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed: 108.6min\n",
            "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed: 110.0min\n",
            "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed: 110.4min\n",
            "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed: 112.4min\n",
            "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed: 113.3min\n",
            "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed: 114.0min\n",
            "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed: 116.0min\n",
            "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed: 116.6min\n",
            "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed: 117.3min\n",
            "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed: 119.8min\n",
            "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed: 120.2min\n",
            "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed: 120.7min\n",
            "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed: 123.3min\n",
            "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed: 123.7min\n",
            "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed: 124.0min\n",
            "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed: 127.0min\n",
            "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed: 127.2min\n",
            "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed: 127.3min\n",
            "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed: 130.6min\n",
            "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed: 130.7min\n",
            "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed: 130.7min\n",
            "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed: 133.7min\n",
            "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed: 134.3min\n",
            "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed: 134.4min\n",
            "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed: 137.1min\n",
            "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed: 137.7min\n",
            "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed: 138.1min\n",
            "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed: 140.6min\n",
            "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed: 141.1min\n",
            "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed: 141.6min\n",
            "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed: 143.9min\n",
            "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed: 144.7min\n",
            "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed: 147.1min\n",
            "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed: 148.3min\n",
            "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed: 148.5min\n",
            "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed: 150.6min\n",
            "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed: 151.8min\n",
            "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed: 152.1min\n",
            "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed: 154.0min\n",
            "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed: 155.4min\n",
            "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed: 155.7min\n",
            "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed: 157.4min\n",
            "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed: 158.6min\n",
            "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed: 159.3min\n",
            "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed: 160.8min\n",
            "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed: 162.2min\n",
            "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed: 162.7min\n",
            "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed: 164.2min\n",
            "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed: 165.5min\n",
            "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed: 166.0min\n",
            "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed: 168.0min\n",
            "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed: 169.1min\n",
            "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed: 169.3min\n",
            "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed: 171.4min\n",
            "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed: 172.8min\n",
            "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed: 172.9min\n",
            "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed: 175.2min\n",
            "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed: 176.4min\n",
            "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed: 176.5min\n",
            "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed: 178.7min\n",
            "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed: 179.8min\n",
            "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed: 180.1min\n",
            "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed: 182.3min\n",
            "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 183.5min\n",
            "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed: 183.7min\n",
            "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed: 185.8min\n",
            "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed: 187.2min\n",
            "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed: 187.3min\n",
            "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed: 189.6min\n",
            "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed: 190.5min\n",
            "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed: 191.1min\n",
            "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed: 192.9min\n",
            "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed: 194.2min\n",
            "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed: 194.6min\n",
            "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed: 196.8min\n",
            "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed: 197.6min\n",
            "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed: 198.0min\n",
            "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed: 200.2min\n",
            "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed: 201.1min\n",
            "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed: 201.7min\n",
            "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed: 203.9min\n",
            "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed: 204.6min\n",
            "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed: 205.2min\n",
            "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed: 207.5min\n",
            "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed: 207.9min\n",
            "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed: 208.8min\n",
            "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed: 211.4min\n",
            "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed: 212.0min\n",
            "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed: 212.0min\n",
            "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed: 215.0min\n",
            "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed: 215.6min\n",
            "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed: 215.7min\n",
            "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed: 218.4min\n",
            "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed: 219.1min\n",
            "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed: 219.3min\n",
            "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed: 222.1min\n",
            "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed: 222.6min\n",
            "[Parallel(n_jobs=3)]: Done 192 out of 192 | elapsed: 225.7min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split',\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=90,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_state=None, reg_...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'bagging_fraction': (0.4, 0.5),\n",
            "                         'feature_fraction': (0.6, 0.7), 'lambda_l1': (1, 2),\n",
            "                         'max_bin': (125, 150), 'min_data_in_leaf': (300, 400),\n",
            "                         'num_leaves': (250, 300)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9272417521074825\n",
            "{'bagging_fraction': 0.4, 'feature_fraction': 0.7, 'lambda_l1': 1, 'max_bin': 125, 'min_data_in_leaf': 300, 'num_leaves': 300}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, learning_rate=0.1,\n",
            "               max_bin=125, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=300, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=90, num_leaves=300,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d1qmccME6gNU",
        "outputId": "7059376d-383a-43b4-863a-17fc988b5119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'learning_rate':(0.2,0.3),\n",
        "     'lambda_l2':(2,4),     \n",
        "     'max_depth':(60,80,90)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=3,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=1,max_bin=125,min_data_in_leaf=300,num_leaves=300)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  6.7min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  7.2min\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed: 11.0min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed: 11.1min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 14.0min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 14.0min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 14.7min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 17.1min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 17.5min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 18.3min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 20.5min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 20.9min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 22.1min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 23.8min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 24.6min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 25.8min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 27.4min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 28.2min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 29.6min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 30.8min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 32.3min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 33.1min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 34.0min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 35.9min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 36.7min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 37.3min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 39.3min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 40.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 out of  36 | elapsed: 43.2min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.4,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      feature_fraction=0.7,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_bin=125,\n",
            "                                      max_depth=-1, min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=300, min_split_gain=0.0,\n",
            "                                      n_estimat...\n",
            "                                      num_iterations=90, num_leaves=300,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'lambda_l2': (2, 4), 'learning_rate': (0.2, 0.3),\n",
            "                         'max_depth': (60, 80, 90)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9319399935584403\n",
            "{'lambda_l2': 4, 'learning_rate': 0.3, 'max_depth': 60}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=4,\n",
            "               learning_rate=0.3, max_bin=125, max_depth=60,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=300, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=300, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YwFiAmL4JZDO",
        "outputId": "1aac075a-8258-4c64-c232-55266ebeb34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'learning_rate':(0.4,0.5),\n",
        "     'lambda_l2':(6,8),     \n",
        "     'max_depth':(40,50)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=4,refit=\"accuracy\",pre_dispatch=5,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=1,max_bin=125,min_data_in_leaf=300,num_leaves=300)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  7.9min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:  8.1min\n",
            "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed: 11.7min\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed: 11.9min\n",
            "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed: 12.0min\n",
            "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed: 15.7min\n",
            "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed: 15.9min\n",
            "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed: 16.0min\n",
            "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed: 16.0min\n",
            "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed: 19.6min\n",
            "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed: 19.7min\n",
            "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed: 19.9min\n",
            "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed: 20.1min\n",
            "[Parallel(n_jobs=4)]: Done  21 out of  24 | elapsed: 23.6min remaining:  3.4min\n",
            "[Parallel(n_jobs=4)]: Done  22 out of  24 | elapsed: 23.7min remaining:  2.2min\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 24.0min finished\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 24.0min remaining:    0.0s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.4,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      feature_fraction=0.7,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_bin=125,\n",
            "                                      max_depth=-1, min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=300, min_split_gain=0.0,\n",
            "                                      n_estimat...\n",
            "                                      num_iterations=90, num_leaves=300,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=4,\n",
            "             param_grid={'lambda_l2': (4, 6), 'learning_rate': (0.3, 0.4),\n",
            "                         'max_depth': (50, 60)},\n",
            "             pre_dispatch=5, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9330757831179838\n",
            "{'lambda_l2': 6, 'learning_rate': 0.4, 'max_depth': 50}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=6,\n",
            "               learning_rate=0.4, max_bin=125, max_depth=50,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=300, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=300, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZdlHThqYTZSQ",
        "outputId": "fbf31d0c-2636-4028-a7b8-174f914e6c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'learning_rate':(0.4,0.5),\n",
        "     'lambda_l2':(6,8),     \n",
        "     'max_depth':(40,50)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=4,refit=\"accuracy\",pre_dispatch=5,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=1,max_bin=125,min_data_in_leaf=300,num_leaves=300)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  7.7min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed: 11.5min\n",
            "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed: 11.7min\n",
            "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed: 15.2min\n",
            "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed: 15.5min\n",
            "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed: 15.5min\n",
            "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed: 15.6min\n",
            "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed: 19.2min\n",
            "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed: 19.3min\n",
            "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed: 19.5min\n",
            "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed: 19.5min\n",
            "[Parallel(n_jobs=4)]: Done  21 out of  24 | elapsed: 23.1min remaining:  3.3min\n",
            "[Parallel(n_jobs=4)]: Done  22 out of  24 | elapsed: 23.2min remaining:  2.1min\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 23.4min remaining:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 23.4min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.4,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      feature_fraction=0.7,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_bin=125,\n",
            "                                      max_depth=-1, min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=300, min_split_gain=0.0,\n",
            "                                      n_estimat...\n",
            "                                      num_iterations=90, num_leaves=300,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=4,\n",
            "             param_grid={'lambda_l2': (6, 8), 'learning_rate': (0.4, 0.5),\n",
            "                         'max_depth': (40, 50)},\n",
            "             pre_dispatch=5, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9337819973503855\n",
            "{'lambda_l2': 8, 'learning_rate': 0.5, 'max_depth': 40}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=8,\n",
            "               learning_rate=0.5, max_bin=125, max_depth=40,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=300, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=300, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cEBGv0t5Iixl",
        "outputId": "b12a0998-b2aa-4d48-c3dc-14ecdb2ef322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols,Y_train.OUTCOME.mean(),Y_test.OUTCOME.mean())\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(num_iterations=100,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=3,max_bin=125,min_data_in_leaf=300,num_leaves=300,lambda_l2=8,learning_rate=0.2,max_depth=40)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  sel_X_valid=X_valid[sel_cols]\n",
        "  eval_set = [(sel_X_test, Y_test)]\n",
        "  model.fit(sel_X_train, Y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
        "\n",
        "  print(\"Test dataset:\")\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(\"Validation dataset:\")\n",
        "  pred=model.predict(sel_X_valid)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_valid,pred)\n",
        "\n",
        "  \n",
        "  print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "  #plot graph of feature importances for better visualization\n",
        "  feat_importances = pd.Series(model.feature_importances_, index=sel_cols)\n",
        "  feat_importances.nlargest(26).plot(kind='barh')\n",
        "  plt.show()\n",
        "\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test,sel_X_valid])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test,Y_valid])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'WHEELS_OFF_MINUTE', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing'] 0.5 0.2940363992608305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.569479\tvalid_0's binary_logloss: 0.569479\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.486589\tvalid_0's binary_logloss: 0.486589\n",
            "[3]\tvalid_0's binary_logloss: 0.428012\tvalid_0's binary_logloss: 0.428012\n",
            "[4]\tvalid_0's binary_logloss: 0.383814\tvalid_0's binary_logloss: 0.383814\n",
            "[5]\tvalid_0's binary_logloss: 0.345746\tvalid_0's binary_logloss: 0.345746\n",
            "[6]\tvalid_0's binary_logloss: 0.321031\tvalid_0's binary_logloss: 0.321031\n",
            "[7]\tvalid_0's binary_logloss: 0.298154\tvalid_0's binary_logloss: 0.298154\n",
            "[8]\tvalid_0's binary_logloss: 0.285058\tvalid_0's binary_logloss: 0.285058\n",
            "[9]\tvalid_0's binary_logloss: 0.270262\tvalid_0's binary_logloss: 0.270262\n",
            "[10]\tvalid_0's binary_logloss: 0.25903\tvalid_0's binary_logloss: 0.25903\n",
            "[11]\tvalid_0's binary_logloss: 0.250008\tvalid_0's binary_logloss: 0.250008\n",
            "[12]\tvalid_0's binary_logloss: 0.24317\tvalid_0's binary_logloss: 0.24317\n",
            "[13]\tvalid_0's binary_logloss: 0.237548\tvalid_0's binary_logloss: 0.237548\n",
            "[14]\tvalid_0's binary_logloss: 0.233508\tvalid_0's binary_logloss: 0.233508\n",
            "[15]\tvalid_0's binary_logloss: 0.230025\tvalid_0's binary_logloss: 0.230025\n",
            "[16]\tvalid_0's binary_logloss: 0.227125\tvalid_0's binary_logloss: 0.227125\n",
            "[17]\tvalid_0's binary_logloss: 0.224827\tvalid_0's binary_logloss: 0.224827\n",
            "[18]\tvalid_0's binary_logloss: 0.222553\tvalid_0's binary_logloss: 0.222553\n",
            "[19]\tvalid_0's binary_logloss: 0.220987\tvalid_0's binary_logloss: 0.220987\n",
            "[20]\tvalid_0's binary_logloss: 0.219362\tvalid_0's binary_logloss: 0.219362\n",
            "[21]\tvalid_0's binary_logloss: 0.218192\tvalid_0's binary_logloss: 0.218192\n",
            "[22]\tvalid_0's binary_logloss: 0.217354\tvalid_0's binary_logloss: 0.217354\n",
            "[23]\tvalid_0's binary_logloss: 0.215716\tvalid_0's binary_logloss: 0.215716\n",
            "[24]\tvalid_0's binary_logloss: 0.214515\tvalid_0's binary_logloss: 0.214515\n",
            "[25]\tvalid_0's binary_logloss: 0.213685\tvalid_0's binary_logloss: 0.213685\n",
            "[26]\tvalid_0's binary_logloss: 0.212459\tvalid_0's binary_logloss: 0.212459\n",
            "[27]\tvalid_0's binary_logloss: 0.211427\tvalid_0's binary_logloss: 0.211427\n",
            "[28]\tvalid_0's binary_logloss: 0.210558\tvalid_0's binary_logloss: 0.210558\n",
            "[29]\tvalid_0's binary_logloss: 0.209752\tvalid_0's binary_logloss: 0.209752\n",
            "[30]\tvalid_0's binary_logloss: 0.209184\tvalid_0's binary_logloss: 0.209184\n",
            "[31]\tvalid_0's binary_logloss: 0.208561\tvalid_0's binary_logloss: 0.208561\n",
            "[32]\tvalid_0's binary_logloss: 0.208034\tvalid_0's binary_logloss: 0.208034\n",
            "[33]\tvalid_0's binary_logloss: 0.207512\tvalid_0's binary_logloss: 0.207512\n",
            "[34]\tvalid_0's binary_logloss: 0.20691\tvalid_0's binary_logloss: 0.20691\n",
            "[35]\tvalid_0's binary_logloss: 0.206361\tvalid_0's binary_logloss: 0.206361\n",
            "[36]\tvalid_0's binary_logloss: 0.205974\tvalid_0's binary_logloss: 0.205974\n",
            "[37]\tvalid_0's binary_logloss: 0.205683\tvalid_0's binary_logloss: 0.205683\n",
            "[38]\tvalid_0's binary_logloss: 0.205309\tvalid_0's binary_logloss: 0.205309\n",
            "[39]\tvalid_0's binary_logloss: 0.204805\tvalid_0's binary_logloss: 0.204805\n",
            "[40]\tvalid_0's binary_logloss: 0.20445\tvalid_0's binary_logloss: 0.20445\n",
            "[41]\tvalid_0's binary_logloss: 0.204225\tvalid_0's binary_logloss: 0.204225\n",
            "[42]\tvalid_0's binary_logloss: 0.203815\tvalid_0's binary_logloss: 0.203815\n",
            "[43]\tvalid_0's binary_logloss: 0.203449\tvalid_0's binary_logloss: 0.203449\n",
            "[44]\tvalid_0's binary_logloss: 0.203076\tvalid_0's binary_logloss: 0.203076\n",
            "[45]\tvalid_0's binary_logloss: 0.202747\tvalid_0's binary_logloss: 0.202747\n",
            "[46]\tvalid_0's binary_logloss: 0.202478\tvalid_0's binary_logloss: 0.202478\n",
            "[47]\tvalid_0's binary_logloss: 0.202192\tvalid_0's binary_logloss: 0.202192\n",
            "[48]\tvalid_0's binary_logloss: 0.201896\tvalid_0's binary_logloss: 0.201896\n",
            "[49]\tvalid_0's binary_logloss: 0.201606\tvalid_0's binary_logloss: 0.201606\n",
            "[50]\tvalid_0's binary_logloss: 0.201398\tvalid_0's binary_logloss: 0.201398\n",
            "[51]\tvalid_0's binary_logloss: 0.20116\tvalid_0's binary_logloss: 0.20116\n",
            "[52]\tvalid_0's binary_logloss: 0.201016\tvalid_0's binary_logloss: 0.201016\n",
            "[53]\tvalid_0's binary_logloss: 0.200871\tvalid_0's binary_logloss: 0.200871\n",
            "[54]\tvalid_0's binary_logloss: 0.20062\tvalid_0's binary_logloss: 0.20062\n",
            "[55]\tvalid_0's binary_logloss: 0.200484\tvalid_0's binary_logloss: 0.200484\n",
            "[56]\tvalid_0's binary_logloss: 0.200357\tvalid_0's binary_logloss: 0.200357\n",
            "[57]\tvalid_0's binary_logloss: 0.200141\tvalid_0's binary_logloss: 0.200141\n",
            "[58]\tvalid_0's binary_logloss: 0.199941\tvalid_0's binary_logloss: 0.199941\n",
            "[59]\tvalid_0's binary_logloss: 0.199715\tvalid_0's binary_logloss: 0.199715\n",
            "[60]\tvalid_0's binary_logloss: 0.199545\tvalid_0's binary_logloss: 0.199545\n",
            "[61]\tvalid_0's binary_logloss: 0.199314\tvalid_0's binary_logloss: 0.199314\n",
            "[62]\tvalid_0's binary_logloss: 0.199153\tvalid_0's binary_logloss: 0.199153\n",
            "[63]\tvalid_0's binary_logloss: 0.198995\tvalid_0's binary_logloss: 0.198995\n",
            "[64]\tvalid_0's binary_logloss: 0.198806\tvalid_0's binary_logloss: 0.198806\n",
            "[65]\tvalid_0's binary_logloss: 0.198639\tvalid_0's binary_logloss: 0.198639\n",
            "[66]\tvalid_0's binary_logloss: 0.198537\tvalid_0's binary_logloss: 0.198537\n",
            "[67]\tvalid_0's binary_logloss: 0.198449\tvalid_0's binary_logloss: 0.198449\n",
            "[68]\tvalid_0's binary_logloss: 0.198315\tvalid_0's binary_logloss: 0.198315\n",
            "[69]\tvalid_0's binary_logloss: 0.198207\tvalid_0's binary_logloss: 0.198207\n",
            "[70]\tvalid_0's binary_logloss: 0.197997\tvalid_0's binary_logloss: 0.197997\n",
            "[71]\tvalid_0's binary_logloss: 0.197888\tvalid_0's binary_logloss: 0.197888\n",
            "[72]\tvalid_0's binary_logloss: 0.197812\tvalid_0's binary_logloss: 0.197812\n",
            "[73]\tvalid_0's binary_logloss: 0.197663\tvalid_0's binary_logloss: 0.197663\n",
            "[74]\tvalid_0's binary_logloss: 0.197578\tvalid_0's binary_logloss: 0.197578\n",
            "[75]\tvalid_0's binary_logloss: 0.19748\tvalid_0's binary_logloss: 0.19748\n",
            "[76]\tvalid_0's binary_logloss: 0.197374\tvalid_0's binary_logloss: 0.197374\n",
            "[77]\tvalid_0's binary_logloss: 0.197307\tvalid_0's binary_logloss: 0.197307\n",
            "[78]\tvalid_0's binary_logloss: 0.197177\tvalid_0's binary_logloss: 0.197177\n",
            "[79]\tvalid_0's binary_logloss: 0.197013\tvalid_0's binary_logloss: 0.197013\n",
            "[80]\tvalid_0's binary_logloss: 0.196888\tvalid_0's binary_logloss: 0.196888\n",
            "[81]\tvalid_0's binary_logloss: 0.196794\tvalid_0's binary_logloss: 0.196794\n",
            "[82]\tvalid_0's binary_logloss: 0.196746\tvalid_0's binary_logloss: 0.196746\n",
            "[83]\tvalid_0's binary_logloss: 0.19667\tvalid_0's binary_logloss: 0.19667\n",
            "[84]\tvalid_0's binary_logloss: 0.19652\tvalid_0's binary_logloss: 0.19652\n",
            "[85]\tvalid_0's binary_logloss: 0.196443\tvalid_0's binary_logloss: 0.196443\n",
            "[86]\tvalid_0's binary_logloss: 0.19639\tvalid_0's binary_logloss: 0.19639\n",
            "[87]\tvalid_0's binary_logloss: 0.196355\tvalid_0's binary_logloss: 0.196355\n",
            "[88]\tvalid_0's binary_logloss: 0.196253\tvalid_0's binary_logloss: 0.196253\n",
            "[89]\tvalid_0's binary_logloss: 0.196177\tvalid_0's binary_logloss: 0.196177\n",
            "[90]\tvalid_0's binary_logloss: 0.196095\tvalid_0's binary_logloss: 0.196095\n",
            "[91]\tvalid_0's binary_logloss: 0.195989\tvalid_0's binary_logloss: 0.195989\n",
            "[92]\tvalid_0's binary_logloss: 0.195945\tvalid_0's binary_logloss: 0.195945\n",
            "[93]\tvalid_0's binary_logloss: 0.195833\tvalid_0's binary_logloss: 0.195833\n",
            "[94]\tvalid_0's binary_logloss: 0.195774\tvalid_0's binary_logloss: 0.195774\n",
            "[95]\tvalid_0's binary_logloss: 0.195717\tvalid_0's binary_logloss: 0.195717\n",
            "[96]\tvalid_0's binary_logloss: 0.195638\tvalid_0's binary_logloss: 0.195638\n",
            "[97]\tvalid_0's binary_logloss: 0.195552\tvalid_0's binary_logloss: 0.195552\n",
            "[98]\tvalid_0's binary_logloss: 0.195481\tvalid_0's binary_logloss: 0.195481\n",
            "[99]\tvalid_0's binary_logloss: 0.195445\tvalid_0's binary_logloss: 0.195445\n",
            "[100]\tvalid_0's binary_logloss: 0.195381\tvalid_0's binary_logloss: 0.195381\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's binary_logloss: 0.195381\tvalid_0's binary_logloss: 0.195381\n",
            "Test dataset:\n",
            "predictions are  [0 1 0 ... 0 0 1]\n",
            "Test ROC AUC score: 0.889763304872015\n",
            "Test accuracy score: 0.925443953673668\n",
            "Confusion matrix is  [[327874   7931]\n",
            " [ 27533 112331]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95    335805\n",
            "           1       0.93      0.80      0.86    139864\n",
            "\n",
            "    accuracy                           0.93    475669\n",
            "   macro avg       0.93      0.89      0.91    475669\n",
            "weighted avg       0.93      0.93      0.92    475669\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation dataset:\n",
            "predictions are  [0 0 1 ... 0 0 0]\n",
            "Test ROC AUC score: 0.889452094492922\n",
            "Test accuracy score: 0.9253657246375291\n",
            "Confusion matrix is  [[657307  15906]\n",
            " [ 55203 224350]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95    673213\n",
            "           1       0.93      0.80      0.86    279553\n",
            "\n",
            "    accuracy                           0.93    952766\n",
            "   macro avg       0.93      0.89      0.91    952766\n",
            "weighted avg       0.93      0.93      0.92    952766\n",
            "\n",
            "\n",
            "\n",
            "[2403 3518 2949 1924 2421 3433 4062    0    0    0    0    0 2854 2149\n",
            "  669  596  697 1369  787   47   15    6    1    0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([64.79852962, 63.8235991 , 62.77963233, 63.46227574, 63.47014284]), 'score_time': array([5.62395573, 6.19999909, 5.42903042, 5.62770867, 5.48015618]), 'test_accuracy': array([0.92474026, 0.92496246, 0.92488983, 0.92569138, 0.92547787]), 'test_roc_auc': array([0.8873977 , 0.88801197, 0.88765863, 0.88874069, 0.88873849])}\n",
            "cross for accuracy [0.92474026 0.92496246 0.92488983 0.92569138 0.92547787]\n",
            "cross for roc-auc [0.8873977  0.88801197 0.88765863 0.88874069 0.88873849]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQbFihYc_4ki",
        "colab_type": "code",
        "outputId": "66ad30d6-1c2d-4556-9eae-e8531526201d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sel_cols=cols_after_removing_recursive\n",
        "print(sel_cols,Y_train.OUTCOME.mean(),Y_test.OUTCOME.mean())\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(extra_trees=True,num_iterations=100,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=3,max_bin=125,min_data_in_leaf=300,num_leaves=300,lambda_l2=8,learning_rate=0.2,max_depth=40)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  sel_X_valid=X_valid[sel_cols]\n",
        "  eval_set = [(sel_X_test, Y_test)]\n",
        "  model.fit(sel_X_train, Y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
        "\n",
        "  print(\"Test dataset:\")\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(\"Validation dataset:\")\n",
        "  pred=model.predict(sel_X_valid)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_valid,pred)\n",
        "\n",
        "  \n",
        "  print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "  #plot graph of feature importances for better visualization\n",
        "  feat_importances = pd.Series(model.feature_importances_, index=sel_cols)\n",
        "  feat_importances.nlargest(26).plot(kind='barh')\n",
        "  plt.show()\n",
        "\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test,sel_X_valid])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test,Y_valid])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'AIR_SYSTEM_DELAY_is_missing'] 0.5 0.2940363992608305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.569479\tvalid_0's binary_logloss: 0.569479\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.496275\tvalid_0's binary_logloss: 0.496275\n",
            "[3]\tvalid_0's binary_logloss: 0.428993\tvalid_0's binary_logloss: 0.428993\n",
            "[4]\tvalid_0's binary_logloss: 0.384118\tvalid_0's binary_logloss: 0.384118\n",
            "[5]\tvalid_0's binary_logloss: 0.351167\tvalid_0's binary_logloss: 0.351167\n",
            "[6]\tvalid_0's binary_logloss: 0.321787\tvalid_0's binary_logloss: 0.321787\n",
            "[7]\tvalid_0's binary_logloss: 0.299552\tvalid_0's binary_logloss: 0.299552\n",
            "[8]\tvalid_0's binary_logloss: 0.287327\tvalid_0's binary_logloss: 0.287327\n",
            "[9]\tvalid_0's binary_logloss: 0.272573\tvalid_0's binary_logloss: 0.272573\n",
            "[10]\tvalid_0's binary_logloss: 0.26186\tvalid_0's binary_logloss: 0.26186\n",
            "[11]\tvalid_0's binary_logloss: 0.255889\tvalid_0's binary_logloss: 0.255889\n",
            "[12]\tvalid_0's binary_logloss: 0.249588\tvalid_0's binary_logloss: 0.249588\n",
            "[13]\tvalid_0's binary_logloss: 0.243674\tvalid_0's binary_logloss: 0.243674\n",
            "[14]\tvalid_0's binary_logloss: 0.238166\tvalid_0's binary_logloss: 0.238166\n",
            "[15]\tvalid_0's binary_logloss: 0.233114\tvalid_0's binary_logloss: 0.233114\n",
            "[16]\tvalid_0's binary_logloss: 0.23005\tvalid_0's binary_logloss: 0.23005\n",
            "[17]\tvalid_0's binary_logloss: 0.226733\tvalid_0's binary_logloss: 0.226733\n",
            "[18]\tvalid_0's binary_logloss: 0.224843\tvalid_0's binary_logloss: 0.224843\n",
            "[19]\tvalid_0's binary_logloss: 0.223361\tvalid_0's binary_logloss: 0.223361\n",
            "[20]\tvalid_0's binary_logloss: 0.22111\tvalid_0's binary_logloss: 0.22111\n",
            "[21]\tvalid_0's binary_logloss: 0.219457\tvalid_0's binary_logloss: 0.219457\n",
            "[22]\tvalid_0's binary_logloss: 0.217893\tvalid_0's binary_logloss: 0.217893\n",
            "[23]\tvalid_0's binary_logloss: 0.216516\tvalid_0's binary_logloss: 0.216516\n",
            "[24]\tvalid_0's binary_logloss: 0.214957\tvalid_0's binary_logloss: 0.214957\n",
            "[25]\tvalid_0's binary_logloss: 0.213833\tvalid_0's binary_logloss: 0.213833\n",
            "[26]\tvalid_0's binary_logloss: 0.21289\tvalid_0's binary_logloss: 0.21289\n",
            "[27]\tvalid_0's binary_logloss: 0.211949\tvalid_0's binary_logloss: 0.211949\n",
            "[28]\tvalid_0's binary_logloss: 0.210974\tvalid_0's binary_logloss: 0.210974\n",
            "[29]\tvalid_0's binary_logloss: 0.210262\tvalid_0's binary_logloss: 0.210262\n",
            "[30]\tvalid_0's binary_logloss: 0.209609\tvalid_0's binary_logloss: 0.209609\n",
            "[31]\tvalid_0's binary_logloss: 0.209084\tvalid_0's binary_logloss: 0.209084\n",
            "[32]\tvalid_0's binary_logloss: 0.208525\tvalid_0's binary_logloss: 0.208525\n",
            "[33]\tvalid_0's binary_logloss: 0.207608\tvalid_0's binary_logloss: 0.207608\n",
            "[34]\tvalid_0's binary_logloss: 0.20713\tvalid_0's binary_logloss: 0.20713\n",
            "[35]\tvalid_0's binary_logloss: 0.206383\tvalid_0's binary_logloss: 0.206383\n",
            "[36]\tvalid_0's binary_logloss: 0.205786\tvalid_0's binary_logloss: 0.205786\n",
            "[37]\tvalid_0's binary_logloss: 0.205518\tvalid_0's binary_logloss: 0.205518\n",
            "[38]\tvalid_0's binary_logloss: 0.205035\tvalid_0's binary_logloss: 0.205035\n",
            "[39]\tvalid_0's binary_logloss: 0.204587\tvalid_0's binary_logloss: 0.204587\n",
            "[40]\tvalid_0's binary_logloss: 0.204164\tvalid_0's binary_logloss: 0.204164\n",
            "[41]\tvalid_0's binary_logloss: 0.203839\tvalid_0's binary_logloss: 0.203839\n",
            "[42]\tvalid_0's binary_logloss: 0.203494\tvalid_0's binary_logloss: 0.203494\n",
            "[43]\tvalid_0's binary_logloss: 0.203167\tvalid_0's binary_logloss: 0.203167\n",
            "[44]\tvalid_0's binary_logloss: 0.202762\tvalid_0's binary_logloss: 0.202762\n",
            "[45]\tvalid_0's binary_logloss: 0.202566\tvalid_0's binary_logloss: 0.202566\n",
            "[46]\tvalid_0's binary_logloss: 0.202247\tvalid_0's binary_logloss: 0.202247\n",
            "[47]\tvalid_0's binary_logloss: 0.20194\tvalid_0's binary_logloss: 0.20194\n",
            "[48]\tvalid_0's binary_logloss: 0.201754\tvalid_0's binary_logloss: 0.201754\n",
            "[49]\tvalid_0's binary_logloss: 0.201592\tvalid_0's binary_logloss: 0.201592\n",
            "[50]\tvalid_0's binary_logloss: 0.201309\tvalid_0's binary_logloss: 0.201309\n",
            "[51]\tvalid_0's binary_logloss: 0.20118\tvalid_0's binary_logloss: 0.20118\n",
            "[52]\tvalid_0's binary_logloss: 0.200989\tvalid_0's binary_logloss: 0.200989\n",
            "[53]\tvalid_0's binary_logloss: 0.200828\tvalid_0's binary_logloss: 0.200828\n",
            "[54]\tvalid_0's binary_logloss: 0.200691\tvalid_0's binary_logloss: 0.200691\n",
            "[55]\tvalid_0's binary_logloss: 0.200442\tvalid_0's binary_logloss: 0.200442\n",
            "[56]\tvalid_0's binary_logloss: 0.200287\tvalid_0's binary_logloss: 0.200287\n",
            "[57]\tvalid_0's binary_logloss: 0.200037\tvalid_0's binary_logloss: 0.200037\n",
            "[58]\tvalid_0's binary_logloss: 0.199826\tvalid_0's binary_logloss: 0.199826\n",
            "[59]\tvalid_0's binary_logloss: 0.19961\tvalid_0's binary_logloss: 0.19961\n",
            "[60]\tvalid_0's binary_logloss: 0.199461\tvalid_0's binary_logloss: 0.199461\n",
            "[61]\tvalid_0's binary_logloss: 0.199256\tvalid_0's binary_logloss: 0.199256\n",
            "[62]\tvalid_0's binary_logloss: 0.19916\tvalid_0's binary_logloss: 0.19916\n",
            "[63]\tvalid_0's binary_logloss: 0.199046\tvalid_0's binary_logloss: 0.199046\n",
            "[64]\tvalid_0's binary_logloss: 0.198864\tvalid_0's binary_logloss: 0.198864\n",
            "[65]\tvalid_0's binary_logloss: 0.198719\tvalid_0's binary_logloss: 0.198719\n",
            "[66]\tvalid_0's binary_logloss: 0.198561\tvalid_0's binary_logloss: 0.198561\n",
            "[67]\tvalid_0's binary_logloss: 0.198386\tvalid_0's binary_logloss: 0.198386\n",
            "[68]\tvalid_0's binary_logloss: 0.198311\tvalid_0's binary_logloss: 0.198311\n",
            "[69]\tvalid_0's binary_logloss: 0.198253\tvalid_0's binary_logloss: 0.198253\n",
            "[70]\tvalid_0's binary_logloss: 0.198074\tvalid_0's binary_logloss: 0.198074\n",
            "[71]\tvalid_0's binary_logloss: 0.198029\tvalid_0's binary_logloss: 0.198029\n",
            "[72]\tvalid_0's binary_logloss: 0.197893\tvalid_0's binary_logloss: 0.197893\n",
            "[73]\tvalid_0's binary_logloss: 0.197776\tvalid_0's binary_logloss: 0.197776\n",
            "[74]\tvalid_0's binary_logloss: 0.19767\tvalid_0's binary_logloss: 0.19767\n",
            "[75]\tvalid_0's binary_logloss: 0.197487\tvalid_0's binary_logloss: 0.197487\n",
            "[76]\tvalid_0's binary_logloss: 0.197429\tvalid_0's binary_logloss: 0.197429\n",
            "[77]\tvalid_0's binary_logloss: 0.197372\tvalid_0's binary_logloss: 0.197372\n",
            "[78]\tvalid_0's binary_logloss: 0.197248\tvalid_0's binary_logloss: 0.197248\n",
            "[79]\tvalid_0's binary_logloss: 0.197185\tvalid_0's binary_logloss: 0.197185\n",
            "[80]\tvalid_0's binary_logloss: 0.197067\tvalid_0's binary_logloss: 0.197067\n",
            "[81]\tvalid_0's binary_logloss: 0.197016\tvalid_0's binary_logloss: 0.197016\n",
            "[82]\tvalid_0's binary_logloss: 0.196863\tvalid_0's binary_logloss: 0.196863\n",
            "[83]\tvalid_0's binary_logloss: 0.196801\tvalid_0's binary_logloss: 0.196801\n",
            "[84]\tvalid_0's binary_logloss: 0.196754\tvalid_0's binary_logloss: 0.196754\n",
            "[85]\tvalid_0's binary_logloss: 0.196639\tvalid_0's binary_logloss: 0.196639\n",
            "[86]\tvalid_0's binary_logloss: 0.196598\tvalid_0's binary_logloss: 0.196598\n",
            "[87]\tvalid_0's binary_logloss: 0.196524\tvalid_0's binary_logloss: 0.196524\n",
            "[88]\tvalid_0's binary_logloss: 0.196445\tvalid_0's binary_logloss: 0.196445\n",
            "[89]\tvalid_0's binary_logloss: 0.196357\tvalid_0's binary_logloss: 0.196357\n",
            "[90]\tvalid_0's binary_logloss: 0.19626\tvalid_0's binary_logloss: 0.19626\n",
            "[91]\tvalid_0's binary_logloss: 0.196173\tvalid_0's binary_logloss: 0.196173\n",
            "[92]\tvalid_0's binary_logloss: 0.196087\tvalid_0's binary_logloss: 0.196087\n",
            "[93]\tvalid_0's binary_logloss: 0.195984\tvalid_0's binary_logloss: 0.195984\n",
            "[94]\tvalid_0's binary_logloss: 0.195899\tvalid_0's binary_logloss: 0.195899\n",
            "[95]\tvalid_0's binary_logloss: 0.195829\tvalid_0's binary_logloss: 0.195829\n",
            "[96]\tvalid_0's binary_logloss: 0.195786\tvalid_0's binary_logloss: 0.195786\n",
            "[97]\tvalid_0's binary_logloss: 0.195701\tvalid_0's binary_logloss: 0.195701\n",
            "[98]\tvalid_0's binary_logloss: 0.195626\tvalid_0's binary_logloss: 0.195626\n",
            "[99]\tvalid_0's binary_logloss: 0.195588\tvalid_0's binary_logloss: 0.195588\n",
            "[100]\tvalid_0's binary_logloss: 0.19555\tvalid_0's binary_logloss: 0.19555\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's binary_logloss: 0.19555\tvalid_0's binary_logloss: 0.19555\n",
            "Test dataset:\n",
            "predictions are  [0 1 0 ... 0 0 1]\n",
            "Test ROC AUC score: 0.88957724789964\n",
            "Test accuracy score: 0.9250487208542074\n",
            "Confusion matrix is  [[327641   8164]\n",
            " [ 27488 112376]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95    335805\n",
            "           1       0.93      0.80      0.86    139864\n",
            "\n",
            "    accuracy                           0.93    475669\n",
            "   macro avg       0.93      0.89      0.91    475669\n",
            "weighted avg       0.93      0.93      0.92    475669\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation dataset:\n",
            "predictions are  [0 0 1 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8896295735299863\n",
            "Test accuracy score: 0.9252618166475294\n",
            "Confusion matrix is  [[656968  16245]\n",
            " [ 54963 224590]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95    673213\n",
            "           1       0.93      0.80      0.86    279553\n",
            "\n",
            "    accuracy                           0.93    952766\n",
            "   macro avg       0.93      0.89      0.91    952766\n",
            "weighted avg       0.93      0.93      0.92    952766\n",
            "\n",
            "\n",
            "\n",
            "[2767 3358 3073 2033 2852 3614 3403 2797 2580 1145 1285  944   49]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([52.77928758, 53.32627749, 52.63276505, 52.61653566, 52.69693279]), 'score_time': array([5.74487638, 5.42663002, 5.33374643, 5.40729117, 5.36637354]), 'test_accuracy': array([0.92468688, 0.92508147, 0.92484083, 0.92547874, 0.92556012]), 'test_roc_auc': array([0.88762208, 0.88842106, 0.88781033, 0.8886555 , 0.8889709 ])}\n",
            "cross for accuracy [0.92468688 0.92508147 0.92484083 0.92547874 0.92556012]\n",
            "cross for roc-auc [0.88762208 0.88842106 0.88781033 0.8886555  0.8889709 ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}