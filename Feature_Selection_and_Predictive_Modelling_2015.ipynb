{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Selection and Predictive Modelling-2015",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP5JYNCqb807Y1adXqbApBW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bchaithanyasai/PredictLateArrivalsPaper/blob/master/Feature_Selection_and_Predictive_Modelling_2015.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zk626ZMKEedL",
        "outputId": "b072b299-373a-41ef-cd6f-1643d9fd108b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4mJaM6qcFABM",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data=pd.read_csv(\"/content/drive/My Drive/train_data.csv\")\n",
        "test_data=pd.read_csv(\"/content/drive/My Drive/test_data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mQQWbYz2gMIN",
        "outputId": "f602a8fc-227d-43bb-e29a-7c62fc1c580b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_data.OUTCOME.mean(),test_data.OUTCOME.mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5 0.2936199407043373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8nFtnzW2ZDo_",
        "outputId": "1857f16d-1305-4e5c-e24b-d41b4db91010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "train_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.308508</td>\n",
              "      <td>0.341235</td>\n",
              "      <td>0.082088</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>337.00000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1226.0</td>\n",
              "      <td>1219.000000</td>\n",
              "      <td>4225.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.304283</td>\n",
              "      <td>0.294836</td>\n",
              "      <td>0.130962</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>480.00000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1309.0</td>\n",
              "      <td>1302.000000</td>\n",
              "      <td>4446.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.257698</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.998464</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>425.00000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1282.0</td>\n",
              "      <td>1232.000000</td>\n",
              "      <td>3175.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.282126</td>\n",
              "      <td>0.305712</td>\n",
              "      <td>0.070847</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>306.000000</td>\n",
              "      <td>2370.00000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.0</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>4025.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.316538</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.076309</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>545.00000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>343.0</td>\n",
              "      <td>237.000000</td>\n",
              "      <td>3545.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054813</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.127057</td>\n",
              "      <td>18.602376</td>\n",
              "      <td>3.872943</td>\n",
              "      <td>0.254685</td>\n",
              "      <td>0.305712</td>\n",
              "      <td>0.290665</td>\n",
              "      <td>17.127057</td>\n",
              "      <td>120.508227</td>\n",
              "      <td>666.00000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>237.0</td>\n",
              "      <td>346.000000</td>\n",
              "      <td>236.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>55.127057</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>50.508227</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>12.254113</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054814</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.512993</td>\n",
              "      <td>24.922040</td>\n",
              "      <td>2.487007</td>\n",
              "      <td>0.273511</td>\n",
              "      <td>0.323033</td>\n",
              "      <td>0.080605</td>\n",
              "      <td>20.948027</td>\n",
              "      <td>174.974013</td>\n",
              "      <td>1075.53898</td>\n",
              "      <td>155.821463</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>310.051973</td>\n",
              "      <td>3973.512993</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>45.282483</td>\n",
              "      <td>50.795477</td>\n",
              "      <td>45.769490</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>6.230510</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054815</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>6.751592</td>\n",
              "      <td>8.745223</td>\n",
              "      <td>3.165605</td>\n",
              "      <td>0.202012</td>\n",
              "      <td>0.299325</td>\n",
              "      <td>0.999615</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>74.834395</td>\n",
              "      <td>295.00000</td>\n",
              "      <td>50.503185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.165605</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>477.0</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>1964.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>11.585987</td>\n",
              "      <td>11.254777</td>\n",
              "      <td>26.089172</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>20.585987</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054816</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>13.349001</td>\n",
              "      <td>4.941833</td>\n",
              "      <td>0.319731</td>\n",
              "      <td>0.319792</td>\n",
              "      <td>0.990391</td>\n",
              "      <td>13.587250</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>946.00000</td>\n",
              "      <td>109.116334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.529083</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.290834</td>\n",
              "      <td>32.116334</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>441.0</td>\n",
              "      <td>432.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>36.174500</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>49.761750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054817</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>6.210935</td>\n",
              "      <td>15.734391</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.328592</td>\n",
              "      <td>0.305712</td>\n",
              "      <td>0.999968</td>\n",
              "      <td>25.839858</td>\n",
              "      <td>212.789065</td>\n",
              "      <td>1325.00000</td>\n",
              "      <td>158.894533</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.792947</td>\n",
              "      <td>20.265609</td>\n",
              "      <td>21.468781</td>\n",
              "      <td>1072.0</td>\n",
              "      <td>1103.000000</td>\n",
              "      <td>2136.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.316402</td>\n",
              "      <td>16.316402</td>\n",
              "      <td>18.785184</td>\n",
              "      <td>44.476544</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>14.789065</td>\n",
              "      <td>18.316402</td>\n",
              "      <td>10.316402</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6054818 rows × 48 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR      MONTH  ...  WEATHER_DELAY_is_missing  OUTCOME\n",
              "0        2015.0   4.000000  ...                       1.0        0\n",
              "1        2015.0   7.000000  ...                       1.0        0\n",
              "2        2015.0   5.000000  ...                       0.0        1\n",
              "3        2015.0  11.000000  ...                       1.0        0\n",
              "4        2015.0   8.000000  ...                       1.0        0\n",
              "...         ...        ...  ...                       ...      ...\n",
              "6054813  2015.0   8.127057  ...                       1.0        1\n",
              "6054814  2015.0   1.512993  ...                       1.0        1\n",
              "6054815  2015.0   6.751592  ...                       0.0        1\n",
              "6054816  2015.0   3.000000  ...                       0.0        1\n",
              "6054817  2015.0   6.210935  ...                       0.0        1\n",
              "\n",
              "[6054818 rows x 48 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vvUpEEFbZGZ9",
        "outputId": "1afe8cb7-01c0-4ff2-f1ab-fa2edec50b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "test_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>0.261397</td>\n",
              "      <td>0.277054</td>\n",
              "      <td>0.889772</td>\n",
              "      <td>23.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>930</td>\n",
              "      <td>124.0</td>\n",
              "      <td>0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57</td>\n",
              "      <td>15</td>\n",
              "      <td>3078</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>21</td>\n",
              "      <td>59</td>\n",
              "      <td>35</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.276077</td>\n",
              "      <td>0.306426</td>\n",
              "      <td>0.160310</td>\n",
              "      <td>14.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>612</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "      <td>65</td>\n",
              "      <td>1082</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>39</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.254685</td>\n",
              "      <td>0.353796</td>\n",
              "      <td>0.082088</td>\n",
              "      <td>24.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>152</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>237</td>\n",
              "      <td>386</td>\n",
              "      <td>277</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>52</td>\n",
              "      <td>13</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>0.319731</td>\n",
              "      <td>0.283453</td>\n",
              "      <td>0.996226</td>\n",
              "      <td>16.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>550</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>21</td>\n",
              "      <td>91</td>\n",
              "      <td>1380</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>57</td>\n",
              "      <td>9</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0.282126</td>\n",
              "      <td>0.287523</td>\n",
              "      <td>0.113494</td>\n",
              "      <td>8.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>1050</td>\n",
              "      <td>129.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1301</td>\n",
              "      <td>1305</td>\n",
              "      <td>4029</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>20</td>\n",
              "      <td>28</td>\n",
              "      <td>30</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428430</th>\n",
              "      <td>2015</td>\n",
              "      <td>11</td>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>0.308508</td>\n",
              "      <td>0.284717</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>1464</td>\n",
              "      <td>167.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85</td>\n",
              "      <td>21</td>\n",
              "      <td>4210</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "      <td>49</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428431</th>\n",
              "      <td>2015</td>\n",
              "      <td>10</td>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>0.201649</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.975365</td>\n",
              "      <td>50.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>813</td>\n",
              "      <td>99.0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>250</td>\n",
              "      <td>237</td>\n",
              "      <td>547</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>17</td>\n",
              "      <td>55</td>\n",
              "      <td>21</td>\n",
              "      <td>34</td>\n",
              "      <td>15</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428432</th>\n",
              "      <td>2015</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "      <td>0.318843</td>\n",
              "      <td>0.288808</td>\n",
              "      <td>0.099772</td>\n",
              "      <td>9.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>255</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1159</td>\n",
              "      <td>1183</td>\n",
              "      <td>2431</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>32</td>\n",
              "      <td>35</td>\n",
              "      <td>44</td>\n",
              "      <td>16</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428433</th>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>0.282422</td>\n",
              "      <td>0.358423</td>\n",
              "      <td>0.063157</td>\n",
              "      <td>10.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>764</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>410</td>\n",
              "      <td>495</td>\n",
              "      <td>432</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>35</td>\n",
              "      <td>47</td>\n",
              "      <td>13</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428434</th>\n",
              "      <td>2015</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0.231242</td>\n",
              "      <td>0.268731</td>\n",
              "      <td>0.113494</td>\n",
              "      <td>15.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>468</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1239</td>\n",
              "      <td>1278</td>\n",
              "      <td>610</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1428435 rows × 48 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         YEAR  MONTH  ...  WEATHER_DELAY_is_missing  OUTCOME\n",
              "0        2015      8  ...                         0        1\n",
              "1        2015     11  ...                         1        0\n",
              "2        2015      1  ...                         1        0\n",
              "3        2015      3  ...                         0        1\n",
              "4        2015      6  ...                         1        0\n",
              "...       ...    ...  ...                       ...      ...\n",
              "1428430  2015     11  ...                         0        1\n",
              "1428431  2015     10  ...                         0        1\n",
              "1428432  2015      4  ...                         1        0\n",
              "1428433  2015     12  ...                         1        0\n",
              "1428434  2015      4  ...                         1        1\n",
              "\n",
              "[1428435 rows x 48 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aigROTKhFYB6",
        "colab": {}
      },
      "source": [
        "Y_train=pd.DataFrame(train_data['OUTCOME'])\n",
        "X_train=train_data.drop(\"OUTCOME\",axis=1)\n",
        "\n",
        "Y_test=pd.DataFrame(test_data['OUTCOME'])\n",
        "X_test=test_data.drop(\"OUTCOME\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T6ZfhIrJFoAo",
        "outputId": "1511cce1-bd80-4420-ea53-e4f7d445f72f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.308508</td>\n",
              "      <td>0.341235</td>\n",
              "      <td>0.082088</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>337.00000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1226.0</td>\n",
              "      <td>1219.000000</td>\n",
              "      <td>4225.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.304283</td>\n",
              "      <td>0.294836</td>\n",
              "      <td>0.130962</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>480.00000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1309.0</td>\n",
              "      <td>1302.000000</td>\n",
              "      <td>4446.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.257698</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.998464</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>425.00000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1282.0</td>\n",
              "      <td>1232.000000</td>\n",
              "      <td>3175.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.282126</td>\n",
              "      <td>0.305712</td>\n",
              "      <td>0.070847</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>306.000000</td>\n",
              "      <td>2370.00000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.0</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>4025.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.316538</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.076309</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>545.00000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>343.0</td>\n",
              "      <td>237.000000</td>\n",
              "      <td>3545.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054813</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.127057</td>\n",
              "      <td>18.602376</td>\n",
              "      <td>3.872943</td>\n",
              "      <td>0.254685</td>\n",
              "      <td>0.305712</td>\n",
              "      <td>0.290665</td>\n",
              "      <td>17.127057</td>\n",
              "      <td>120.508227</td>\n",
              "      <td>666.00000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>237.0</td>\n",
              "      <td>346.000000</td>\n",
              "      <td>236.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>55.127057</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>50.508227</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>12.254113</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054814</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>1.512993</td>\n",
              "      <td>24.922040</td>\n",
              "      <td>2.487007</td>\n",
              "      <td>0.273511</td>\n",
              "      <td>0.323033</td>\n",
              "      <td>0.080605</td>\n",
              "      <td>20.948027</td>\n",
              "      <td>174.974013</td>\n",
              "      <td>1075.53898</td>\n",
              "      <td>155.821463</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>310.051973</td>\n",
              "      <td>3973.512993</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>45.282483</td>\n",
              "      <td>50.795477</td>\n",
              "      <td>45.769490</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>6.230510</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054815</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>6.751592</td>\n",
              "      <td>8.745223</td>\n",
              "      <td>3.165605</td>\n",
              "      <td>0.202012</td>\n",
              "      <td>0.299325</td>\n",
              "      <td>0.999615</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>74.834395</td>\n",
              "      <td>295.00000</td>\n",
              "      <td>50.503185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.165605</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>477.0</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>1964.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>11.585987</td>\n",
              "      <td>11.254777</td>\n",
              "      <td>26.089172</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>20.585987</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054816</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>13.349001</td>\n",
              "      <td>4.941833</td>\n",
              "      <td>0.319731</td>\n",
              "      <td>0.319792</td>\n",
              "      <td>0.990391</td>\n",
              "      <td>13.587250</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>946.00000</td>\n",
              "      <td>109.116334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.529083</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.290834</td>\n",
              "      <td>32.116334</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>441.0</td>\n",
              "      <td>432.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>36.174500</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>49.761750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054817</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>6.210935</td>\n",
              "      <td>15.734391</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.328592</td>\n",
              "      <td>0.305712</td>\n",
              "      <td>0.999968</td>\n",
              "      <td>25.839858</td>\n",
              "      <td>212.789065</td>\n",
              "      <td>1325.00000</td>\n",
              "      <td>158.894533</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.792947</td>\n",
              "      <td>20.265609</td>\n",
              "      <td>21.468781</td>\n",
              "      <td>1072.0</td>\n",
              "      <td>1103.000000</td>\n",
              "      <td>2136.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.316402</td>\n",
              "      <td>16.316402</td>\n",
              "      <td>18.785184</td>\n",
              "      <td>44.476544</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>14.789065</td>\n",
              "      <td>18.316402</td>\n",
              "      <td>10.316402</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6054818 rows × 47 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR  ...  WEATHER_DELAY_is_missing\n",
              "0        2015.0  ...                       1.0\n",
              "1        2015.0  ...                       1.0\n",
              "2        2015.0  ...                       0.0\n",
              "3        2015.0  ...                       1.0\n",
              "4        2015.0  ...                       1.0\n",
              "...         ...  ...                       ...\n",
              "6054813  2015.0  ...                       1.0\n",
              "6054814  2015.0  ...                       1.0\n",
              "6054815  2015.0  ...                       0.0\n",
              "6054816  2015.0  ...                       0.0\n",
              "6054817  2015.0  ...                       0.0\n",
              "\n",
              "[6054818 rows x 47 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RIeo9LwFZl6W",
        "outputId": "fe542512-20b4-4c7e-8925-23a6a2f380f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_train[:4285507]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.308508</td>\n",
              "      <td>0.341235</td>\n",
              "      <td>0.082088</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>80.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1226.0</td>\n",
              "      <td>1219.0</td>\n",
              "      <td>4225.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>30.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.304283</td>\n",
              "      <td>0.294836</td>\n",
              "      <td>0.130962</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>85.0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1309.0</td>\n",
              "      <td>1302.0</td>\n",
              "      <td>4446.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.257698</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.998464</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>90.0</td>\n",
              "      <td>425.0</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1282.0</td>\n",
              "      <td>1232.0</td>\n",
              "      <td>3175.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>20.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.282126</td>\n",
              "      <td>0.305712</td>\n",
              "      <td>0.070847</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>306.0</td>\n",
              "      <td>2370.0</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>4025.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>35.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.316538</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.076309</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>120.0</td>\n",
              "      <td>545.0</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>343.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>3545.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4285502</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.276684</td>\n",
              "      <td>0.340097</td>\n",
              "      <td>0.130962</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1092.0</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1257.0</td>\n",
              "      <td>1268.0</td>\n",
              "      <td>1722.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4285503</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>22.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.254685</td>\n",
              "      <td>0.300638</td>\n",
              "      <td>0.082088</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>136.0</td>\n",
              "      <td>821.0</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>397.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>55.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4285504</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.298798</td>\n",
              "      <td>0.341235</td>\n",
              "      <td>0.070847</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>163.0</td>\n",
              "      <td>954.0</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1005.0</td>\n",
              "      <td>935.0</td>\n",
              "      <td>4154.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>55.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4285505</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.205637</td>\n",
              "      <td>0.313753</td>\n",
              "      <td>0.091677</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>52.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>636.0</td>\n",
              "      <td>637.0</td>\n",
              "      <td>2231.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4285506</th>\n",
              "      <td>2015.0</td>\n",
              "      <td>6.212617</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.480307</td>\n",
              "      <td>0.248783</td>\n",
              "      <td>0.294836</td>\n",
              "      <td>0.127936</td>\n",
              "      <td>12.692924</td>\n",
              "      <td>75.0</td>\n",
              "      <td>368.0</td>\n",
              "      <td>62.173231</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1314.0</td>\n",
              "      <td>1302.0</td>\n",
              "      <td>4688.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.133845</td>\n",
              "      <td>10.133845</td>\n",
              "      <td>10.960614</td>\n",
              "      <td>23.826769</td>\n",
              "      <td>25.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10.133845</td>\n",
              "      <td>36.519693</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4285507 rows × 47 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR  ...  WEATHER_DELAY_is_missing\n",
              "0        2015.0  ...                       1.0\n",
              "1        2015.0  ...                       1.0\n",
              "2        2015.0  ...                       0.0\n",
              "3        2015.0  ...                       1.0\n",
              "4        2015.0  ...                       1.0\n",
              "...         ...  ...                       ...\n",
              "4285502  2015.0  ...                       1.0\n",
              "4285503  2015.0  ...                       1.0\n",
              "4285504  2015.0  ...                       0.0\n",
              "4285505  2015.0  ...                       1.0\n",
              "4285506  2015.0  ...                       1.0\n",
              "\n",
              "[4285507 rows x 47 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XDNQRu46FrIu",
        "outputId": "217bab1c-9936-4ed3-f179-d8d201d256b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "Y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054813</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054814</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054815</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054816</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054817</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6054818 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         OUTCOME\n",
              "0              0\n",
              "1              0\n",
              "2              1\n",
              "3              0\n",
              "4              0\n",
              "...          ...\n",
              "6054813        1\n",
              "6054814        1\n",
              "6054815        1\n",
              "6054816        1\n",
              "6054817        1\n",
              "\n",
              "[6054818 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B5vXc6IeFrS4",
        "outputId": "16ff99a5-6c69-44d0-cde5-e49e9ba7eaf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>US</th>\n",
              "      <th>VX</th>\n",
              "      <th>WN</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>0.261397</td>\n",
              "      <td>0.277054</td>\n",
              "      <td>0.889772</td>\n",
              "      <td>23.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>930</td>\n",
              "      <td>124.0</td>\n",
              "      <td>0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57</td>\n",
              "      <td>15</td>\n",
              "      <td>3078</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>21</td>\n",
              "      <td>59</td>\n",
              "      <td>35</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.276077</td>\n",
              "      <td>0.306426</td>\n",
              "      <td>0.160310</td>\n",
              "      <td>14.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>612</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "      <td>65</td>\n",
              "      <td>1082</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>39</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.254685</td>\n",
              "      <td>0.353796</td>\n",
              "      <td>0.082088</td>\n",
              "      <td>24.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>152</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>237</td>\n",
              "      <td>386</td>\n",
              "      <td>277</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>52</td>\n",
              "      <td>13</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>0.319731</td>\n",
              "      <td>0.283453</td>\n",
              "      <td>0.996226</td>\n",
              "      <td>16.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>550</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>21</td>\n",
              "      <td>91</td>\n",
              "      <td>1380</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>57</td>\n",
              "      <td>9</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0.282126</td>\n",
              "      <td>0.287523</td>\n",
              "      <td>0.113494</td>\n",
              "      <td>8.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>1050</td>\n",
              "      <td>129.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1301</td>\n",
              "      <td>1305</td>\n",
              "      <td>4029</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>20</td>\n",
              "      <td>28</td>\n",
              "      <td>30</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428430</th>\n",
              "      <td>2015</td>\n",
              "      <td>11</td>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>0.308508</td>\n",
              "      <td>0.284717</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>1464</td>\n",
              "      <td>167.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85</td>\n",
              "      <td>21</td>\n",
              "      <td>4210</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "      <td>49</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428431</th>\n",
              "      <td>2015</td>\n",
              "      <td>10</td>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>0.201649</td>\n",
              "      <td>0.238668</td>\n",
              "      <td>0.975365</td>\n",
              "      <td>50.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>813</td>\n",
              "      <td>99.0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>250</td>\n",
              "      <td>237</td>\n",
              "      <td>547</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>17</td>\n",
              "      <td>55</td>\n",
              "      <td>21</td>\n",
              "      <td>34</td>\n",
              "      <td>15</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428432</th>\n",
              "      <td>2015</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "      <td>0.318843</td>\n",
              "      <td>0.288808</td>\n",
              "      <td>0.099772</td>\n",
              "      <td>9.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>255</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1159</td>\n",
              "      <td>1183</td>\n",
              "      <td>2431</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>32</td>\n",
              "      <td>35</td>\n",
              "      <td>44</td>\n",
              "      <td>16</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428433</th>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>0.282422</td>\n",
              "      <td>0.358423</td>\n",
              "      <td>0.063157</td>\n",
              "      <td>10.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>764</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>410</td>\n",
              "      <td>495</td>\n",
              "      <td>432</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>35</td>\n",
              "      <td>47</td>\n",
              "      <td>13</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428434</th>\n",
              "      <td>2015</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0.231242</td>\n",
              "      <td>0.268731</td>\n",
              "      <td>0.113494</td>\n",
              "      <td>15.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>468</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1239</td>\n",
              "      <td>1278</td>\n",
              "      <td>610</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1428435 rows × 47 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         YEAR  MONTH  ...  LATE_AIRCRAFT_DELAY_is_missing  WEATHER_DELAY_is_missing\n",
              "0        2015      8  ...                               0                         0\n",
              "1        2015     11  ...                               1                         1\n",
              "2        2015      1  ...                               1                         1\n",
              "3        2015      3  ...                               0                         0\n",
              "4        2015      6  ...                               1                         1\n",
              "...       ...    ...  ...                             ...                       ...\n",
              "1428430  2015     11  ...                               0                         0\n",
              "1428431  2015     10  ...                               0                         0\n",
              "1428432  2015      4  ...                               1                         1\n",
              "1428433  2015     12  ...                               1                         1\n",
              "1428434  2015      4  ...                               1                         1\n",
              "\n",
              "[1428435 rows x 47 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KrZdDvSZFrcm",
        "outputId": "3f196928-c9ce-4d7f-cd58-b11d1e4767b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428430</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428431</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428432</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428433</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428434</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1428435 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         OUTCOME\n",
              "0              1\n",
              "1              0\n",
              "2              0\n",
              "3              1\n",
              "4              0\n",
              "...          ...\n",
              "1428430        1\n",
              "1428431        1\n",
              "1428432        0\n",
              "1428433        0\n",
              "1428434        1\n",
              "\n",
              "[1428435 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FO3YyADUn0UN",
        "colab": {}
      },
      "source": [
        "####Unused as it would be used for regression problems\n",
        "from sklearn.feature_selection import SelectPercentile, f_regression                      \n",
        "Selector_f = SelectPercentile(f_regression, percentile=25)\n",
        "Selector_f.fit(X,y)\n",
        "for n,s in zip(Unhandled_data.feature_names,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s \" % (s,n))\n",
        "Selector_f.get_support(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SpVyYrOyGYoH",
        "outputId": "789eed14-ccd1-42b7-c4d6-6491c12ee407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "X_train.columns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT',\n",
              "       'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'SCHEDULED_TIME',\n",
              "       'DISTANCE', 'AIR_TIME', 'DIVERTED', 'AIR_SYSTEM_DELAY',\n",
              "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
              "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
              "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
              "       'AA', 'AS', 'B6', 'DL', 'EV', 'F9', 'HA', 'MQ', 'NK', 'OO', 'UA', 'US',\n",
              "       'VX', 'WN', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR',\n",
              "       'SCHEDULED_ARRIVAL_HOUR', 'DEPARTURE_TIME_MINUTE',\n",
              "       'SCHEDULED_DEPARTURE_MINUTE', 'SCHEDULED_ARRIVAL_MINUTE',\n",
              "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
              "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
              "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ubU8RqqzAvk",
        "colab_type": "code",
        "outputId": "a4f51284-070d-4ab8-c071-8377133fc413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=25)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 20994.57t for feature MONTH\n",
            "F-score: 465.26t for feature DAY\n",
            "F-score: 1357.67t for feature DAY_OF_WEEK\n",
            "F-score: 45887.35t for feature ORIGIN_AIRPORT\n",
            "F-score: 31786.85t for feature DESTINATION_AIRPORT\n",
            "F-score: 5060519.01t for feature DEPARTURE_DELAY\n",
            "F-score: 436147.33t for feature TAXI_OUT\n",
            "F-score: 30.21t for feature SCHEDULED_TIME\n",
            "F-score: 319.48t for feature DISTANCE\n",
            "F-score: 6958.08t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 394931.17t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 2366.62t for feature SECURITY_DELAY\n",
            "F-score: 274327.67t for feature AIRLINE_DELAY\n",
            "F-score: 507572.07t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 34800.73t for feature WEATHER_DELAY\n",
            "F-score: 8031.96t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 8412.68t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 11.39t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 216.02t for feature AA\n",
            "F-score: 2326.96t for feature AS\n",
            "F-score: 1905.15t for feature B6\n",
            "F-score: 32498.08t for feature DL\n",
            "F-score: 846.38t for feature EV\n",
            "F-score: 3963.47t for feature F9\n",
            "F-score: 355.71t for feature HA\n",
            "F-score: 621.28t for feature MQ\n",
            "F-score: 10689.09t for feature NK\n",
            "F-score: 489.94t for feature OO\n",
            "F-score: 396.72t for feature UA\n",
            "F-score: 476.43t for feature US\n",
            "F-score: 174.41t for feature VX\n",
            "F-score: 992.70t for feature WN\n",
            "F-score: 235595.84t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 143114.70t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 115483.34t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 4747.94t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 2509.46t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 2.40t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 237523.33t for feature WHEELS_OFF_HOUR\n",
            "F-score: 6690.01t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 5150156.46t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature WEATHER_DELAY_is_missing\n",
            "Index(['DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'DEPARTURE_TIME_HOUR', 'WHEELS_OFF_HOUR',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
            "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
            "       'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DMVewQKgHfpC",
        "outputId": "60d9769a-7700-4bbb-9cfc-67c32c8131d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=50)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 20994.57t for feature MONTH\n",
            "F-score: 465.26t for feature DAY\n",
            "F-score: 1357.67t for feature DAY_OF_WEEK\n",
            "F-score: 45887.35t for feature ORIGIN_AIRPORT\n",
            "F-score: 31786.85t for feature DESTINATION_AIRPORT\n",
            "F-score: 5060519.01t for feature DEPARTURE_DELAY\n",
            "F-score: 436147.33t for feature TAXI_OUT\n",
            "F-score: 30.21t for feature SCHEDULED_TIME\n",
            "F-score: 319.48t for feature DISTANCE\n",
            "F-score: 6958.08t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 394931.17t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 2366.62t for feature SECURITY_DELAY\n",
            "F-score: 274327.67t for feature AIRLINE_DELAY\n",
            "F-score: 507572.07t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 34800.73t for feature WEATHER_DELAY\n",
            "F-score: 8031.96t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 8412.68t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 11.39t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 216.02t for feature AA\n",
            "F-score: 2326.96t for feature AS\n",
            "F-score: 1905.15t for feature B6\n",
            "F-score: 32498.08t for feature DL\n",
            "F-score: 846.38t for feature EV\n",
            "F-score: 3963.47t for feature F9\n",
            "F-score: 355.71t for feature HA\n",
            "F-score: 621.28t for feature MQ\n",
            "F-score: 10689.09t for feature NK\n",
            "F-score: 489.94t for feature OO\n",
            "F-score: 396.72t for feature UA\n",
            "F-score: 476.43t for feature US\n",
            "F-score: 174.41t for feature VX\n",
            "F-score: 992.70t for feature WN\n",
            "F-score: 235595.84t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 143114.70t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 115483.34t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 4747.94t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 2509.46t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 2.40t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 237523.33t for feature WHEELS_OFF_HOUR\n",
            "F-score: 6690.01t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 5150156.46t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature WEATHER_DELAY_is_missing\n",
            "Index(['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
            "       'TAXI_OUT', 'AIR_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'DL', 'NK', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
            "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
            "       'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TyOUNz2dgJAq",
        "outputId": "482c14e5-ec82-4f80-b8b6-d633428f8f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=75)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 20994.57t for feature MONTH\n",
            "F-score: 465.26t for feature DAY\n",
            "F-score: 1357.67t for feature DAY_OF_WEEK\n",
            "F-score: 45887.35t for feature ORIGIN_AIRPORT\n",
            "F-score: 31786.85t for feature DESTINATION_AIRPORT\n",
            "F-score: 5060519.01t for feature DEPARTURE_DELAY\n",
            "F-score: 436147.33t for feature TAXI_OUT\n",
            "F-score: 30.21t for feature SCHEDULED_TIME\n",
            "F-score: 319.48t for feature DISTANCE\n",
            "F-score: 6958.08t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 394931.17t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 2366.62t for feature SECURITY_DELAY\n",
            "F-score: 274327.67t for feature AIRLINE_DELAY\n",
            "F-score: 507572.07t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 34800.73t for feature WEATHER_DELAY\n",
            "F-score: 8031.96t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 8412.68t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 11.39t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 216.02t for feature AA\n",
            "F-score: 2326.96t for feature AS\n",
            "F-score: 1905.15t for feature B6\n",
            "F-score: 32498.08t for feature DL\n",
            "F-score: 846.38t for feature EV\n",
            "F-score: 3963.47t for feature F9\n",
            "F-score: 355.71t for feature HA\n",
            "F-score: 621.28t for feature MQ\n",
            "F-score: 10689.09t for feature NK\n",
            "F-score: 489.94t for feature OO\n",
            "F-score: 396.72t for feature UA\n",
            "F-score: 476.43t for feature US\n",
            "F-score: 174.41t for feature VX\n",
            "F-score: 992.70t for feature WN\n",
            "F-score: 235595.84t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 143114.70t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 115483.34t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 4747.94t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 2509.46t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 2.40t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 237523.33t for feature WHEELS_OFF_HOUR\n",
            "F-score: 6690.01t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 5150156.46t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 5150156.46t for feature WEATHER_DELAY_is_missing\n",
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'AS', 'B6', 'DL', 'EV', 'F9', 'MQ', 'NK',\n",
            "       'OO', 'WN', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR',\n",
            "       'SCHEDULED_ARRIVAL_HOUR', 'DEPARTURE_TIME_MINUTE',\n",
            "       'SCHEDULED_DEPARTURE_MINUTE', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
            "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
            "       'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H3DVM-Qtu-Fo",
        "outputId": "e494dde8-9894-4412-8d7e-968e9be856aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=25)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 35026.84t for feature MONTH \n",
            "F-score: 2123.78t for feature DAY \n",
            "F-score: 1232.63t for feature DAY_OF_WEEK \n",
            "F-score: 190.28t for feature ORIGIN_AIRPORT \n",
            "F-score: 92.66t for feature DESTINATION_AIRPORT \n",
            "F-score: 940956.15t for feature DEPARTURE_DELAY \n",
            "F-score: 2344154.23t for feature TAXI_OUT \n",
            "F-score: 1208.02t for feature SCHEDULED_TIME \n",
            "F-score: 143425.28t for feature DISTANCE \n",
            "F-score: 321832.48t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 24114100.87t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 113239.16t for feature SECURITY_DELAY \n",
            "F-score: 34816756.63t for feature AIRLINE_DELAY \n",
            "F-score: 43592722.61t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 5045192.67t for feature WEATHER_DELAY \n",
            "F-score: 2340246.60t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 2452913.37t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 8882.95t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 189.26t for feature AA \n",
            "F-score: 2258.94t for feature AS \n",
            "F-score: 1813.79t for feature B6 \n",
            "F-score: 27740.16t for feature DL \n",
            "F-score: 762.97t for feature EV \n",
            "F-score: 3892.20t for feature F9 \n",
            "F-score: 351.08t for feature HA \n",
            "F-score: 590.27t for feature MQ \n",
            "F-score: 10425.18t for feature NK \n",
            "F-score: 439.82t for feature OO \n",
            "F-score: 361.05t for feature UA \n",
            "F-score: 459.79t for feature US \n",
            "F-score: 172.41t for feature VX \n",
            "F-score: 774.31t for feature WN \n",
            "F-score: 406109.74t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 232819.79t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 188495.14t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 49159.15t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 30271.30t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 25.49t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 403800.18t for feature WHEELS_OFF_HOUR \n",
            "F-score: 66352.63t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 832561.49t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 832561.49t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 832561.49t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 832561.49t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 832561.49t for feature WEATHER_DELAY_is_missing \n",
            "Index(['DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iZMAvNE7E9NS",
        "outputId": "89cf3f7b-b547-4ad8-86fc-3a42b120cb88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=50)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 35026.84t for feature MONTH \n",
            "F-score: 2123.78t for feature DAY \n",
            "F-score: 1232.63t for feature DAY_OF_WEEK \n",
            "F-score: 190.28t for feature ORIGIN_AIRPORT \n",
            "F-score: 92.66t for feature DESTINATION_AIRPORT \n",
            "F-score: 940956.15t for feature DEPARTURE_DELAY \n",
            "F-score: 2344154.23t for feature TAXI_OUT \n",
            "F-score: 1208.02t for feature SCHEDULED_TIME \n",
            "F-score: 143425.28t for feature DISTANCE \n",
            "F-score: 321832.48t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 24114100.87t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 113239.16t for feature SECURITY_DELAY \n",
            "F-score: 34816756.63t for feature AIRLINE_DELAY \n",
            "F-score: 43592722.61t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 5045192.67t for feature WEATHER_DELAY \n",
            "F-score: 2340246.60t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 2452913.37t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 8882.95t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 189.26t for feature AA \n",
            "F-score: 2258.94t for feature AS \n",
            "F-score: 1813.79t for feature B6 \n",
            "F-score: 27740.16t for feature DL \n",
            "F-score: 762.97t for feature EV \n",
            "F-score: 3892.20t for feature F9 \n",
            "F-score: 351.08t for feature HA \n",
            "F-score: 590.27t for feature MQ \n",
            "F-score: 10425.18t for feature NK \n",
            "F-score: 439.82t for feature OO \n",
            "F-score: 361.05t for feature UA \n",
            "F-score: 459.79t for feature US \n",
            "F-score: 172.41t for feature VX \n",
            "F-score: 774.31t for feature WN \n",
            "F-score: 406109.74t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 232819.79t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 188495.14t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 49159.15t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 30271.30t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 25.49t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 403800.18t for feature WHEELS_OFF_HOUR \n",
            "F-score: 66352.63t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 832561.49t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 832561.49t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 832561.49t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 832561.49t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 832561.49t for feature WEATHER_DELAY_is_missing \n",
            "Index(['MONTH', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'AIR_TIME',\n",
            "       'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR',\n",
            "       'DEPARTURE_TIME_MINUTE', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
            "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
            "       'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5E3V06WmE_4l",
        "outputId": "8e141de8-ccee-4f42-a527-0feb9902801a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=75)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 35026.84t for feature MONTH \n",
            "F-score: 2123.78t for feature DAY \n",
            "F-score: 1232.63t for feature DAY_OF_WEEK \n",
            "F-score: 190.28t for feature ORIGIN_AIRPORT \n",
            "F-score: 92.66t for feature DESTINATION_AIRPORT \n",
            "F-score: 940956.15t for feature DEPARTURE_DELAY \n",
            "F-score: 2344154.23t for feature TAXI_OUT \n",
            "F-score: 1208.02t for feature SCHEDULED_TIME \n",
            "F-score: 143425.28t for feature DISTANCE \n",
            "F-score: 321832.48t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 24114100.87t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 113239.16t for feature SECURITY_DELAY \n",
            "F-score: 34816756.63t for feature AIRLINE_DELAY \n",
            "F-score: 43592722.61t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 5045192.67t for feature WEATHER_DELAY \n",
            "F-score: 2340246.60t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 2452913.37t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 8882.95t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 189.26t for feature AA \n",
            "F-score: 2258.94t for feature AS \n",
            "F-score: 1813.79t for feature B6 \n",
            "F-score: 27740.16t for feature DL \n",
            "F-score: 762.97t for feature EV \n",
            "F-score: 3892.20t for feature F9 \n",
            "F-score: 351.08t for feature HA \n",
            "F-score: 590.27t for feature MQ \n",
            "F-score: 10425.18t for feature NK \n",
            "F-score: 439.82t for feature OO \n",
            "F-score: 361.05t for feature UA \n",
            "F-score: 459.79t for feature US \n",
            "F-score: 172.41t for feature VX \n",
            "F-score: 774.31t for feature WN \n",
            "F-score: 406109.74t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 232819.79t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 188495.14t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 49159.15t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 30271.30t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 25.49t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 403800.18t for feature WHEELS_OFF_HOUR \n",
            "F-score: 66352.63t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 832561.49t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 832561.49t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 832561.49t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 832561.49t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 832561.49t for feature WEATHER_DELAY_is_missing \n",
            "Index(['MONTH', 'DAY', 'DAY_OF_WEEK', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'SCHEDULED_TIME', 'DISTANCE', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
            "       'AS', 'B6', 'DL', 'EV', 'F9', 'NK', 'WN', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR',\n",
            "       'DEPARTURE_TIME_MINUTE', 'SCHEDULED_DEPARTURE_MINUTE',\n",
            "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
            "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nnPzt_pvDJs6",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "val_df, test_df = train_test_split(test_data, test_size=0.333, random_state=0)\n",
        "\n",
        "#Y_train=pd.DataFrame(train_data['OUTCOME'])\n",
        "#X_train=train_data.drop(\"OUTCOME\",axis=1)\n",
        "\n",
        "Y_test=pd.DataFrame(test_df['OUTCOME'])\n",
        "X_test=test_df.drop(\"OUTCOME\",axis=1)\n",
        "\n",
        "Y_valid=pd.DataFrame(val_df['OUTCOME'])\n",
        "X_valid=val_df.drop(\"OUTCOME\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s_vLx-nobFzs",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer,accuracy_score,roc_auc_score\n",
        "from sklearn import metrics\n",
        "\n",
        "def cross_validation(model,X,y):\n",
        "  scores = cross_validate(model, X, y, scoring={'accuracy':make_scorer(accuracy_score),'roc_auc':make_scorer(roc_auc_score)},cv=5)\n",
        "  print(\"Cross-validated scores:\", scores)\n",
        "  print(\"cross for accuracy\",scores['test_accuracy'])\n",
        "  print(\"cross for roc-auc\",scores['test_roc_auc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZIBZy8h6bUmh",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "def report(Y_test,pred):\n",
        "  score1=metrics.roc_auc_score(Y_test,pred)\n",
        "  score2=metrics.accuracy_score(Y_test,pred)\n",
        "\n",
        "  print(f\"Test ROC AUC score: {score1}\")\n",
        "  print(f\"Test accuracy score: {score2}\")\n",
        "  print(\"Confusion matrix is \",metrics.confusion_matrix(Y_test,pred))\n",
        "  print(\"Classification report is \\n\",metrics.classification_report(Y_test,pred))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "REAFrlKudcHT",
        "colab": {}
      },
      "source": [
        "from math import log\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def calculate_aic(n, mse, num_params):\n",
        "\taic = n * log(mse) + 2 * num_params\n",
        "\treturn aic\n",
        "\n",
        "def calculate_bic(n, mse, num_params):\n",
        "\tbic = n * log(mse) + num_params * log(n)\n",
        "\treturn bic\n",
        "  \n",
        "def aic_and_bic(Y_test,pred,num_params):\n",
        "  mse=mean_squared_error(Y_test,pred)\n",
        "  print(pred)\n",
        "  print('Number of parameters: %d' % (num_params))\n",
        "  aic=calculate_aic(len(Y_train), mse, num_params)\n",
        "  print('AIC: %.3f' % aic)\n",
        "  bic = calculate_bic(len(y), mse, num_params)\n",
        "  print('BIC: %.3f' % bic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0jLcuAH-cSKo",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.svm import *\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iePhsaLZ50Im",
        "colab_type": "code",
        "outputId": "7d67a325-fa60-4ea8-b1b9-5d6b20a4e02a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "cols=['MONTH','ORIGIN_AIRPORT','DESTINATION_AIRPORT','DEPARTURE_DELAY','TAXI_OUT','DISTANCE','SCHEDULED_TIME',\n",
        "'AIR_SYSTEM_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY','SECURITY_DELAY','AIRLINE_ORIGIN_AIRPORT','AIRLINE_DESTINATION_AIRPORT',\n",
        "'DEPARTURE_TIME_HOUR','WHEELS_OFF_MINUTE',\n",
        "'AIR_SYSTEM_DELAY_is_missing','SECURITY_DELAY_is_missing','AIRLINE_DELAY_is_missing','LATE_AIRCRAFT_DELAY_is_missing','WEATHER_DELAY_is_missing']\n",
        "print(cols)#'SCHEDULED_DEPARTURE_HOUR','SCHEDULED_ARRIVAL_HOUR','WHEELS_OFF_HOUR',\n",
        "print(len(cols))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n",
            "21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Qio4-8g6aQJ",
        "outputId": "49ca6d86-2bfc-4b81-fd5e-fb26759e3aa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "selected_X_train=X_train[cols]\n",
        "print(selected_X_train)\n",
        "\n",
        "lgbmclassifier=LGBMClassifier()\n",
        "selector = RFECV(estimator=lgbmclassifier, cv=5,scoring='accuracy',n_jobs=1)\n",
        "selector.fit(selected_X_train,Y_train)\n",
        "print(\"Optimal number of features: %d\" % selector.n_features_)\n",
        "print(selected_X_train.columns[selector.support_])\n",
        "print(selector.ranking_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             MONTH  ...  WEATHER_DELAY_is_missing\n",
            "0         4.000000  ...                       1.0\n",
            "1         7.000000  ...                       1.0\n",
            "2         5.000000  ...                       0.0\n",
            "3        11.000000  ...                       1.0\n",
            "4         8.000000  ...                       1.0\n",
            "...            ...  ...                       ...\n",
            "6054813   8.127057  ...                       1.0\n",
            "6054814   1.512993  ...                       1.0\n",
            "6054815   6.751592  ...                       0.0\n",
            "6054816   3.000000  ...                       0.0\n",
            "6054817   6.210935  ...                       0.0\n",
            "\n",
            "[6054818 rows x 24 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimal number of features: 13\n",
            "Index(['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
            "       'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE_HOUR',\n",
            "       'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR',\n",
            "       'AIR_SYSTEM_DELAY_is_missing'],\n",
            "      dtype='object')\n",
            "[ 1  1  1  1  1  1  1  4  6  8 10 12  1  1  2  1  1  1  3  1  5  7  9 11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4isf5vUsOzx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "2282bbab-276b-48c9-8e26-2f165813115c"
      },
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "selected_X_train=X_train[cols]\n",
        "print(selected_X_train)\n",
        "\n",
        "lgbmclassifier=LGBMClassifier()\n",
        "selector = RFECV(estimator=lgbmclassifier, cv=5,scoring='accuracy',n_jobs=1)\n",
        "selector.fit(selected_X_train,Y_train)\n",
        "print(\"Optimal number of features: %d\" % selector.n_features_)\n",
        "print(selected_X_train.columns[selector.support_])\n",
        "print(selector.ranking_)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             MONTH  ...  WEATHER_DELAY_is_missing\n",
            "0         4.000000  ...                       1.0\n",
            "1         7.000000  ...                       1.0\n",
            "2         5.000000  ...                       0.0\n",
            "3        11.000000  ...                       1.0\n",
            "4         8.000000  ...                       1.0\n",
            "...            ...  ...                       ...\n",
            "6054813   8.127057  ...                       1.0\n",
            "6054814   1.512993  ...                       1.0\n",
            "6054815   6.751592  ...                       0.0\n",
            "6054816   3.000000  ...                       0.0\n",
            "6054817   6.210935  ...                       0.0\n",
            "\n",
            "[6054818 rows x 21 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimal number of features: 10\n",
            "Index(['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
            "       'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', 'AIR_SYSTEM_DELAY_is_missing'],\n",
            "      dtype='object')\n",
            "[ 1  1  1  1  1  1  1  7  9 11 12 10  1  1  2  6  1  5  4  3  8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "raZFbf_bIrHa",
        "outputId": "7bb25f49-4095-4485-c992-c99538e5d0af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "selected_X_train=X_train[cols]\n",
        "print(selected_X_train)\n",
        "\n",
        "model = LGBMClassifier()\n",
        "model.fit(selected_X_train,Y_train)\n",
        "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "#plot graph of feature importances for better visualization\n",
        "feat_importances = pd.Series(model.feature_importances_, index=selected_X_train.columns)\n",
        "feat_importances.nlargest(24).plot(kind='barh')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             MONTH  ...  WEATHER_DELAY_is_missing\n",
            "0         4.000000  ...                       1.0\n",
            "1         7.000000  ...                       1.0\n",
            "2         5.000000  ...                       0.0\n",
            "3        11.000000  ...                       1.0\n",
            "4         8.000000  ...                       1.0\n",
            "...            ...  ...                       ...\n",
            "6054813   8.127057  ...                       1.0\n",
            "6054814   1.512993  ...                       1.0\n",
            "6054815   6.751592  ...                       0.0\n",
            "6054816   3.000000  ...                       0.0\n",
            "6054817   6.210935  ...                       0.0\n",
            "\n",
            "[6054818 rows x 24 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[238 213  42 704 747 284 360   0   0   0   0   0 196  72  10  12  28  14\n",
            "   0  80   0   0   0   0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEoNAdnTL873",
        "colab_type": "code",
        "outputId": "9acd8883-e7d4-471d-e9d9-f4df4449b46a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cols_after_removing_recursive=['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
        "       'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT',\n",
        "       'AIRLINE_DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE_HOUR',\n",
        "       'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR',\n",
        "       'AIR_SYSTEM_DELAY_is_missing']\n",
        "print(len(cols_after_removing_recursive))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5pi4gQReHbqt",
        "outputId": "c1150a4d-2c49-4fa1-c709-955bdbe9366a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpBernoulliNBModel():\n",
        "  model = BernoulliNB()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpBernoulliNBModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8176742955101963\n",
            "Test accuracy score: 0.8929310749176547\n",
            "Confusion matrix is  [[1009018       0]\n",
            " [ 152941  266476]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93   1009018\n",
            "           1       1.00      0.64      0.78    419417\n",
            "\n",
            "    accuracy                           0.89   1428435\n",
            "   macro avg       0.93      0.82      0.85   1428435\n",
            "weighted avg       0.91      0.89      0.88   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([4.02533007, 2.54916596, 2.55393291, 2.55440617, 2.59539628]), 'score_time': array([0.74628329, 0.73334026, 0.73816514, 0.75022101, 0.73059821]), 'test_accuracy': array([0.89224958, 0.89253475, 0.89226873, 0.89243149, 0.89311053]), 'test_roc_auc': array([0.81649046, 0.81697576, 0.81652325, 0.81680045, 0.81795692])}\n",
            "cross for accuracy [0.89224958 0.89253475 0.89226873 0.89243149 0.89311053]\n",
            "cross for roc-auc [0.81649046 0.81697576 0.81652325 0.81680045 0.81795692]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y5T6_ef4OO_u",
        "outputId": "42f8f237-7925-40ae-9908-09e5360082f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpLinearSVCModel():\n",
        "  model = LinearSVC()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpLinearSVCModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8702226924092784\n",
            "Test accuracy score: 0.8776304137045088\n",
            "Confusion matrix is  [[896179 112839]\n",
            " [ 61958 357459]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.89      0.91   1009018\n",
            "           1       0.76      0.85      0.80    419417\n",
            "\n",
            "    accuracy                           0.88   1428435\n",
            "   macro avg       0.85      0.87      0.86   1428435\n",
            "weighted avg       0.88      0.88      0.88   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([3081.71970844, 3051.46147275, 2886.84516859, 2654.25043535,\n",
            "       2552.9044137 ]), 'score_time': array([0.54690695, 0.55531693, 0.58428001, 0.71781397, 0.70923042]), 'test_accuracy': array([0.87662639, 0.90151542, 0.89231336, 0.91299524, 0.73374327]), 'test_roc_auc': array([0.84201889, 0.83442459, 0.81856845, 0.87189416, 0.76420607])}\n",
            "cross for accuracy [0.87662639 0.90151542 0.89231336 0.91299524 0.73374327]\n",
            "cross for roc-auc [0.84201889 0.83442459 0.81856845 0.87189416 0.76420607]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Pfvps8ZPgE2",
        "outputId": "a21eddad-9038-4f87-ba9d-682cb16f5de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpLGBMClassifierModel():\n",
        "  model = LGBMClassifier(random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8835184663748327\n",
            "Test accuracy score: 0.9192360870463129\n",
            "Confusion matrix is  [[978800  30218]\n",
            " [ 85148 334269]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94   1009018\n",
            "           1       0.92      0.80      0.85    419417\n",
            "\n",
            "    accuracy                           0.92   1428435\n",
            "   macro avg       0.92      0.88      0.90   1428435\n",
            "weighted avg       0.92      0.92      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([41.22812128, 40.24779701, 39.54788852, 39.78039384, 39.87078381]), 'score_time': array([3.31302762, 3.32302547, 3.34789038, 3.37988997, 3.29774284]), 'test_accuracy': array([0.9203335 , 0.92077008, 0.92059507, 0.92129774, 0.92163113]), 'test_roc_auc': array([0.87939089, 0.88030232, 0.87978335, 0.88089036, 0.88147384])}\n",
            "cross for accuracy [0.9203335  0.92077008 0.92059507 0.92129774 0.92163113]\n",
            "cross for roc-auc [0.87939089 0.88030232 0.87978335 0.88089036 0.88147384]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W-dq1z4DYbE7",
        "outputId": "0328fe72-2abd-4299-fef0-688518f60333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpDecisionTreeModel():\n",
        "  tree = DecisionTreeClassifier(random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  tree.fit(sel_X_train, Y_train)\n",
        "  pred=tree.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(tree,X,y)\n",
        "\n",
        "runexpDecisionTreeModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n",
            "predictions are  [0 1 0 ... 0 0 1]\n",
            "Test ROC AUC score: 0.8534604689864477\n",
            "Test accuracy score: 0.8752767155311781\n",
            "Confusion matrix is  [[304381  31424]\n",
            " [ 27903 111961]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.91      0.91    335805\n",
            "           1       0.78      0.80      0.79    139864\n",
            "\n",
            "    accuracy                           0.88    475669\n",
            "   macro avg       0.85      0.85      0.85    475669\n",
            "weighted avg       0.88      0.88      0.88    475669\n",
            "\n",
            "\n",
            "\n",
            "Cross-validated scores: {'fit_time': array([98.33280826, 98.03923869, 96.89853787, 98.87323689, 96.7072258 ]), 'score_time': array([0.79567885, 0.80918908, 0.79715633, 0.79890203, 0.79836798]), 'test_accuracy': array([0.87706396, 0.87722568, 0.8766859 , 0.87769196, 0.87768776]), 'test_roc_auc': array([0.85492068, 0.85549495, 0.85448066, 0.85580723, 0.85612326])}\n",
            "cross for accuracy [0.87706396 0.87722568 0.8766859  0.87769196 0.87768776]\n",
            "cross for roc-auc [0.85492068 0.85549495 0.85448066 0.85580723 0.85612326]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1T8qD_h5S9mU",
        "outputId": "9cd5a4f6-05a8-436f-a54c-56f19432fadc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpRandomForestModel():\n",
        "  forest = RandomForestClassifier(max_features=16,max_depth=25,min_samples_leaf=10,random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  forest.fit(sel_X_train, Y_train)\n",
        "  pred=forest.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)                                         #91.87\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(forest,X,y)\n",
        "\n",
        "runexpRandomForestModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8820867826754215\n",
            "Test accuracy score: 0.9205585133380237\n",
            "Confusion matrix is  [[984088  24930]\n",
            " [ 88547 330870]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95   1009018\n",
            "           1       0.93      0.79      0.85    419417\n",
            "\n",
            "    accuracy                           0.92   1428435\n",
            "   macro avg       0.92      0.88      0.90   1428435\n",
            "weighted avg       0.92      0.92      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([6110.38994956, 4488.80710149, 4275.5737865 , 4204.35399055,\n",
            "       4153.96794605]), 'score_time': array([41.55245614, 41.19122052, 39.72275329, 41.90458846, 40.24595284]), 'test_accuracy': array([0.92165833, 0.92206779, 0.92205903, 0.92246593, 0.92285358]), 'test_roc_auc': array([0.88105758, 0.88187055, 0.8817018 , 0.88237476, 0.88290781])}\n",
            "cross for accuracy [0.92165833 0.92206779 0.92205903 0.92246593 0.92285358]\n",
            "cross for roc-auc [0.88105758 0.88187055 0.8817018  0.88237476 0.88290781]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "guOphXVvu15j",
        "outputId": "b6095b5e-7499-4bab-c256-0fa748a3c3ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLogisticRegressionModel():\n",
        "  lrmodel=LogisticRegression()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  lrmodel.fit(sel_X_train, Y_train)\n",
        "  pred=lrmodel.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(lrmodel,X,y)\n",
        "  num_params = len(lrmodel.coef_) + 1\n",
        "  aic_and_bic(Y_test,pred,num_params)\n",
        "\n",
        "runLogisticRegressionModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [0 1 0 ... 0 0 1]\n",
            "Test ROC AUC score: 0.8296774206409845\n",
            "Test accuracy score: 0.8885107080764145\n",
            "Confusion matrix is  [[326571   9234]\n",
            " [ 43798  96066]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92    335805\n",
            "           1       0.91      0.69      0.78    139864\n",
            "\n",
            "    accuracy                           0.89    475669\n",
            "   macro avg       0.90      0.83      0.85    475669\n",
            "weighted avg       0.89      0.89      0.88    475669\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([67.50734687, 65.93810582, 66.96874094, 66.1269958 , 65.12360954]), 'score_time': array([0.41015744, 0.42351747, 0.41843605, 0.40717268, 0.41280127]), 'test_accuracy': array([0.8936544 , 0.89500911, 0.89364285, 0.89404716, 0.8939663 ]), 'test_roc_auc': array([0.82146836, 0.82712552, 0.82564117, 0.82180698, 0.82085378])}\n",
            "cross for accuracy [0.8936544  0.89500911 0.89364285 0.89404716 0.8939663 ]\n",
            "cross for roc-auc [0.82146836 0.82712552 0.82564117 0.82180698 0.82085378]\n",
            "[0 1 0 ... 0 0 1]\n",
            "Number of parameters: 2\n",
            "AIC: -13283217.569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c89c4cf15e04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0maic_and_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrunLogisticRegressionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-c89c4cf15e04>\u001b[0m in \u001b[0;36mrunLogisticRegressionModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mnum_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0maic_and_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mrunLogisticRegressionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-15c7f88bee80>\u001b[0m in \u001b[0;36maic_and_bic\u001b[0;34m(Y_test, pred, num_params)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0maic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalculate_aic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AIC: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mbic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BIC: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBxc3eE0YXL8",
        "colab_type": "code",
        "outputId": "d218e3c2-23c8-4191-ebb4-8aa7d7f8ee2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runXGBClassifierModel():\n",
        "  model=XGBClassifier()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runXGBClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[12:14:03] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8799539221752859\n",
            "Test accuracy score: 0.9069905175944303\n",
            "Confusion matrix is  [[953982  55036]\n",
            " [ 77822 341595]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93   1009018\n",
            "           1       0.86      0.81      0.84    419417\n",
            "\n",
            "    accuracy                           0.91   1428435\n",
            "   macro avg       0.89      0.88      0.89   1428435\n",
            "weighted avg       0.91      0.91      0.91   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[13:00:04] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[13:33:07] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[14:06:18] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[14:39:28] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[15:12:40] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
            "Cross-validated scores: {'fit_time': array([1982.48600912, 1986.70746088, 1986.53589177, 1987.457937  ,\n",
            "       1982.43312955]), 'score_time': array([3.77771521, 3.85807991, 3.84304357, 3.85526156, 3.86914086]), 'test_accuracy': array([0.91359997, 0.91408205, 0.91418706, 0.91419406, 0.91461583]), 'test_roc_auc': array([0.8665095 , 0.86698104, 0.86721075, 0.86698055, 0.86812215])}\n",
            "cross for accuracy [0.91359997 0.91408205 0.91418706 0.91419406 0.91461583]\n",
            "cross for roc-auc [0.8665095  0.86698104 0.86721075 0.86698055 0.86812215]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VEX6VSX0SbJT",
        "outputId": "fc44a228-a295-424f-e7d2-8c09c057b98f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(max_bin=175,num_leaves=150,lambda_l1=2,lambda_l2=2,max_depth=100)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8864658355968845\n",
            "Test accuracy score: 0.9229394407165884\n",
            "Confusion matrix is  [[983622  25396]\n",
            " [ 84680 334737]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95   1009018\n",
            "           1       0.93      0.80      0.86    419417\n",
            "\n",
            "    accuracy                           0.92   1428435\n",
            "   macro avg       0.93      0.89      0.90   1428435\n",
            "weighted avg       0.92      0.92      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([60.28556156, 58.70853829, 59.37966013, 59.14075065, 58.98669577]), 'score_time': array([4.36771607, 4.28731585, 4.35411382, 4.39645362, 4.26688361]), 'test_accuracy': array([0.92274514, 0.92301722, 0.92293759, 0.92366826, 0.92380564]), 'test_roc_auc': array([0.8837847 , 0.88449522, 0.88409949, 0.8850948 , 0.88547858])}\n",
            "cross for accuracy [0.92274514 0.92301722 0.92293759 0.92366826 0.92380564]\n",
            "cross for roc-auc [0.8837847  0.88449522 0.88409949 0.8850948  0.88547858]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E9wkWA2b1USV",
        "outputId": "18a12aee-b2d9-4987-abc5-25604d1a0aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(max_bin=150,num_leaves=150,lambda_l1=5,lambda_l2=5,max_depth=90,bagging_fraction=0.8)#decrease bagging_fraction\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8863051495392817\n",
            "Test accuracy score: 0.9228610332286733\n",
            "Confusion matrix is  [[983661  25357]\n",
            " [ 84831 334586]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95   1009018\n",
            "           1       0.93      0.80      0.86    419417\n",
            "\n",
            "    accuracy                           0.92   1428435\n",
            "   macro avg       0.93      0.89      0.90   1428435\n",
            "weighted avg       0.92      0.92      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([59.39565849, 59.75253558, 58.57243896, 58.77869701, 60.90981364]), 'score_time': array([4.42929626, 4.32503486, 4.49348521, 4.35506034, 4.42180252]), 'test_accuracy': array([0.92274339, 0.92305047, 0.92290084, 0.923509  , 0.92384327]), 'test_roc_auc': array([0.88380785, 0.88453791, 0.88411963, 0.88505175, 0.88558011])}\n",
            "cross for accuracy [0.92274339 0.92305047 0.92290084 0.923509   0.92384327]\n",
            "cross for roc-auc [0.88380785 0.88453791 0.88411963 0.88505175 0.88558011]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OQQEenwR-EHf",
        "outputId": "3b88bfe8-75a1-4684-83bf-7406926d3a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(learning_rate=0.2,max_bin=150,num_leaves=250,min_data_in_leaf=300,lambda_l1=4,lambda_l2=4,max_depth=80,bagging_fraction=0.7)#decrease bagging_fraction\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8896156328262435\n",
            "Test accuracy score: 0.9252370601392433\n",
            "Confusion matrix is  [[984717  24301]\n",
            " [ 82493 336924]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95   1009018\n",
            "           1       0.93      0.80      0.86    419417\n",
            "\n",
            "    accuracy                           0.93   1428435\n",
            "   macro avg       0.93      0.89      0.91   1428435\n",
            "weighted avg       0.93      0.93      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([67.17893696, 66.94291735, 65.40629935, 65.40760207, 64.98969841]), 'score_time': array([5.00798702, 5.02646971, 5.04435062, 5.04537511, 4.97464848]), 'test_accuracy': array([0.92467201, 0.92484083, 0.92466494, 0.92539649, 0.92560387]), 'test_roc_auc': array([0.88757584, 0.88820022, 0.88781038, 0.88874621, 0.88905413])}\n",
            "cross for accuracy [0.92467201 0.92484083 0.92466494 0.92539649 0.92560387]\n",
            "cross for roc-auc [0.88757584 0.88820022 0.88781038 0.88874621 0.88905413]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ixe9qVM6_pj5",
        "outputId": "b46eb36d-7db1-411c-a57e-0868a0f73355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'max_bin':(125,150),#               #'learning_rate':(0.2,0.3),\n",
        "     'feature_fraction':(0.6,0.7),\n",
        "     'num_leaves':(250,300),#\n",
        "     'min_data_in_leaf':(300,400),\n",
        "     'lambda_l1':(1,2),#--6                    #'lambda_l2':(2,4,6),     #'max_depth':(60,80,90),\n",
        "     'bagging_fraction':(0.4,0.5)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=3,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  6.0min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed:  9.1min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 17.3min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 18.5min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 19.9min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 20.7min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 21.4min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 22.5min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 24.2min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 24.3min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 25.4min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 26.6min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 27.2min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 28.5min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 29.4min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 30.6min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 32.5min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 33.0min\n",
            "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed: 34.2min\n",
            "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed: 35.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed: 36.3min\n",
            "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed: 37.0min\n",
            "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed: 38.4min\n",
            "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed: 38.7min\n",
            "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed: 40.1min\n",
            "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed: 42.0min\n",
            "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed: 42.1min\n",
            "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed: 42.3min\n",
            "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 44.9min\n",
            "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed: 45.2min\n",
            "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed: 45.3min\n",
            "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed: 47.7min\n",
            "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed: 48.5min\n",
            "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed: 48.7min\n",
            "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed: 50.5min\n",
            "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed: 51.4min\n",
            "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed: 52.0min\n",
            "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed: 53.5min\n",
            "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed: 54.7min\n",
            "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed: 54.9min\n",
            "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed: 56.2min\n",
            "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed: 57.5min\n",
            "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed: 58.1min\n",
            "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed: 59.7min\n",
            "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed: 60.4min\n",
            "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed: 61.0min\n",
            "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed: 62.6min\n",
            "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed: 63.2min\n",
            "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed: 64.2min\n",
            "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed: 65.8min\n",
            "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed: 66.5min\n",
            "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed: 67.0min\n",
            "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed: 68.6min\n",
            "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed: 69.3min\n",
            "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed: 70.0min\n",
            "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed: 71.9min\n",
            "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed: 72.5min\n",
            "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed: 73.1min\n",
            "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed: 74.3min\n",
            "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed: 75.8min\n",
            "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed: 76.3min\n",
            "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed: 77.3min\n",
            "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed: 78.9min\n",
            "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed: 79.2min\n",
            "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed: 80.2min\n",
            "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed: 82.1min\n",
            "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed: 82.4min\n",
            "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed: 83.2min\n",
            "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed: 85.2min\n",
            "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed: 85.7min\n",
            "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed: 85.9min\n",
            "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed: 88.0min\n",
            "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed: 88.7min\n",
            "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed: 89.3min\n",
            "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed: 91.3min\n",
            "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed: 92.3min\n",
            "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed: 94.2min\n",
            "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed: 94.7min\n",
            "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed: 95.5min\n",
            "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed: 97.3min\n",
            "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed: 97.6min\n",
            "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed: 98.3min\n",
            "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed: 100.2min\n",
            "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed: 100.3min\n",
            "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed: 101.7min\n",
            "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed: 103.1min\n",
            "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed: 103.3min\n",
            "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed: 104.6min\n",
            "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed: 106.1min\n",
            "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed: 106.2min\n",
            "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed: 107.7min\n",
            "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed: 108.7min\n",
            "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed: 109.5min\n",
            "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed: 110.6min\n",
            "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed: 111.6min\n",
            "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed: 112.4min\n",
            "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed: 114.1min\n",
            "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed: 114.8min\n",
            "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed: 114.9min\n",
            "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed: 116.9min\n",
            "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed: 117.6min\n",
            "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed: 117.9min\n",
            "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed: 120.0min\n",
            "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed: 120.7min\n",
            "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed: 120.9min\n",
            "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed: 122.5min\n",
            "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed: 123.8min\n",
            "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed: 123.9min\n",
            "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed: 125.4min\n",
            "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed: 126.7min\n",
            "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed: 127.1min\n",
            "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed: 127.9min\n",
            "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed: 129.5min\n",
            "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed: 130.1min\n",
            "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed: 131.0min\n",
            "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed: 132.7min\n",
            "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed: 132.8min\n",
            "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed: 133.5min\n",
            "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed: 135.6min\n",
            "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed: 136.0min\n",
            "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed: 136.8min\n",
            "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed: 139.2min\n",
            "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed: 141.7min\n",
            "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed: 142.0min\n",
            "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed: 142.2min\n",
            "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed: 145.3min\n",
            "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed: 147.5min\n",
            "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed: 148.2min\n",
            "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed: 148.8min\n",
            "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed: 150.8min\n",
            "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed: 151.2min\n",
            "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed: 151.6min\n",
            "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed: 153.7min\n",
            "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed: 154.1min\n",
            "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed: 155.1min\n",
            "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 156.8min\n",
            "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed: 156.9min\n",
            "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed: 158.3min\n",
            "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed: 159.7min\n",
            "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed: 159.9min\n",
            "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed: 161.6min\n",
            "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed: 162.8min\n",
            "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed: 163.0min\n",
            "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed: 164.7min\n",
            "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed: 165.7min\n",
            "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed: 166.1min\n",
            "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed: 168.0min\n",
            "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed: 168.9min\n",
            "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed: 169.4min\n",
            "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed: 170.8min\n",
            "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed: 171.8min\n",
            "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed: 172.5min\n",
            "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed: 174.2min\n",
            "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed: 177.0min\n",
            "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed: 177.8min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  6.0min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed:  9.1min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 17.3min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 18.5min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 19.9min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 20.7min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 21.4min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 22.5min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 24.2min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 24.3min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 25.4min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 26.6min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 27.2min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 28.5min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 29.4min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 30.6min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 32.5min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 33.0min\n",
            "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed: 34.2min\n",
            "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed: 35.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed: 36.3min\n",
            "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed: 37.0min\n",
            "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed: 38.4min\n",
            "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed: 38.7min\n",
            "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed: 40.1min\n",
            "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed: 42.0min\n",
            "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed: 42.1min\n",
            "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed: 42.3min\n",
            "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 44.9min\n",
            "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed: 45.2min\n",
            "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed: 45.3min\n",
            "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed: 47.7min\n",
            "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed: 48.5min\n",
            "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed: 48.7min\n",
            "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed: 50.5min\n",
            "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed: 51.4min\n",
            "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed: 52.0min\n",
            "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed: 53.5min\n",
            "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed: 54.7min\n",
            "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed: 54.9min\n",
            "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed: 56.2min\n",
            "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed: 57.5min\n",
            "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed: 58.1min\n",
            "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed: 59.7min\n",
            "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed: 60.4min\n",
            "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed: 61.0min\n",
            "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed: 62.6min\n",
            "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed: 63.2min\n",
            "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed: 64.2min\n",
            "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed: 65.8min\n",
            "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed: 66.5min\n",
            "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed: 67.0min\n",
            "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed: 68.6min\n",
            "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed: 69.3min\n",
            "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed: 70.0min\n",
            "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed: 71.9min\n",
            "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed: 72.5min\n",
            "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed: 73.1min\n",
            "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed: 74.3min\n",
            "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed: 75.8min\n",
            "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed: 76.3min\n",
            "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed: 77.3min\n",
            "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed: 78.9min\n",
            "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed: 79.2min\n",
            "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed: 80.2min\n",
            "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed: 82.1min\n",
            "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed: 82.4min\n",
            "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed: 83.2min\n",
            "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed: 85.2min\n",
            "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed: 85.7min\n",
            "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed: 85.9min\n",
            "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed: 88.0min\n",
            "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed: 88.7min\n",
            "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed: 89.3min\n",
            "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed: 91.3min\n",
            "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed: 92.3min\n",
            "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed: 94.2min\n",
            "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed: 94.7min\n",
            "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed: 95.5min\n",
            "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed: 97.3min\n",
            "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed: 97.6min\n",
            "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed: 98.3min\n",
            "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed: 100.2min\n",
            "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed: 100.3min\n",
            "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed: 101.7min\n",
            "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed: 103.1min\n",
            "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed: 103.3min\n",
            "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed: 104.6min\n",
            "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed: 106.1min\n",
            "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed: 106.2min\n",
            "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed: 107.7min\n",
            "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed: 108.7min\n",
            "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed: 109.5min\n",
            "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed: 110.6min\n",
            "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed: 111.6min\n",
            "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed: 112.4min\n",
            "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed: 114.1min\n",
            "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed: 114.8min\n",
            "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed: 114.9min\n",
            "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed: 116.9min\n",
            "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed: 117.6min\n",
            "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed: 117.9min\n",
            "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed: 120.0min\n",
            "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed: 120.7min\n",
            "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed: 120.9min\n",
            "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed: 122.5min\n",
            "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed: 123.8min\n",
            "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed: 123.9min\n",
            "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed: 125.4min\n",
            "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed: 126.7min\n",
            "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed: 127.1min\n",
            "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed: 127.9min\n",
            "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed: 129.5min\n",
            "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed: 130.1min\n",
            "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed: 131.0min\n",
            "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed: 132.7min\n",
            "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed: 132.8min\n",
            "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed: 133.5min\n",
            "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed: 135.6min\n",
            "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed: 136.0min\n",
            "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed: 136.8min\n",
            "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed: 139.2min\n",
            "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed: 141.7min\n",
            "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed: 142.0min\n",
            "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed: 142.2min\n",
            "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed: 145.3min\n",
            "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed: 147.5min\n",
            "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed: 148.2min\n",
            "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed: 148.8min\n",
            "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed: 150.8min\n",
            "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed: 151.2min\n",
            "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed: 151.6min\n",
            "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed: 153.7min\n",
            "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed: 154.1min\n",
            "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed: 155.1min\n",
            "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 156.8min\n",
            "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed: 156.9min\n",
            "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed: 158.3min\n",
            "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed: 159.7min\n",
            "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed: 159.9min\n",
            "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed: 161.6min\n",
            "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed: 162.8min\n",
            "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed: 163.0min\n",
            "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed: 164.7min\n",
            "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed: 165.7min\n",
            "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed: 166.1min\n",
            "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed: 168.0min\n",
            "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed: 168.9min\n",
            "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed: 169.4min\n",
            "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed: 170.8min\n",
            "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed: 171.8min\n",
            "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed: 172.5min\n",
            "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed: 174.2min\n",
            "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed: 177.0min\n",
            "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed: 177.8min\n",
            "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed: 178.6min\n",
            "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed: 178.6min\n",
            "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed: 180.3min\n",
            "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed: 180.3min\n",
            "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed: 181.1min\n",
            "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed: 181.1min\n",
            "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed: 181.4min\n",
            "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed: 181.4min\n",
            "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed: 183.1min\n",
            "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed: 183.1min\n",
            "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed: 184.1min\n",
            "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed: 184.1min\n",
            "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed: 184.5min\n",
            "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed: 184.5min\n",
            "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed: 186.1min\n",
            "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed: 186.1min\n",
            "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed: 187.2min\n",
            "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed: 187.2min\n",
            "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed: 187.5min\n",
            "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed: 187.5min\n",
            "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed: 189.1min\n",
            "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed: 189.1min\n",
            "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed: 190.1min\n",
            "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed: 190.1min\n",
            "[Parallel(n_jobs=3)]: Done 192 out of 192 | elapsed: 192.8min finished\n",
            "[Parallel(n_jobs=3)]: Done 192 out of 192 | elapsed: 192.8min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split',\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=90,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_state=None, reg_...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'bagging_fraction': (0.5, 0.6),\n",
            "                         'feature_fraction': (0.5, 0.6), 'lambda_l1': (2, 4),\n",
            "                         'max_bin': (100, 125), 'min_data_in_leaf': (200, 300),\n",
            "                         'num_leaves': (150, 250)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9267652722511871\n",
            "{'bagging_fraction': 0.5, 'feature_fraction': 0.6, 'lambda_l1': 2, 'max_bin': 125, 'min_data_in_leaf': 300, 'num_leaves': 250}\n",
            "LGBMClassifier(bagging_fraction=0.5, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.6,\n",
            "               importance_type='split', lambda_l1=2, learning_rate=0.1,\n",
            "               max_bin=125, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=300, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=90, num_leaves=250,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n",
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split',\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=90,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_state=None, reg_...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'bagging_fraction': (0.5, 0.6),\n",
            "                         'feature_fraction': (0.5, 0.6), 'lambda_l1': (2, 4),\n",
            "                         'max_bin': (100, 125), 'min_data_in_leaf': (200, 300),\n",
            "                         'num_leaves': (150, 250)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9267652722511871\n",
            "{'bagging_fraction': 0.5, 'feature_fraction': 0.6, 'lambda_l1': 2, 'max_bin': 125, 'min_data_in_leaf': 300, 'num_leaves': 250}\n",
            "LGBMClassifier(bagging_fraction=0.5, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.6,\n",
            "               importance_type='split', lambda_l1=2, learning_rate=0.1,\n",
            "               max_bin=125, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=300, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=90, num_leaves=250,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "52sUc9Uswc1x",
        "outputId": "7dfa9c3b-227e-437f-fe7a-d88372d8a4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'max_bin':(100,125),#               #'learning_rate':(0.2,0.3),\n",
        "     'feature_fraction':(0.7,0.8),\n",
        "     'num_leaves':(300,350),#\n",
        "     'min_data_in_leaf':(300),\n",
        "     'lambda_l1':(1),#                    #'lambda_l2':(2,4,6),     #'max_depth':(60,80,90),\n",
        "     'bagging_fraction':(0.3,0.4)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=3,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  7.0min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  7.3min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed: 10.3min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed: 10.9min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 13.8min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 13.9min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 17.0min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 17.2min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 18.2min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 20.4min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 20.9min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 21.9min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 23.5min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 24.5min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 25.2min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 26.9min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 27.8min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 29.1min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 30.4min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 32.5min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 33.5min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 34.5min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 36.2min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 36.7min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 37.8min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 39.6min\n",
            "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed: 39.8min\n",
            "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed: 41.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed: 43.1min\n",
            "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed: 43.2min\n",
            "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed: 44.4min\n",
            "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed: 46.1min\n",
            "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed: 46.7min\n",
            "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed: 48.2min\n",
            "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed: 49.6min\n",
            "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed: 49.7min\n",
            "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 51.6min\n",
            "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed: 53.0min\n",
            "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed: 53.0min\n",
            "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed: 55.0min\n",
            "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed: 56.0min\n",
            "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed: 56.6min\n",
            "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed: 58.7min\n",
            "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed: 59.6min\n",
            "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed: 60.1min\n",
            "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed: 62.7min\n",
            "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed: 62.9min\n",
            "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed: 63.6min\n",
            "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed: 66.1min\n",
            "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed: 66.4min\n",
            "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed: 67.2min\n",
            "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed: 69.8min\n",
            "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed: 70.3min\n",
            "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed: 70.5min\n",
            "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed: 73.2min\n",
            "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed: 74.1min\n",
            "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed: 74.2min\n",
            "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed: 76.9min\n",
            "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed: 77.7min\n",
            "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed: 77.8min\n",
            "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed: 80.7min\n",
            "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed: 81.0min\n",
            "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed: 81.4min\n",
            "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed: 84.1min\n",
            "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed: 84.8min\n",
            "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed: 84.9min\n",
            "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed: 87.8min\n",
            "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed: 88.4min\n",
            "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed: 88.4min\n",
            "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed: 92.1min\n",
            "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed: 95.0min\n",
            "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed: 95.2min\n",
            "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed: 95.9min\n",
            "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed: 98.8min\n",
            "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed: 99.0min\n",
            "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed: 99.1min\n",
            "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed: 101.9min\n",
            "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed: 102.9min\n",
            "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed: 102.9min\n",
            "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed: 105.4min\n",
            "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed: 106.4min\n",
            "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed: 106.8min\n",
            "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed: 108.6min\n",
            "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed: 110.0min\n",
            "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed: 110.4min\n",
            "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed: 112.4min\n",
            "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed: 113.3min\n",
            "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed: 114.0min\n",
            "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed: 116.0min\n",
            "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed: 116.6min\n",
            "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed: 117.3min\n",
            "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed: 119.8min\n",
            "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed: 120.2min\n",
            "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed: 120.7min\n",
            "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed: 123.3min\n",
            "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed: 123.7min\n",
            "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed: 124.0min\n",
            "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed: 127.0min\n",
            "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed: 127.2min\n",
            "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed: 127.3min\n",
            "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed: 130.6min\n",
            "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed: 130.7min\n",
            "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed: 130.7min\n",
            "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed: 133.7min\n",
            "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed: 134.3min\n",
            "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed: 134.4min\n",
            "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed: 137.1min\n",
            "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed: 137.7min\n",
            "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed: 138.1min\n",
            "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed: 140.6min\n",
            "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed: 141.1min\n",
            "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed: 141.6min\n",
            "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed: 143.9min\n",
            "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed: 144.7min\n",
            "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed: 147.1min\n",
            "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed: 148.3min\n",
            "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed: 148.5min\n",
            "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed: 150.6min\n",
            "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed: 151.8min\n",
            "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed: 152.1min\n",
            "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed: 154.0min\n",
            "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed: 155.4min\n",
            "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed: 155.7min\n",
            "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed: 157.4min\n",
            "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed: 158.6min\n",
            "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed: 159.3min\n",
            "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed: 160.8min\n",
            "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed: 162.2min\n",
            "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed: 162.7min\n",
            "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed: 164.2min\n",
            "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed: 165.5min\n",
            "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed: 166.0min\n",
            "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed: 168.0min\n",
            "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed: 169.1min\n",
            "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed: 169.3min\n",
            "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed: 171.4min\n",
            "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed: 172.8min\n",
            "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed: 172.9min\n",
            "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed: 175.2min\n",
            "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed: 176.4min\n",
            "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed: 176.5min\n",
            "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed: 178.7min\n",
            "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed: 179.8min\n",
            "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed: 180.1min\n",
            "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed: 182.3min\n",
            "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 183.5min\n",
            "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed: 183.7min\n",
            "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed: 185.8min\n",
            "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed: 187.2min\n",
            "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed: 187.3min\n",
            "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed: 189.6min\n",
            "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed: 190.5min\n",
            "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed: 191.1min\n",
            "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed: 192.9min\n",
            "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed: 194.2min\n",
            "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed: 194.6min\n",
            "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed: 196.8min\n",
            "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed: 197.6min\n",
            "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed: 198.0min\n",
            "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed: 200.2min\n",
            "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed: 201.1min\n",
            "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed: 201.7min\n",
            "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed: 203.9min\n",
            "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed: 204.6min\n",
            "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed: 205.2min\n",
            "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed: 207.5min\n",
            "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed: 207.9min\n",
            "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed: 208.8min\n",
            "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed: 211.4min\n",
            "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed: 212.0min\n",
            "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed: 212.0min\n",
            "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed: 215.0min\n",
            "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed: 215.6min\n",
            "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed: 215.7min\n",
            "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed: 218.4min\n",
            "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed: 219.1min\n",
            "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed: 219.3min\n",
            "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed: 222.1min\n",
            "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed: 222.6min\n",
            "[Parallel(n_jobs=3)]: Done 192 out of 192 | elapsed: 225.7min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split',\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=90,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_state=None, reg_...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'bagging_fraction': (0.4, 0.5),\n",
            "                         'feature_fraction': (0.6, 0.7), 'lambda_l1': (1, 2),\n",
            "                         'max_bin': (125, 150), 'min_data_in_leaf': (300, 400),\n",
            "                         'num_leaves': (250, 300)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9272417521074825\n",
            "{'bagging_fraction': 0.4, 'feature_fraction': 0.7, 'lambda_l1': 1, 'max_bin': 125, 'min_data_in_leaf': 300, 'num_leaves': 300}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, learning_rate=0.1,\n",
            "               max_bin=125, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=300, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=90, num_leaves=300,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d1qmccME6gNU",
        "outputId": "7059376d-383a-43b4-863a-17fc988b5119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'learning_rate':(0.2,0.3),\n",
        "     'lambda_l2':(2,4),     \n",
        "     'max_depth':(60,80,90)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=3,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=1,max_bin=125,min_data_in_leaf=300,num_leaves=300)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  6.7min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  7.2min\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed: 11.0min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed: 11.1min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 14.0min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 14.0min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 14.7min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 17.1min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 17.5min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 18.3min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 20.5min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 20.9min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 22.1min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 23.8min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 24.6min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 25.8min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 27.4min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 28.2min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 29.6min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 30.8min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 32.3min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 33.1min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 34.0min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 35.9min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 36.7min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 37.3min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 39.3min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 40.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 out of  36 | elapsed: 43.2min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.4,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      feature_fraction=0.7,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_bin=125,\n",
            "                                      max_depth=-1, min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=300, min_split_gain=0.0,\n",
            "                                      n_estimat...\n",
            "                                      num_iterations=90, num_leaves=300,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'lambda_l2': (2, 4), 'learning_rate': (0.2, 0.3),\n",
            "                         'max_depth': (60, 80, 90)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9319399935584403\n",
            "{'lambda_l2': 4, 'learning_rate': 0.3, 'max_depth': 60}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=4,\n",
            "               learning_rate=0.3, max_bin=125, max_depth=60,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=300, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=300, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YwFiAmL4JZDO",
        "outputId": "1aac075a-8258-4c64-c232-55266ebeb34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'learning_rate':(0.4,0.5),\n",
        "     'lambda_l2':(6,8),     \n",
        "     'max_depth':(40,50)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=4,refit=\"accuracy\",pre_dispatch=5,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=1,max_bin=125,min_data_in_leaf=300,num_leaves=300)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  7.9min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:  8.1min\n",
            "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed: 11.7min\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed: 11.9min\n",
            "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed: 12.0min\n",
            "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed: 15.7min\n",
            "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed: 15.9min\n",
            "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed: 16.0min\n",
            "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed: 16.0min\n",
            "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed: 19.6min\n",
            "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed: 19.7min\n",
            "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed: 19.9min\n",
            "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed: 20.1min\n",
            "[Parallel(n_jobs=4)]: Done  21 out of  24 | elapsed: 23.6min remaining:  3.4min\n",
            "[Parallel(n_jobs=4)]: Done  22 out of  24 | elapsed: 23.7min remaining:  2.2min\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 24.0min finished\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 24.0min remaining:    0.0s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.4,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      feature_fraction=0.7,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_bin=125,\n",
            "                                      max_depth=-1, min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=300, min_split_gain=0.0,\n",
            "                                      n_estimat...\n",
            "                                      num_iterations=90, num_leaves=300,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=4,\n",
            "             param_grid={'lambda_l2': (4, 6), 'learning_rate': (0.3, 0.4),\n",
            "                         'max_depth': (50, 60)},\n",
            "             pre_dispatch=5, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9330757831179838\n",
            "{'lambda_l2': 6, 'learning_rate': 0.4, 'max_depth': 50}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=6,\n",
            "               learning_rate=0.4, max_bin=125, max_depth=50,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=300, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=300, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZdlHThqYTZSQ",
        "outputId": "fbf31d0c-2636-4028-a7b8-174f914e6c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'learning_rate':(0.4,0.5),\n",
        "     'lambda_l2':(6,8),     \n",
        "     'max_depth':(40,50)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=4,refit=\"accuracy\",pre_dispatch=5,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=1,max_bin=125,min_data_in_leaf=300,num_leaves=300)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  7.7min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed: 11.5min\n",
            "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed: 11.7min\n",
            "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed: 15.2min\n",
            "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed: 15.5min\n",
            "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed: 15.5min\n",
            "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed: 15.6min\n",
            "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed: 19.2min\n",
            "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed: 19.3min\n",
            "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed: 19.5min\n",
            "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed: 19.5min\n",
            "[Parallel(n_jobs=4)]: Done  21 out of  24 | elapsed: 23.1min remaining:  3.3min\n",
            "[Parallel(n_jobs=4)]: Done  22 out of  24 | elapsed: 23.2min remaining:  2.1min\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 23.4min remaining:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 23.4min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.4,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      feature_fraction=0.7,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_bin=125,\n",
            "                                      max_depth=-1, min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=300, min_split_gain=0.0,\n",
            "                                      n_estimat...\n",
            "                                      num_iterations=90, num_leaves=300,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=4,\n",
            "             param_grid={'lambda_l2': (6, 8), 'learning_rate': (0.4, 0.5),\n",
            "                         'max_depth': (40, 50)},\n",
            "             pre_dispatch=5, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9337819973503855\n",
            "{'lambda_l2': 8, 'learning_rate': 0.5, 'max_depth': 40}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=8,\n",
            "               learning_rate=0.5, max_bin=125, max_depth=40,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=300, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=300, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cEBGv0t5Iixl",
        "outputId": "e51a48bf-136c-4478-afca-979e5bf493ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols,Y_train.OUTCOME.mean(),Y_test.OUTCOME.mean())\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(num_iterations=100,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=3,max_bin=125,min_data_in_leaf=300,num_leaves=300,lambda_l2=8,learning_rate=0.2,max_depth=40)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  sel_X_valid=X_valid[sel_cols]\n",
        "  eval_set = [(sel_X_test, Y_test)]\n",
        "  model.fit(sel_X_train, Y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
        "\n",
        "  print(\"Test dataset:\")\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(\"Validation dataset:\")\n",
        "  pred=model.predict(sel_X_valid)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_valid,pred)\n",
        "\n",
        "  \n",
        "  print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "  #plot graph of feature importances for better visualization\n",
        "  feat_importances = pd.Series(model.feature_importances_, index=sel_cols)\n",
        "  feat_importances.nlargest(26).plot(kind='barh')\n",
        "  plt.show()\n",
        "\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test,sel_X_valid])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test,Y_valid])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing'] 0.5 0.2940363992608305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.569479\tvalid_0's binary_logloss: 0.569479\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.48659\tvalid_0's binary_logloss: 0.48659\n",
            "[3]\tvalid_0's binary_logloss: 0.428016\tvalid_0's binary_logloss: 0.428016\n",
            "[4]\tvalid_0's binary_logloss: 0.383767\tvalid_0's binary_logloss: 0.383767\n",
            "[5]\tvalid_0's binary_logloss: 0.345744\tvalid_0's binary_logloss: 0.345744\n",
            "[6]\tvalid_0's binary_logloss: 0.321117\tvalid_0's binary_logloss: 0.321117\n",
            "[7]\tvalid_0's binary_logloss: 0.298243\tvalid_0's binary_logloss: 0.298243\n",
            "[8]\tvalid_0's binary_logloss: 0.285128\tvalid_0's binary_logloss: 0.285128\n",
            "[9]\tvalid_0's binary_logloss: 0.270261\tvalid_0's binary_logloss: 0.270261\n",
            "[10]\tvalid_0's binary_logloss: 0.259071\tvalid_0's binary_logloss: 0.259071\n",
            "[11]\tvalid_0's binary_logloss: 0.250068\tvalid_0's binary_logloss: 0.250068\n",
            "[12]\tvalid_0's binary_logloss: 0.243208\tvalid_0's binary_logloss: 0.243208\n",
            "[13]\tvalid_0's binary_logloss: 0.237672\tvalid_0's binary_logloss: 0.237672\n",
            "[14]\tvalid_0's binary_logloss: 0.233698\tvalid_0's binary_logloss: 0.233698\n",
            "[15]\tvalid_0's binary_logloss: 0.230239\tvalid_0's binary_logloss: 0.230239\n",
            "[16]\tvalid_0's binary_logloss: 0.227401\tvalid_0's binary_logloss: 0.227401\n",
            "[17]\tvalid_0's binary_logloss: 0.224922\tvalid_0's binary_logloss: 0.224922\n",
            "[18]\tvalid_0's binary_logloss: 0.222631\tvalid_0's binary_logloss: 0.222631\n",
            "[19]\tvalid_0's binary_logloss: 0.221121\tvalid_0's binary_logloss: 0.221121\n",
            "[20]\tvalid_0's binary_logloss: 0.219519\tvalid_0's binary_logloss: 0.219519\n",
            "[21]\tvalid_0's binary_logloss: 0.218306\tvalid_0's binary_logloss: 0.218306\n",
            "[22]\tvalid_0's binary_logloss: 0.217403\tvalid_0's binary_logloss: 0.217403\n",
            "[23]\tvalid_0's binary_logloss: 0.215742\tvalid_0's binary_logloss: 0.215742\n",
            "[24]\tvalid_0's binary_logloss: 0.214624\tvalid_0's binary_logloss: 0.214624\n",
            "[25]\tvalid_0's binary_logloss: 0.213874\tvalid_0's binary_logloss: 0.213874\n",
            "[26]\tvalid_0's binary_logloss: 0.212639\tvalid_0's binary_logloss: 0.212639\n",
            "[27]\tvalid_0's binary_logloss: 0.211592\tvalid_0's binary_logloss: 0.211592\n",
            "[28]\tvalid_0's binary_logloss: 0.210676\tvalid_0's binary_logloss: 0.210676\n",
            "[29]\tvalid_0's binary_logloss: 0.209813\tvalid_0's binary_logloss: 0.209813\n",
            "[30]\tvalid_0's binary_logloss: 0.209194\tvalid_0's binary_logloss: 0.209194\n",
            "[31]\tvalid_0's binary_logloss: 0.208512\tvalid_0's binary_logloss: 0.208512\n",
            "[32]\tvalid_0's binary_logloss: 0.208077\tvalid_0's binary_logloss: 0.208077\n",
            "[33]\tvalid_0's binary_logloss: 0.20754\tvalid_0's binary_logloss: 0.20754\n",
            "[34]\tvalid_0's binary_logloss: 0.206883\tvalid_0's binary_logloss: 0.206883\n",
            "[35]\tvalid_0's binary_logloss: 0.206408\tvalid_0's binary_logloss: 0.206408\n",
            "[36]\tvalid_0's binary_logloss: 0.205985\tvalid_0's binary_logloss: 0.205985\n",
            "[37]\tvalid_0's binary_logloss: 0.205723\tvalid_0's binary_logloss: 0.205723\n",
            "[38]\tvalid_0's binary_logloss: 0.205317\tvalid_0's binary_logloss: 0.205317\n",
            "[39]\tvalid_0's binary_logloss: 0.204824\tvalid_0's binary_logloss: 0.204824\n",
            "[40]\tvalid_0's binary_logloss: 0.204454\tvalid_0's binary_logloss: 0.204454\n",
            "[41]\tvalid_0's binary_logloss: 0.204184\tvalid_0's binary_logloss: 0.204184\n",
            "[42]\tvalid_0's binary_logloss: 0.20383\tvalid_0's binary_logloss: 0.20383\n",
            "[43]\tvalid_0's binary_logloss: 0.203458\tvalid_0's binary_logloss: 0.203458\n",
            "[44]\tvalid_0's binary_logloss: 0.203061\tvalid_0's binary_logloss: 0.203061\n",
            "[45]\tvalid_0's binary_logloss: 0.202731\tvalid_0's binary_logloss: 0.202731\n",
            "[46]\tvalid_0's binary_logloss: 0.202469\tvalid_0's binary_logloss: 0.202469\n",
            "[47]\tvalid_0's binary_logloss: 0.202239\tvalid_0's binary_logloss: 0.202239\n",
            "[48]\tvalid_0's binary_logloss: 0.202004\tvalid_0's binary_logloss: 0.202004\n",
            "[49]\tvalid_0's binary_logloss: 0.201789\tvalid_0's binary_logloss: 0.201789\n",
            "[50]\tvalid_0's binary_logloss: 0.201586\tvalid_0's binary_logloss: 0.201586\n",
            "[51]\tvalid_0's binary_logloss: 0.201372\tvalid_0's binary_logloss: 0.201372\n",
            "[52]\tvalid_0's binary_logloss: 0.201204\tvalid_0's binary_logloss: 0.201204\n",
            "[53]\tvalid_0's binary_logloss: 0.201074\tvalid_0's binary_logloss: 0.201074\n",
            "[54]\tvalid_0's binary_logloss: 0.2008\tvalid_0's binary_logloss: 0.2008\n",
            "[55]\tvalid_0's binary_logloss: 0.200604\tvalid_0's binary_logloss: 0.200604\n",
            "[56]\tvalid_0's binary_logloss: 0.200436\tvalid_0's binary_logloss: 0.200436\n",
            "[57]\tvalid_0's binary_logloss: 0.200222\tvalid_0's binary_logloss: 0.200222\n",
            "[58]\tvalid_0's binary_logloss: 0.200037\tvalid_0's binary_logloss: 0.200037\n",
            "[59]\tvalid_0's binary_logloss: 0.199814\tvalid_0's binary_logloss: 0.199814\n",
            "[60]\tvalid_0's binary_logloss: 0.199649\tvalid_0's binary_logloss: 0.199649\n",
            "[61]\tvalid_0's binary_logloss: 0.199444\tvalid_0's binary_logloss: 0.199444\n",
            "[62]\tvalid_0's binary_logloss: 0.199286\tvalid_0's binary_logloss: 0.199286\n",
            "[63]\tvalid_0's binary_logloss: 0.199128\tvalid_0's binary_logloss: 0.199128\n",
            "[64]\tvalid_0's binary_logloss: 0.198985\tvalid_0's binary_logloss: 0.198985\n",
            "[65]\tvalid_0's binary_logloss: 0.198847\tvalid_0's binary_logloss: 0.198847\n",
            "[66]\tvalid_0's binary_logloss: 0.198724\tvalid_0's binary_logloss: 0.198724\n",
            "[67]\tvalid_0's binary_logloss: 0.198657\tvalid_0's binary_logloss: 0.198657\n",
            "[68]\tvalid_0's binary_logloss: 0.198558\tvalid_0's binary_logloss: 0.198558\n",
            "[69]\tvalid_0's binary_logloss: 0.198413\tvalid_0's binary_logloss: 0.198413\n",
            "[70]\tvalid_0's binary_logloss: 0.198247\tvalid_0's binary_logloss: 0.198247\n",
            "[71]\tvalid_0's binary_logloss: 0.198061\tvalid_0's binary_logloss: 0.198061\n",
            "[72]\tvalid_0's binary_logloss: 0.197956\tvalid_0's binary_logloss: 0.197956\n",
            "[73]\tvalid_0's binary_logloss: 0.197863\tvalid_0's binary_logloss: 0.197863\n",
            "[74]\tvalid_0's binary_logloss: 0.197786\tvalid_0's binary_logloss: 0.197786\n",
            "[75]\tvalid_0's binary_logloss: 0.197678\tvalid_0's binary_logloss: 0.197678\n",
            "[76]\tvalid_0's binary_logloss: 0.197566\tvalid_0's binary_logloss: 0.197566\n",
            "[77]\tvalid_0's binary_logloss: 0.197491\tvalid_0's binary_logloss: 0.197491\n",
            "[78]\tvalid_0's binary_logloss: 0.1974\tvalid_0's binary_logloss: 0.1974\n",
            "[79]\tvalid_0's binary_logloss: 0.197233\tvalid_0's binary_logloss: 0.197233\n",
            "[80]\tvalid_0's binary_logloss: 0.197109\tvalid_0's binary_logloss: 0.197109\n",
            "[81]\tvalid_0's binary_logloss: 0.197004\tvalid_0's binary_logloss: 0.197004\n",
            "[82]\tvalid_0's binary_logloss: 0.196941\tvalid_0's binary_logloss: 0.196941\n",
            "[83]\tvalid_0's binary_logloss: 0.196843\tvalid_0's binary_logloss: 0.196843\n",
            "[84]\tvalid_0's binary_logloss: 0.196701\tvalid_0's binary_logloss: 0.196701\n",
            "[85]\tvalid_0's binary_logloss: 0.196613\tvalid_0's binary_logloss: 0.196613\n",
            "[86]\tvalid_0's binary_logloss: 0.196528\tvalid_0's binary_logloss: 0.196528\n",
            "[87]\tvalid_0's binary_logloss: 0.196487\tvalid_0's binary_logloss: 0.196487\n",
            "[88]\tvalid_0's binary_logloss: 0.196399\tvalid_0's binary_logloss: 0.196399\n",
            "[89]\tvalid_0's binary_logloss: 0.196327\tvalid_0's binary_logloss: 0.196327\n",
            "[90]\tvalid_0's binary_logloss: 0.196288\tvalid_0's binary_logloss: 0.196288\n",
            "[91]\tvalid_0's binary_logloss: 0.196221\tvalid_0's binary_logloss: 0.196221\n",
            "[92]\tvalid_0's binary_logloss: 0.196163\tvalid_0's binary_logloss: 0.196163\n",
            "[93]\tvalid_0's binary_logloss: 0.196059\tvalid_0's binary_logloss: 0.196059\n",
            "[94]\tvalid_0's binary_logloss: 0.195999\tvalid_0's binary_logloss: 0.195999\n",
            "[95]\tvalid_0's binary_logloss: 0.195936\tvalid_0's binary_logloss: 0.195936\n",
            "[96]\tvalid_0's binary_logloss: 0.195874\tvalid_0's binary_logloss: 0.195874\n",
            "[97]\tvalid_0's binary_logloss: 0.19577\tvalid_0's binary_logloss: 0.19577\n",
            "[98]\tvalid_0's binary_logloss: 0.195682\tvalid_0's binary_logloss: 0.195682\n",
            "[99]\tvalid_0's binary_logloss: 0.195652\tvalid_0's binary_logloss: 0.195652\n",
            "[100]\tvalid_0's binary_logloss: 0.195605\tvalid_0's binary_logloss: 0.195605\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's binary_logloss: 0.195605\tvalid_0's binary_logloss: 0.195605\n",
            "Test dataset:\n",
            "predictions are  [0 1 0 ... 0 0 1]\n",
            "Test ROC AUC score: 0.8893542491836463\n",
            "Test accuracy score: 0.925261053379556\n",
            "Confusion matrix is  [[327921   7884]\n",
            " [ 27667 112197]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95    335805\n",
            "           1       0.93      0.80      0.86    139864\n",
            "\n",
            "    accuracy                           0.93    475669\n",
            "   macro avg       0.93      0.89      0.91    475669\n",
            "weighted avg       0.93      0.93      0.92    475669\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation dataset:\n",
            "predictions are  [0 0 1 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8893666219746664\n",
            "Test accuracy score: 0.925332138216519\n",
            "Confusion matrix is  [[657334  15879]\n",
            " [ 55262 224291]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95    673213\n",
            "           1       0.93      0.80      0.86    279553\n",
            "\n",
            "    accuracy                           0.93    952766\n",
            "   macro avg       0.93      0.89      0.91    952766\n",
            "weighted avg       0.93      0.93      0.92    952766\n",
            "\n",
            "\n",
            "\n",
            "[2386 3495 2834 1937 2421 3511 4084    0    0    0    0    0 2862 2180\n",
            "  703  704 1234  950  532   48   14    4    1    0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-65813d7d922c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mrunLGBMClassifierModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-65813d7d922c>\u001b[0m in \u001b[0;36mrunLGBMClassifierModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel_X_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4285506\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msel_X_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msel_X_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4285506\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mrunLGBMClassifierModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-74d1b7d78339>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cross-validated scores:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cross for accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    742\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQbFihYc_4ki",
        "colab_type": "code",
        "outputId": "bf1e367b-3d6b-4015-8f3a-d90915619943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sel_cols=cols_after_removing_recursive\n",
        "print(sel_cols,Y_train.OUTCOME.mean(),Y_test.OUTCOME.mean())\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(extra_trees=True,num_iterations=100,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=3,max_bin=125,min_data_in_leaf=300,num_leaves=300,lambda_l2=8,learning_rate=0.2,max_depth=40)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  sel_X_valid=X_valid[sel_cols]\n",
        "  eval_set = [(sel_X_test, Y_test)]\n",
        "  model.fit(sel_X_train, Y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
        "\n",
        "  print(\"Test dataset:\")\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(\"Validation dataset:\")\n",
        "  pred=model.predict(sel_X_valid)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_valid,pred)\n",
        "\n",
        "  \n",
        "  print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "  #plot graph of feature importances for better visualization\n",
        "  feat_importances = pd.Series(model.feature_importances_, index=sel_cols)\n",
        "  feat_importances.nlargest(26).plot(kind='barh')\n",
        "  plt.show()\n",
        "\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test,sel_X_valid])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test,Y_valid])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'AIR_SYSTEM_DELAY_is_missing'] 0.5 0.2940363992608305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.569479\tvalid_0's binary_logloss: 0.569479\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.496275\tvalid_0's binary_logloss: 0.496275\n",
            "[3]\tvalid_0's binary_logloss: 0.428993\tvalid_0's binary_logloss: 0.428993\n",
            "[4]\tvalid_0's binary_logloss: 0.384118\tvalid_0's binary_logloss: 0.384118\n",
            "[5]\tvalid_0's binary_logloss: 0.351167\tvalid_0's binary_logloss: 0.351167\n",
            "[6]\tvalid_0's binary_logloss: 0.321787\tvalid_0's binary_logloss: 0.321787\n",
            "[7]\tvalid_0's binary_logloss: 0.299552\tvalid_0's binary_logloss: 0.299552\n",
            "[8]\tvalid_0's binary_logloss: 0.287327\tvalid_0's binary_logloss: 0.287327\n",
            "[9]\tvalid_0's binary_logloss: 0.272573\tvalid_0's binary_logloss: 0.272573\n",
            "[10]\tvalid_0's binary_logloss: 0.26186\tvalid_0's binary_logloss: 0.26186\n",
            "[11]\tvalid_0's binary_logloss: 0.255889\tvalid_0's binary_logloss: 0.255889\n",
            "[12]\tvalid_0's binary_logloss: 0.249588\tvalid_0's binary_logloss: 0.249588\n",
            "[13]\tvalid_0's binary_logloss: 0.243674\tvalid_0's binary_logloss: 0.243674\n",
            "[14]\tvalid_0's binary_logloss: 0.238166\tvalid_0's binary_logloss: 0.238166\n",
            "[15]\tvalid_0's binary_logloss: 0.233114\tvalid_0's binary_logloss: 0.233114\n",
            "[16]\tvalid_0's binary_logloss: 0.23005\tvalid_0's binary_logloss: 0.23005\n",
            "[17]\tvalid_0's binary_logloss: 0.226733\tvalid_0's binary_logloss: 0.226733\n",
            "[18]\tvalid_0's binary_logloss: 0.224843\tvalid_0's binary_logloss: 0.224843\n",
            "[19]\tvalid_0's binary_logloss: 0.223361\tvalid_0's binary_logloss: 0.223361\n",
            "[20]\tvalid_0's binary_logloss: 0.22111\tvalid_0's binary_logloss: 0.22111\n",
            "[21]\tvalid_0's binary_logloss: 0.219457\tvalid_0's binary_logloss: 0.219457\n",
            "[22]\tvalid_0's binary_logloss: 0.217893\tvalid_0's binary_logloss: 0.217893\n",
            "[23]\tvalid_0's binary_logloss: 0.216516\tvalid_0's binary_logloss: 0.216516\n",
            "[24]\tvalid_0's binary_logloss: 0.214957\tvalid_0's binary_logloss: 0.214957\n",
            "[25]\tvalid_0's binary_logloss: 0.213833\tvalid_0's binary_logloss: 0.213833\n",
            "[26]\tvalid_0's binary_logloss: 0.21289\tvalid_0's binary_logloss: 0.21289\n",
            "[27]\tvalid_0's binary_logloss: 0.211949\tvalid_0's binary_logloss: 0.211949\n",
            "[28]\tvalid_0's binary_logloss: 0.210974\tvalid_0's binary_logloss: 0.210974\n",
            "[29]\tvalid_0's binary_logloss: 0.210262\tvalid_0's binary_logloss: 0.210262\n",
            "[30]\tvalid_0's binary_logloss: 0.209609\tvalid_0's binary_logloss: 0.209609\n",
            "[31]\tvalid_0's binary_logloss: 0.209084\tvalid_0's binary_logloss: 0.209084\n",
            "[32]\tvalid_0's binary_logloss: 0.208525\tvalid_0's binary_logloss: 0.208525\n",
            "[33]\tvalid_0's binary_logloss: 0.207608\tvalid_0's binary_logloss: 0.207608\n",
            "[34]\tvalid_0's binary_logloss: 0.20713\tvalid_0's binary_logloss: 0.20713\n",
            "[35]\tvalid_0's binary_logloss: 0.206383\tvalid_0's binary_logloss: 0.206383\n",
            "[36]\tvalid_0's binary_logloss: 0.205786\tvalid_0's binary_logloss: 0.205786\n",
            "[37]\tvalid_0's binary_logloss: 0.205518\tvalid_0's binary_logloss: 0.205518\n",
            "[38]\tvalid_0's binary_logloss: 0.205035\tvalid_0's binary_logloss: 0.205035\n",
            "[39]\tvalid_0's binary_logloss: 0.204587\tvalid_0's binary_logloss: 0.204587\n",
            "[40]\tvalid_0's binary_logloss: 0.204164\tvalid_0's binary_logloss: 0.204164\n",
            "[41]\tvalid_0's binary_logloss: 0.203839\tvalid_0's binary_logloss: 0.203839\n",
            "[42]\tvalid_0's binary_logloss: 0.203494\tvalid_0's binary_logloss: 0.203494\n",
            "[43]\tvalid_0's binary_logloss: 0.203167\tvalid_0's binary_logloss: 0.203167\n",
            "[44]\tvalid_0's binary_logloss: 0.202762\tvalid_0's binary_logloss: 0.202762\n",
            "[45]\tvalid_0's binary_logloss: 0.202566\tvalid_0's binary_logloss: 0.202566\n",
            "[46]\tvalid_0's binary_logloss: 0.202247\tvalid_0's binary_logloss: 0.202247\n",
            "[47]\tvalid_0's binary_logloss: 0.20194\tvalid_0's binary_logloss: 0.20194\n",
            "[48]\tvalid_0's binary_logloss: 0.201754\tvalid_0's binary_logloss: 0.201754\n",
            "[49]\tvalid_0's binary_logloss: 0.201592\tvalid_0's binary_logloss: 0.201592\n",
            "[50]\tvalid_0's binary_logloss: 0.201309\tvalid_0's binary_logloss: 0.201309\n",
            "[51]\tvalid_0's binary_logloss: 0.20118\tvalid_0's binary_logloss: 0.20118\n",
            "[52]\tvalid_0's binary_logloss: 0.200989\tvalid_0's binary_logloss: 0.200989\n",
            "[53]\tvalid_0's binary_logloss: 0.200828\tvalid_0's binary_logloss: 0.200828\n",
            "[54]\tvalid_0's binary_logloss: 0.200691\tvalid_0's binary_logloss: 0.200691\n",
            "[55]\tvalid_0's binary_logloss: 0.200442\tvalid_0's binary_logloss: 0.200442\n",
            "[56]\tvalid_0's binary_logloss: 0.200287\tvalid_0's binary_logloss: 0.200287\n",
            "[57]\tvalid_0's binary_logloss: 0.200037\tvalid_0's binary_logloss: 0.200037\n",
            "[58]\tvalid_0's binary_logloss: 0.199826\tvalid_0's binary_logloss: 0.199826\n",
            "[59]\tvalid_0's binary_logloss: 0.19961\tvalid_0's binary_logloss: 0.19961\n",
            "[60]\tvalid_0's binary_logloss: 0.199461\tvalid_0's binary_logloss: 0.199461\n",
            "[61]\tvalid_0's binary_logloss: 0.199256\tvalid_0's binary_logloss: 0.199256\n",
            "[62]\tvalid_0's binary_logloss: 0.19916\tvalid_0's binary_logloss: 0.19916\n",
            "[63]\tvalid_0's binary_logloss: 0.199046\tvalid_0's binary_logloss: 0.199046\n",
            "[64]\tvalid_0's binary_logloss: 0.198864\tvalid_0's binary_logloss: 0.198864\n",
            "[65]\tvalid_0's binary_logloss: 0.198719\tvalid_0's binary_logloss: 0.198719\n",
            "[66]\tvalid_0's binary_logloss: 0.198561\tvalid_0's binary_logloss: 0.198561\n",
            "[67]\tvalid_0's binary_logloss: 0.198386\tvalid_0's binary_logloss: 0.198386\n",
            "[68]\tvalid_0's binary_logloss: 0.198311\tvalid_0's binary_logloss: 0.198311\n",
            "[69]\tvalid_0's binary_logloss: 0.198253\tvalid_0's binary_logloss: 0.198253\n",
            "[70]\tvalid_0's binary_logloss: 0.198074\tvalid_0's binary_logloss: 0.198074\n",
            "[71]\tvalid_0's binary_logloss: 0.198029\tvalid_0's binary_logloss: 0.198029\n",
            "[72]\tvalid_0's binary_logloss: 0.197893\tvalid_0's binary_logloss: 0.197893\n",
            "[73]\tvalid_0's binary_logloss: 0.197776\tvalid_0's binary_logloss: 0.197776\n",
            "[74]\tvalid_0's binary_logloss: 0.19767\tvalid_0's binary_logloss: 0.19767\n",
            "[75]\tvalid_0's binary_logloss: 0.197487\tvalid_0's binary_logloss: 0.197487\n",
            "[76]\tvalid_0's binary_logloss: 0.197429\tvalid_0's binary_logloss: 0.197429\n",
            "[77]\tvalid_0's binary_logloss: 0.197372\tvalid_0's binary_logloss: 0.197372\n",
            "[78]\tvalid_0's binary_logloss: 0.197248\tvalid_0's binary_logloss: 0.197248\n",
            "[79]\tvalid_0's binary_logloss: 0.197185\tvalid_0's binary_logloss: 0.197185\n",
            "[80]\tvalid_0's binary_logloss: 0.197067\tvalid_0's binary_logloss: 0.197067\n",
            "[81]\tvalid_0's binary_logloss: 0.197016\tvalid_0's binary_logloss: 0.197016\n",
            "[82]\tvalid_0's binary_logloss: 0.196863\tvalid_0's binary_logloss: 0.196863\n",
            "[83]\tvalid_0's binary_logloss: 0.196801\tvalid_0's binary_logloss: 0.196801\n",
            "[84]\tvalid_0's binary_logloss: 0.196754\tvalid_0's binary_logloss: 0.196754\n",
            "[85]\tvalid_0's binary_logloss: 0.196639\tvalid_0's binary_logloss: 0.196639\n",
            "[86]\tvalid_0's binary_logloss: 0.196598\tvalid_0's binary_logloss: 0.196598\n",
            "[87]\tvalid_0's binary_logloss: 0.196524\tvalid_0's binary_logloss: 0.196524\n",
            "[88]\tvalid_0's binary_logloss: 0.196445\tvalid_0's binary_logloss: 0.196445\n",
            "[89]\tvalid_0's binary_logloss: 0.196357\tvalid_0's binary_logloss: 0.196357\n",
            "[90]\tvalid_0's binary_logloss: 0.19626\tvalid_0's binary_logloss: 0.19626\n",
            "[91]\tvalid_0's binary_logloss: 0.196173\tvalid_0's binary_logloss: 0.196173\n",
            "[92]\tvalid_0's binary_logloss: 0.196087\tvalid_0's binary_logloss: 0.196087\n",
            "[93]\tvalid_0's binary_logloss: 0.195984\tvalid_0's binary_logloss: 0.195984\n",
            "[94]\tvalid_0's binary_logloss: 0.195899\tvalid_0's binary_logloss: 0.195899\n",
            "[95]\tvalid_0's binary_logloss: 0.195829\tvalid_0's binary_logloss: 0.195829\n",
            "[96]\tvalid_0's binary_logloss: 0.195786\tvalid_0's binary_logloss: 0.195786\n",
            "[97]\tvalid_0's binary_logloss: 0.195701\tvalid_0's binary_logloss: 0.195701\n",
            "[98]\tvalid_0's binary_logloss: 0.195626\tvalid_0's binary_logloss: 0.195626\n",
            "[99]\tvalid_0's binary_logloss: 0.195588\tvalid_0's binary_logloss: 0.195588\n",
            "[100]\tvalid_0's binary_logloss: 0.19555\tvalid_0's binary_logloss: 0.19555\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's binary_logloss: 0.19555\tvalid_0's binary_logloss: 0.19555\n",
            "Test dataset:\n",
            "predictions are  [0 1 0 ... 0 0 1]\n",
            "Test ROC AUC score: 0.88957724789964\n",
            "Test accuracy score: 0.9250487208542074\n",
            "Confusion matrix is  [[327641   8164]\n",
            " [ 27488 112376]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95    335805\n",
            "           1       0.93      0.80      0.86    139864\n",
            "\n",
            "    accuracy                           0.93    475669\n",
            "   macro avg       0.93      0.89      0.91    475669\n",
            "weighted avg       0.93      0.93      0.92    475669\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation dataset:\n",
            "predictions are  [0 0 1 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8896295735299863\n",
            "Test accuracy score: 0.9252618166475294\n",
            "Confusion matrix is  [[656968  16245]\n",
            " [ 54963 224590]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95    673213\n",
            "           1       0.93      0.80      0.86    279553\n",
            "\n",
            "    accuracy                           0.93    952766\n",
            "   macro avg       0.93      0.89      0.91    952766\n",
            "weighted avg       0.93      0.93      0.92    952766\n",
            "\n",
            "\n",
            "\n",
            "[2767 3358 3073 2033 2852 3614 3403 2797 2580 1145 1285  944   49]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ce9a7010e4b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mrunLGBMClassifierModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-ce9a7010e4b2>\u001b[0m in \u001b[0;36mrunLGBMClassifierModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel_X_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4285506\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msel_X_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msel_X_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4285506\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mrunLGBMClassifierModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-74d1b7d78339>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cross-validated scores:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cross for accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    742\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSa_F5DdiZ-e",
        "colab_type": "code",
        "outputId": "a4537683-636b-49fa-875c-6ac3ef31e66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "cols[8:13]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AIRLINE_DELAY',\n",
              " 'LATE_AIRCRAFT_DELAY',\n",
              " 'WEATHER_DELAY',\n",
              " 'SECURITY_DELAY',\n",
              " 'AIRLINE_ORIGIN_AIRPORT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-CSFvCpux_B8",
        "outputId": "602e982a-44da-424e-e3a5-66927d16f678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "source": [
        "def runXGBoostModel():\n",
        "  # fit model no training data\n",
        "  model = XGBClassifier(learning_rate=0.01,  \n",
        "                      colsample_bytree = 0.4,\n",
        "                      subsample = 0.8,\n",
        "                      objective='binary:logistic', \n",
        "                      n_estimators=300, \n",
        "                      reg_alpha = 0.3,\n",
        "                      max_depth=4,\n",
        "                      n_jobs=10,\n",
        "                      gamma=10)\n",
        "  model.fit(X_train, Y_train)\n",
        "  # make predictions for test data\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"Initial predictions are \",y_pred)\n",
        "  predictions = [round(value) for value in y_pred]\n",
        "  # evaluate predictions\n",
        "  report(Y_test,predictions)\n",
        "  X=pd.concat([X_train,X_test])\n",
        "  y=pd.concat([Y_train,Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "  \n",
        "runXGBoostModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[08:09:19] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
            "Initial predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.86731179532437\n",
            "Test accuracy score: 0.9062176437849815\n",
            "Confusion matrix is  [[970241  38777]\n",
            " [ 95185 324232]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.94   1009018\n",
            "           1       0.89      0.77      0.83    419417\n",
            "\n",
            "    accuracy                           0.91   1428435\n",
            "   macro avg       0.90      0.87      0.88   1428435\n",
            "weighted avg       0.91      0.91      0.90   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c398b2e8416e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgbclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mrunXGBoostModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-c398b2e8416e>\u001b[0m in \u001b[0;36mrunXGBoostModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgbclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mrunXGBoostModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lgbclassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p2HsWMEd3adP",
        "colab": {}
      },
      "source": [
        "def runXGBoostModel():\n",
        "  # fit model no training data\n",
        "  model = XGBClassifier()\n",
        "  eval_set = [(X_test, Y_test)]\n",
        "  model.fit(X_train, Y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
        "  # make predictions for test data\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"Initial predictions are \",y_pred)\n",
        "  predictions = [round(value) for value in y_pred]\n",
        "  # evaluate predictions\n",
        "  report(Y_test,predictions)\n",
        "  X=pd.concat([X_train,X_test])\n",
        "  y=pd.concat([Y_train,Y_test])\n",
        "  cross_validation(lgbclassifier,X,y)\n",
        "  \n",
        "runXGBoostModel()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}