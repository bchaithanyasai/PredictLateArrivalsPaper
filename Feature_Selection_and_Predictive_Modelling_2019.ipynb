{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Selection and Predictive Modelling-2019",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP3UGCDYLRM9Np3L3JKeM5f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bchaithanyasai/PredictLateArrivalsPaper/blob/master/Feature_Selection_and_Predictive_Modelling_2019.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zk626ZMKEedL",
        "outputId": "d6f20930-50a2-42d4-a381-a8d5627d21c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4mJaM6qcFABM",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data=pd.read_csv(\"/content/drive/My Drive/train_data_2019.csv\")\n",
        "test_data=pd.read_csv(\"/content/drive/My Drive/test_data_2019.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mQQWbYz2gMIN",
        "outputId": "0383f66f-94b7-41b2-e2bf-8b7e1234071d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_data.OUTCOME.mean(),test_data.OUTCOME.mean())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5 0.2844134268265696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8nFtnzW2ZDo_",
        "outputId": "4d8312e6-5b2e-44ce-b578-8d2a04c00f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "train_data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>9E</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>G4</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OH</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>WN</th>\n",
              "      <th>YV</th>\n",
              "      <th>YX</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.363194</td>\n",
              "      <td>0.276112</td>\n",
              "      <td>0.172746</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>586.000000</td>\n",
              "      <td>2085.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.280897</td>\n",
              "      <td>0.254714</td>\n",
              "      <td>0.988349</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>562.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1197.0</td>\n",
              "      <td>1167.000000</td>\n",
              "      <td>2936.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.254740</td>\n",
              "      <td>0.295210</td>\n",
              "      <td>0.547704</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>829.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1677.0</td>\n",
              "      <td>1689.000000</td>\n",
              "      <td>2879.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.307638</td>\n",
              "      <td>0.285337</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>948.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1034.0</td>\n",
              "      <td>969.000000</td>\n",
              "      <td>3810.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.278899</td>\n",
              "      <td>0.346516</td>\n",
              "      <td>0.878470</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>431.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1955.0</td>\n",
              "      <td>1924.000000</td>\n",
              "      <td>5199.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803243</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>10.663059</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>3.347763</td>\n",
              "      <td>0.253447</td>\n",
              "      <td>0.246818</td>\n",
              "      <td>0.101423</td>\n",
              "      <td>32.336941</td>\n",
              "      <td>48.315296</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>25.989178</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1698.0</td>\n",
              "      <td>1671.000000</td>\n",
              "      <td>4262.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.315296</td>\n",
              "      <td>13.315296</td>\n",
              "      <td>14.315296</td>\n",
              "      <td>15.315296</td>\n",
              "      <td>18.315296</td>\n",
              "      <td>6.630592</td>\n",
              "      <td>13.315296</td>\n",
              "      <td>47.652237</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803244</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>19.355369</td>\n",
              "      <td>4.355369</td>\n",
              "      <td>0.225014</td>\n",
              "      <td>0.299424</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.966946</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>601.000000</td>\n",
              "      <td>90.611577</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.809899</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1493.0</td>\n",
              "      <td>1506.000000</td>\n",
              "      <td>6008.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.677685</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>22.570303</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>14.198322</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803245</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>5.140977</td>\n",
              "      <td>18.845860</td>\n",
              "      <td>5.295116</td>\n",
              "      <td>0.286872</td>\n",
              "      <td>0.298326</td>\n",
              "      <td>0.910206</td>\n",
              "      <td>11.268791</td>\n",
              "      <td>90.140977</td>\n",
              "      <td>408.000000</td>\n",
              "      <td>58.563907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.255628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1173.0</td>\n",
              "      <td>1160.000000</td>\n",
              "      <td>1397.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>23.295116</td>\n",
              "      <td>57.718047</td>\n",
              "      <td>27.859023</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>34.563907</td>\n",
              "      <td>0.859023</td>\n",
              "      <td>0.859023</td>\n",
              "      <td>0.859023</td>\n",
              "      <td>0.859023</td>\n",
              "      <td>0.859023</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803246</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>21.805989</td>\n",
              "      <td>3.477604</td>\n",
              "      <td>0.311624</td>\n",
              "      <td>0.281179</td>\n",
              "      <td>0.305898</td>\n",
              "      <td>19.283594</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>541.000000</td>\n",
              "      <td>80.761198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>340.0</td>\n",
              "      <td>355.000000</td>\n",
              "      <td>1094.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>21.343230</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>40.626823</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803247</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>9.049170</td>\n",
              "      <td>9.590166</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.289787</td>\n",
              "      <td>0.308171</td>\n",
              "      <td>0.131682</td>\n",
              "      <td>55.836080</td>\n",
              "      <td>89.819668</td>\n",
              "      <td>279.704917</td>\n",
              "      <td>59.819668</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.180332</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1949.0</td>\n",
              "      <td>1872.180332</td>\n",
              "      <td>4747.590166</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.590166</td>\n",
              "      <td>8.590166</td>\n",
              "      <td>10.590166</td>\n",
              "      <td>49.409834</td>\n",
              "      <td>51.475415</td>\n",
              "      <td>21.295083</td>\n",
              "      <td>9.590166</td>\n",
              "      <td>45.245914</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7803248 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR      MONTH  ...  WEATHER_DELAY_is_missing  OUTCOME\n",
              "0        2019.0   2.000000  ...                  1.000000        0\n",
              "1        2019.0   9.000000  ...                  0.000000        1\n",
              "2        2019.0   3.000000  ...                  1.000000        1\n",
              "3        2019.0   6.000000  ...                  0.000000        1\n",
              "4        2019.0   4.000000  ...                  1.000000        1\n",
              "...         ...        ...  ...                       ...      ...\n",
              "7803243  2019.0  10.663059  ...                  1.000000        1\n",
              "7803244  2019.0   9.000000  ...                  0.000000        1\n",
              "7803245  2019.0   5.140977  ...                  0.859023        1\n",
              "7803246  2019.0   1.000000  ...                  1.000000        1\n",
              "7803247  2019.0   9.049170  ...                  0.000000        1\n",
              "\n",
              "[7803248 rows x 51 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vvUpEEFbZGZ9",
        "outputId": "0395d857-5a46-41b2-cc25-dda95a7dd38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "test_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>9E</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>G4</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OH</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>WN</th>\n",
              "      <th>YV</th>\n",
              "      <th>YX</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019</td>\n",
              "      <td>6</td>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>0.217848</td>\n",
              "      <td>0.254714</td>\n",
              "      <td>0.055675</td>\n",
              "      <td>11.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>605.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1191</td>\n",
              "      <td>1167</td>\n",
              "      <td>2613</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>54</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019</td>\n",
              "      <td>5</td>\n",
              "      <td>31</td>\n",
              "      <td>5</td>\n",
              "      <td>0.348094</td>\n",
              "      <td>0.270726</td>\n",
              "      <td>0.070983</td>\n",
              "      <td>33.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>974</td>\n",
              "      <td>1073</td>\n",
              "      <td>1811</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>28</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019</td>\n",
              "      <td>11</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>0.290462</td>\n",
              "      <td>0.316392</td>\n",
              "      <td>0.079499</td>\n",
              "      <td>16.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>416.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1311</td>\n",
              "      <td>1437</td>\n",
              "      <td>1242</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>18</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0.326653</td>\n",
              "      <td>0.236877</td>\n",
              "      <td>0.047858</td>\n",
              "      <td>10.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>349.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1410</td>\n",
              "      <td>1428</td>\n",
              "      <td>3700</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>50</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.246815</td>\n",
              "      <td>0.273759</td>\n",
              "      <td>0.079499</td>\n",
              "      <td>16.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>448.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>161</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816597</th>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>0.246815</td>\n",
              "      <td>0.300134</td>\n",
              "      <td>0.101423</td>\n",
              "      <td>9.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>674.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>401</td>\n",
              "      <td>544</td>\n",
              "      <td>303</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>21</td>\n",
              "      <td>31</td>\n",
              "      <td>14</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816598</th>\n",
              "      <td>2019</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0.240225</td>\n",
              "      <td>0.273006</td>\n",
              "      <td>0.157092</td>\n",
              "      <td>20.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>626.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91</td>\n",
              "      <td>30</td>\n",
              "      <td>3993</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>55</td>\n",
              "      <td>55</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816599</th>\n",
              "      <td>2019</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>0.286687</td>\n",
              "      <td>0.263243</td>\n",
              "      <td>0.989352</td>\n",
              "      <td>13.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>345.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1681</td>\n",
              "      <td>1712</td>\n",
              "      <td>3176</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>58</td>\n",
              "      <td>20</td>\n",
              "      <td>45</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816600</th>\n",
              "      <td>2019</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>0.320773</td>\n",
              "      <td>0.223493</td>\n",
              "      <td>0.132316</td>\n",
              "      <td>11.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117</td>\n",
              "      <td>5</td>\n",
              "      <td>5811</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816601</th>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0.306975</td>\n",
              "      <td>0.316392</td>\n",
              "      <td>0.091360</td>\n",
              "      <td>10.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>738.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1005</td>\n",
              "      <td>1049</td>\n",
              "      <td>2585</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1816602 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         YEAR  MONTH  ...  WEATHER_DELAY_is_missing  OUTCOME\n",
              "0        2019      6  ...                         1        0\n",
              "1        2019      5  ...                         1        1\n",
              "2        2019     11  ...                         1        0\n",
              "3        2019      5  ...                         1        0\n",
              "4        2019      9  ...                         1        0\n",
              "...       ...    ...  ...                       ...      ...\n",
              "1816597  2019      1  ...                         1        0\n",
              "1816598  2019     12  ...                         1        0\n",
              "1816599  2019      5  ...                         0        1\n",
              "1816600  2019     11  ...                         1        0\n",
              "1816601  2019      9  ...                         1        1\n",
              "\n",
              "[1816602 rows x 51 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aigROTKhFYB6",
        "colab": {}
      },
      "source": [
        "Y_train=pd.DataFrame(train_data['OUTCOME'])\n",
        "X_train=train_data.drop(\"OUTCOME\",axis=1)\n",
        "\n",
        "Y_test=pd.DataFrame(test_data['OUTCOME'])\n",
        "X_test=test_data.drop(\"OUTCOME\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T6ZfhIrJFoAo",
        "outputId": "9ff5253b-51ae-45b7-acdc-cf188912ddd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>9E</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>G4</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OH</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>WN</th>\n",
              "      <th>YV</th>\n",
              "      <th>YX</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.363194</td>\n",
              "      <td>0.276112</td>\n",
              "      <td>0.172746</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>586.000000</td>\n",
              "      <td>2085.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.280897</td>\n",
              "      <td>0.254714</td>\n",
              "      <td>0.988349</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>562.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1197.0</td>\n",
              "      <td>1167.000000</td>\n",
              "      <td>2936.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.254740</td>\n",
              "      <td>0.295210</td>\n",
              "      <td>0.547704</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>829.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1677.0</td>\n",
              "      <td>1689.000000</td>\n",
              "      <td>2879.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.307638</td>\n",
              "      <td>0.285337</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>948.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1034.0</td>\n",
              "      <td>969.000000</td>\n",
              "      <td>3810.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.278899</td>\n",
              "      <td>0.346516</td>\n",
              "      <td>0.878470</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>431.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1955.0</td>\n",
              "      <td>1924.000000</td>\n",
              "      <td>5199.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803243</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>10.663059</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>3.347763</td>\n",
              "      <td>0.253447</td>\n",
              "      <td>0.246818</td>\n",
              "      <td>0.101423</td>\n",
              "      <td>32.336941</td>\n",
              "      <td>48.315296</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>25.989178</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1698.0</td>\n",
              "      <td>1671.000000</td>\n",
              "      <td>4262.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.315296</td>\n",
              "      <td>13.315296</td>\n",
              "      <td>14.315296</td>\n",
              "      <td>15.315296</td>\n",
              "      <td>18.315296</td>\n",
              "      <td>6.630592</td>\n",
              "      <td>13.315296</td>\n",
              "      <td>47.652237</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803244</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>19.355369</td>\n",
              "      <td>4.355369</td>\n",
              "      <td>0.225014</td>\n",
              "      <td>0.299424</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.966946</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>601.000000</td>\n",
              "      <td>90.611577</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.809899</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1493.0</td>\n",
              "      <td>1506.000000</td>\n",
              "      <td>6008.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.677685</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>22.570303</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>14.198322</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803245</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>5.140977</td>\n",
              "      <td>18.845860</td>\n",
              "      <td>5.295116</td>\n",
              "      <td>0.286872</td>\n",
              "      <td>0.298326</td>\n",
              "      <td>0.910206</td>\n",
              "      <td>11.268791</td>\n",
              "      <td>90.140977</td>\n",
              "      <td>408.000000</td>\n",
              "      <td>58.563907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.255628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1173.0</td>\n",
              "      <td>1160.000000</td>\n",
              "      <td>1397.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>23.295116</td>\n",
              "      <td>57.718047</td>\n",
              "      <td>27.859023</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>34.563907</td>\n",
              "      <td>0.859023</td>\n",
              "      <td>0.859023</td>\n",
              "      <td>0.859023</td>\n",
              "      <td>0.859023</td>\n",
              "      <td>0.859023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803246</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>21.805989</td>\n",
              "      <td>3.477604</td>\n",
              "      <td>0.311624</td>\n",
              "      <td>0.281179</td>\n",
              "      <td>0.305898</td>\n",
              "      <td>19.283594</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>541.000000</td>\n",
              "      <td>80.761198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>340.0</td>\n",
              "      <td>355.000000</td>\n",
              "      <td>1094.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>21.343230</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>40.626823</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803247</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>9.049170</td>\n",
              "      <td>9.590166</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.289787</td>\n",
              "      <td>0.308171</td>\n",
              "      <td>0.131682</td>\n",
              "      <td>55.836080</td>\n",
              "      <td>89.819668</td>\n",
              "      <td>279.704917</td>\n",
              "      <td>59.819668</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.180332</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1949.0</td>\n",
              "      <td>1872.180332</td>\n",
              "      <td>4747.590166</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.590166</td>\n",
              "      <td>8.590166</td>\n",
              "      <td>10.590166</td>\n",
              "      <td>49.409834</td>\n",
              "      <td>51.475415</td>\n",
              "      <td>21.295083</td>\n",
              "      <td>9.590166</td>\n",
              "      <td>45.245914</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7803248 rows × 50 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR  ...  WEATHER_DELAY_is_missing\n",
              "0        2019.0  ...                  1.000000\n",
              "1        2019.0  ...                  0.000000\n",
              "2        2019.0  ...                  1.000000\n",
              "3        2019.0  ...                  0.000000\n",
              "4        2019.0  ...                  1.000000\n",
              "...         ...  ...                       ...\n",
              "7803243  2019.0  ...                  1.000000\n",
              "7803244  2019.0  ...                  0.000000\n",
              "7803245  2019.0  ...                  0.859023\n",
              "7803246  2019.0  ...                  1.000000\n",
              "7803247  2019.0  ...                  0.000000\n",
              "\n",
              "[7803248 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RIeo9LwFZl6W",
        "outputId": "ceb5a089-5662-4a44-b286-d2881694e32a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_train[:5449996]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>9E</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>G4</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OH</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>WN</th>\n",
              "      <th>YV</th>\n",
              "      <th>YX</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.363194</td>\n",
              "      <td>0.276112</td>\n",
              "      <td>0.172746</td>\n",
              "      <td>25.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>586.0</td>\n",
              "      <td>2085.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.280897</td>\n",
              "      <td>0.254714</td>\n",
              "      <td>0.988349</td>\n",
              "      <td>14.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>562.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1197.0</td>\n",
              "      <td>1167.0</td>\n",
              "      <td>2936.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.254740</td>\n",
              "      <td>0.295210</td>\n",
              "      <td>0.547704</td>\n",
              "      <td>10.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>829.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1677.0</td>\n",
              "      <td>1689.0</td>\n",
              "      <td>2879.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.307638</td>\n",
              "      <td>0.285337</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>18.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>948.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1034.0</td>\n",
              "      <td>969.0</td>\n",
              "      <td>3810.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.278899</td>\n",
              "      <td>0.346516</td>\n",
              "      <td>0.878470</td>\n",
              "      <td>24.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>431.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1955.0</td>\n",
              "      <td>1924.0</td>\n",
              "      <td>5199.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5449991</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.337451</td>\n",
              "      <td>0.279267</td>\n",
              "      <td>0.132316</td>\n",
              "      <td>16.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>533.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1662.0</td>\n",
              "      <td>1688.0</td>\n",
              "      <td>1576.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5449992</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.246815</td>\n",
              "      <td>0.309531</td>\n",
              "      <td>0.115647</td>\n",
              "      <td>15.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>1264.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5449993</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.311624</td>\n",
              "      <td>0.288380</td>\n",
              "      <td>0.115647</td>\n",
              "      <td>27.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>1089.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5449994</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.289787</td>\n",
              "      <td>0.304345</td>\n",
              "      <td>0.079499</td>\n",
              "      <td>10.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>1325.0</td>\n",
              "      <td>189.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1823.0</td>\n",
              "      <td>1787.0</td>\n",
              "      <td>4775.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5449995</th>\n",
              "      <td>2019.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.307638</td>\n",
              "      <td>0.243274</td>\n",
              "      <td>0.999190</td>\n",
              "      <td>14.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>946.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>3804.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5449996 rows × 50 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           YEAR  ...  WEATHER_DELAY_is_missing\n",
              "0        2019.0  ...                       1.0\n",
              "1        2019.0  ...                       0.0\n",
              "2        2019.0  ...                       1.0\n",
              "3        2019.0  ...                       0.0\n",
              "4        2019.0  ...                       1.0\n",
              "...         ...  ...                       ...\n",
              "5449991  2019.0  ...                       1.0\n",
              "5449992  2019.0  ...                       1.0\n",
              "5449993  2019.0  ...                       1.0\n",
              "5449994  2019.0  ...                       1.0\n",
              "5449995  2019.0  ...                       0.0\n",
              "\n",
              "[5449996 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XDNQRu46FrIu",
        "outputId": "ad1052e8-fdf2-4382-886b-01161ee09816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "Y_train"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803243</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803244</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803245</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803246</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7803247</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7803248 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         OUTCOME\n",
              "0              0\n",
              "1              1\n",
              "2              1\n",
              "3              1\n",
              "4              1\n",
              "...          ...\n",
              "7803243        1\n",
              "7803244        1\n",
              "7803245        1\n",
              "7803246        1\n",
              "7803247        1\n",
              "\n",
              "[7803248 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B5vXc6IeFrS4",
        "outputId": "847e99e4-e4fa-45ab-e228-b885d49e0772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "X_test"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>DEPARTURE_DELAY</th>\n",
              "      <th>TAXI_OUT</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>AIR_SYSTEM_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>AIRLINE_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>AIRLINE_ORIGIN_AIRPORT</th>\n",
              "      <th>AIRLINE_DESTINATION_AIRPORT</th>\n",
              "      <th>ORIGIN_AIRPORT_DESTINATION_AIRPORT</th>\n",
              "      <th>9E</th>\n",
              "      <th>AA</th>\n",
              "      <th>AS</th>\n",
              "      <th>B6</th>\n",
              "      <th>DL</th>\n",
              "      <th>EV</th>\n",
              "      <th>F9</th>\n",
              "      <th>G4</th>\n",
              "      <th>HA</th>\n",
              "      <th>MQ</th>\n",
              "      <th>NK</th>\n",
              "      <th>OH</th>\n",
              "      <th>OO</th>\n",
              "      <th>UA</th>\n",
              "      <th>WN</th>\n",
              "      <th>YV</th>\n",
              "      <th>YX</th>\n",
              "      <th>DEPARTURE_TIME_HOUR</th>\n",
              "      <th>SCHEDULED_DEPARTURE_HOUR</th>\n",
              "      <th>SCHEDULED_ARRIVAL_HOUR</th>\n",
              "      <th>DEPARTURE_TIME_MINUTE</th>\n",
              "      <th>SCHEDULED_DEPARTURE_MINUTE</th>\n",
              "      <th>SCHEDULED_ARRIVAL_MINUTE</th>\n",
              "      <th>WHEELS_OFF_HOUR</th>\n",
              "      <th>WHEELS_OFF_MINUTE</th>\n",
              "      <th>AIR_SYSTEM_DELAY_is_missing</th>\n",
              "      <th>SECURITY_DELAY_is_missing</th>\n",
              "      <th>AIRLINE_DELAY_is_missing</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY_is_missing</th>\n",
              "      <th>WEATHER_DELAY_is_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019</td>\n",
              "      <td>6</td>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>0.217848</td>\n",
              "      <td>0.254714</td>\n",
              "      <td>0.055675</td>\n",
              "      <td>11.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>605.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1191</td>\n",
              "      <td>1167</td>\n",
              "      <td>2613</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>54</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019</td>\n",
              "      <td>5</td>\n",
              "      <td>31</td>\n",
              "      <td>5</td>\n",
              "      <td>0.348094</td>\n",
              "      <td>0.270726</td>\n",
              "      <td>0.070983</td>\n",
              "      <td>33.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>974</td>\n",
              "      <td>1073</td>\n",
              "      <td>1811</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>28</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019</td>\n",
              "      <td>11</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>0.290462</td>\n",
              "      <td>0.316392</td>\n",
              "      <td>0.079499</td>\n",
              "      <td>16.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>416.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1311</td>\n",
              "      <td>1437</td>\n",
              "      <td>1242</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>18</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0.326653</td>\n",
              "      <td>0.236877</td>\n",
              "      <td>0.047858</td>\n",
              "      <td>10.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>349.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1410</td>\n",
              "      <td>1428</td>\n",
              "      <td>3700</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>50</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.246815</td>\n",
              "      <td>0.273759</td>\n",
              "      <td>0.079499</td>\n",
              "      <td>16.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>448.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>161</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816597</th>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>0.246815</td>\n",
              "      <td>0.300134</td>\n",
              "      <td>0.101423</td>\n",
              "      <td>9.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>674.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>401</td>\n",
              "      <td>544</td>\n",
              "      <td>303</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>21</td>\n",
              "      <td>31</td>\n",
              "      <td>14</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816598</th>\n",
              "      <td>2019</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0.240225</td>\n",
              "      <td>0.273006</td>\n",
              "      <td>0.157092</td>\n",
              "      <td>20.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>626.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91</td>\n",
              "      <td>30</td>\n",
              "      <td>3993</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>55</td>\n",
              "      <td>55</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816599</th>\n",
              "      <td>2019</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>0.286687</td>\n",
              "      <td>0.263243</td>\n",
              "      <td>0.989352</td>\n",
              "      <td>13.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>345.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1681</td>\n",
              "      <td>1712</td>\n",
              "      <td>3176</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>58</td>\n",
              "      <td>20</td>\n",
              "      <td>45</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816600</th>\n",
              "      <td>2019</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>0.320773</td>\n",
              "      <td>0.223493</td>\n",
              "      <td>0.132316</td>\n",
              "      <td>11.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117</td>\n",
              "      <td>5</td>\n",
              "      <td>5811</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816601</th>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0.306975</td>\n",
              "      <td>0.316392</td>\n",
              "      <td>0.091360</td>\n",
              "      <td>10.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>738.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1005</td>\n",
              "      <td>1049</td>\n",
              "      <td>2585</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1816602 rows × 50 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         YEAR  MONTH  ...  LATE_AIRCRAFT_DELAY_is_missing  WEATHER_DELAY_is_missing\n",
              "0        2019      6  ...                               1                         1\n",
              "1        2019      5  ...                               1                         1\n",
              "2        2019     11  ...                               1                         1\n",
              "3        2019      5  ...                               1                         1\n",
              "4        2019      9  ...                               1                         1\n",
              "...       ...    ...  ...                             ...                       ...\n",
              "1816597  2019      1  ...                               1                         1\n",
              "1816598  2019     12  ...                               1                         1\n",
              "1816599  2019      5  ...                               0                         0\n",
              "1816600  2019     11  ...                               1                         1\n",
              "1816601  2019      9  ...                               1                         1\n",
              "\n",
              "[1816602 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KrZdDvSZFrcm",
        "outputId": "786a2962-c6dd-4a33-ef42-dcf705ba6db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816597</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816598</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816599</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816600</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816601</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1816602 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         OUTCOME\n",
              "0              0\n",
              "1              1\n",
              "2              0\n",
              "3              0\n",
              "4              0\n",
              "...          ...\n",
              "1816597        0\n",
              "1816598        0\n",
              "1816599        1\n",
              "1816600        0\n",
              "1816601        1\n",
              "\n",
              "[1816602 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FO3YyADUn0UN",
        "colab": {}
      },
      "source": [
        "####Unused as it would be used for regression problems\n",
        "from sklearn.feature_selection import SelectPercentile, f_regression                      \n",
        "Selector_f = SelectPercentile(f_regression, percentile=25)\n",
        "Selector_f.fit(X,y)\n",
        "for n,s in zip(Unhandled_data.feature_names,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s \" % (s,n))\n",
        "Selector_f.get_support(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SpVyYrOyGYoH",
        "outputId": "04d45ec4-483a-4737-ed76-1bfa265158df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "X_train.columns"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT',\n",
              "       'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'SCHEDULED_TIME',\n",
              "       'DISTANCE', 'AIR_TIME', 'DIVERTED', 'AIR_SYSTEM_DELAY',\n",
              "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
              "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
              "       'AIRLINE_DESTINATION_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT',\n",
              "       '9E', 'AA', 'AS', 'B6', 'DL', 'EV', 'F9', 'G4', 'HA', 'MQ', 'NK', 'OH',\n",
              "       'OO', 'UA', 'WN', 'YV', 'YX', 'DEPARTURE_TIME_HOUR',\n",
              "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR',\n",
              "       'DEPARTURE_TIME_MINUTE', 'SCHEDULED_DEPARTURE_MINUTE',\n",
              "       'SCHEDULED_ARRIVAL_MINUTE', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE',\n",
              "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
              "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
              "       'WEATHER_DELAY_is_missing'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ubU8RqqzAvk",
        "colab_type": "code",
        "outputId": "752cc82a-a1eb-40c5-ff9d-4feef9d2c18d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=25)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 7819.05t for feature MONTH\n",
            "F-score: 494.23t for feature DAY\n",
            "F-score: 131.66t for feature DAY_OF_WEEK\n",
            "F-score: 76681.66t for feature ORIGIN_AIRPORT\n",
            "F-score: 56022.44t for feature DESTINATION_AIRPORT\n",
            "F-score: 6993080.93t for feature DEPARTURE_DELAY\n",
            "F-score: 708176.92t for feature TAXI_OUT\n",
            "F-score: 8354.21t for feature SCHEDULED_TIME\n",
            "F-score: 7706.49t for feature DISTANCE\n",
            "F-score: 29919.99t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 404150.90t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 1993.08t for feature SECURITY_DELAY\n",
            "F-score: 254838.41t for feature AIRLINE_DELAY\n",
            "F-score: 631582.24t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 32915.76t for feature WEATHER_DELAY\n",
            "F-score: 8.63t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 0.14t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 212.77t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 3944.10t for feature 9E\n",
            "F-score: 6155.85t for feature AA\n",
            "F-score: 43.31t for feature AS\n",
            "F-score: 4064.27t for feature B6\n",
            "F-score: 21823.55t for feature DL\n",
            "F-score: 3509.61t for feature EV\n",
            "F-score: 3685.87t for feature F9\n",
            "F-score: 545.05t for feature G4\n",
            "F-score: 1015.92t for feature HA\n",
            "F-score: 1603.27t for feature MQ\n",
            "F-score: 270.35t for feature NK\n",
            "F-score: 188.54t for feature OH\n",
            "F-score: 972.79t for feature OO\n",
            "F-score: 1660.80t for feature UA\n",
            "F-score: 238.91t for feature WN\n",
            "F-score: 490.53t for feature YV\n",
            "F-score: 351.16t for feature YX\n",
            "F-score: 306465.99t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 189798.65t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 146598.91t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 7594.70t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 4283.97t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 163.76t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 310164.44t for feature WHEELS_OFF_HOUR\n",
            "F-score: 5025.17t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 7974292.91t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 7974292.91t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 7974292.91t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 7974292.91t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 7974292.91t for feature WEATHER_DELAY_is_missing\n",
            "Index(['DEPARTURE_DELAY', 'TAXI_OUT', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'WHEELS_OFF_HOUR',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
            "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
            "       'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DMVewQKgHfpC",
        "outputId": "e8091325-c207-4945-c5b1-dab5978e9790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=50)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 7819.05t for feature MONTH\n",
            "F-score: 494.23t for feature DAY\n",
            "F-score: 131.66t for feature DAY_OF_WEEK\n",
            "F-score: 76681.66t for feature ORIGIN_AIRPORT\n",
            "F-score: 56022.44t for feature DESTINATION_AIRPORT\n",
            "F-score: 6993080.93t for feature DEPARTURE_DELAY\n",
            "F-score: 708176.92t for feature TAXI_OUT\n",
            "F-score: 8354.21t for feature SCHEDULED_TIME\n",
            "F-score: 7706.49t for feature DISTANCE\n",
            "F-score: 29919.99t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 404150.90t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 1993.08t for feature SECURITY_DELAY\n",
            "F-score: 254838.41t for feature AIRLINE_DELAY\n",
            "F-score: 631582.24t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 32915.76t for feature WEATHER_DELAY\n",
            "F-score: 8.63t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 0.14t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 212.77t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 3944.10t for feature 9E\n",
            "F-score: 6155.85t for feature AA\n",
            "F-score: 43.31t for feature AS\n",
            "F-score: 4064.27t for feature B6\n",
            "F-score: 21823.55t for feature DL\n",
            "F-score: 3509.61t for feature EV\n",
            "F-score: 3685.87t for feature F9\n",
            "F-score: 545.05t for feature G4\n",
            "F-score: 1015.92t for feature HA\n",
            "F-score: 1603.27t for feature MQ\n",
            "F-score: 270.35t for feature NK\n",
            "F-score: 188.54t for feature OH\n",
            "F-score: 972.79t for feature OO\n",
            "F-score: 1660.80t for feature UA\n",
            "F-score: 238.91t for feature WN\n",
            "F-score: 490.53t for feature YV\n",
            "F-score: 351.16t for feature YX\n",
            "F-score: 306465.99t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 189798.65t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 146598.91t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 7594.70t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 4283.97t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 163.76t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 310164.44t for feature WHEELS_OFF_HOUR\n",
            "F-score: 5025.17t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 7974292.91t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 7974292.91t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 7974292.91t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 7974292.91t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 7974292.91t for feature WEATHER_DELAY_is_missing\n",
            "Index(['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
            "       'TAXI_OUT', 'SCHEDULED_TIME', 'DISTANCE', 'AIR_TIME',\n",
            "       'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AA', 'DL', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR',\n",
            "       'DEPARTURE_TIME_MINUTE', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE',\n",
            "       'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing',\n",
            "       'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing',\n",
            "       'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TyOUNz2dgJAq",
        "outputId": "6ce2438f-e71b-4e0a-aaf7-c680f0aca479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "Selector_f = SelectPercentile(f_classif, percentile=75)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print(\"F-score: %3.2ft for feature %s\" % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F-score: nant for feature YEAR\n",
            "F-score: 7819.05t for feature MONTH\n",
            "F-score: 494.23t for feature DAY\n",
            "F-score: 131.66t for feature DAY_OF_WEEK\n",
            "F-score: 76681.66t for feature ORIGIN_AIRPORT\n",
            "F-score: 56022.44t for feature DESTINATION_AIRPORT\n",
            "F-score: 6993080.93t for feature DEPARTURE_DELAY\n",
            "F-score: 708176.92t for feature TAXI_OUT\n",
            "F-score: 8354.21t for feature SCHEDULED_TIME\n",
            "F-score: 7706.49t for feature DISTANCE\n",
            "F-score: 29919.99t for feature AIR_TIME\n",
            "F-score: nant for feature DIVERTED\n",
            "F-score: 404150.90t for feature AIR_SYSTEM_DELAY\n",
            "F-score: 1993.08t for feature SECURITY_DELAY\n",
            "F-score: 254838.41t for feature AIRLINE_DELAY\n",
            "F-score: 631582.24t for feature LATE_AIRCRAFT_DELAY\n",
            "F-score: 32915.76t for feature WEATHER_DELAY\n",
            "F-score: 8.63t for feature AIRLINE_ORIGIN_AIRPORT\n",
            "F-score: 0.14t for feature AIRLINE_DESTINATION_AIRPORT\n",
            "F-score: 212.77t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT\n",
            "F-score: 3944.10t for feature 9E\n",
            "F-score: 6155.85t for feature AA\n",
            "F-score: 43.31t for feature AS\n",
            "F-score: 4064.27t for feature B6\n",
            "F-score: 21823.55t for feature DL\n",
            "F-score: 3509.61t for feature EV\n",
            "F-score: 3685.87t for feature F9\n",
            "F-score: 545.05t for feature G4\n",
            "F-score: 1015.92t for feature HA\n",
            "F-score: 1603.27t for feature MQ\n",
            "F-score: 270.35t for feature NK\n",
            "F-score: 188.54t for feature OH\n",
            "F-score: 972.79t for feature OO\n",
            "F-score: 1660.80t for feature UA\n",
            "F-score: 238.91t for feature WN\n",
            "F-score: 490.53t for feature YV\n",
            "F-score: 351.16t for feature YX\n",
            "F-score: 306465.99t for feature DEPARTURE_TIME_HOUR\n",
            "F-score: 189798.65t for feature SCHEDULED_DEPARTURE_HOUR\n",
            "F-score: 146598.91t for feature SCHEDULED_ARRIVAL_HOUR\n",
            "F-score: 7594.70t for feature DEPARTURE_TIME_MINUTE\n",
            "F-score: 4283.97t for feature SCHEDULED_DEPARTURE_MINUTE\n",
            "F-score: 163.76t for feature SCHEDULED_ARRIVAL_MINUTE\n",
            "F-score: 310164.44t for feature WHEELS_OFF_HOUR\n",
            "F-score: 5025.17t for feature WHEELS_OFF_MINUTE\n",
            "F-score: 7974292.91t for feature AIR_SYSTEM_DELAY_is_missing\n",
            "F-score: 7974292.91t for feature SECURITY_DELAY_is_missing\n",
            "F-score: 7974292.91t for feature AIRLINE_DELAY_is_missing\n",
            "F-score: 7974292.91t for feature LATE_AIRCRAFT_DELAY_is_missing\n",
            "F-score: 7974292.91t for feature WEATHER_DELAY_is_missing\n",
            "Index(['MONTH', 'DAY', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'DEPARTURE_DELAY', 'TAXI_OUT', 'SCHEDULED_TIME', 'DISTANCE', 'AIR_TIME',\n",
            "       'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', '9E', 'AA', 'B6', 'DL', 'EV',\n",
            "       'F9', 'G4', 'HA', 'MQ', 'OO', 'UA', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR',\n",
            "       'DEPARTURE_TIME_MINUTE', 'SCHEDULED_DEPARTURE_MINUTE',\n",
            "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
            "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 0 11] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H3DVM-Qtu-Fo",
        "outputId": "6911a8b9-d052-43fc-c7cc-84a75d95043c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=25)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 12687.81t for feature MONTH \n",
            "F-score: 2205.69t for feature DAY \n",
            "F-score: 122.17t for feature DAY_OF_WEEK \n",
            "F-score: 435.39t for feature ORIGIN_AIRPORT \n",
            "F-score: 226.24t for feature DESTINATION_AIRPORT \n",
            "F-score: 1327368.86t for feature DEPARTURE_DELAY \n",
            "F-score: 4407569.09t for feature TAXI_OUT \n",
            "F-score: 309078.92t for feature SCHEDULED_TIME \n",
            "F-score: 3370311.08t for feature DISTANCE \n",
            "F-score: 1340195.89t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 40941610.88t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 188996.54t for feature SECURITY_DELAY \n",
            "F-score: 53716042.04t for feature AIRLINE_DELAY \n",
            "F-score: 70264629.79t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 9365045.34t for feature WEATHER_DELAY \n",
            "F-score: 3265.55t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 51.39t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 230403.82t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 3811.94t for feature 9E \n",
            "F-score: 5344.71t for feature AA \n",
            "F-score: 41.74t for feature AS \n",
            "F-score: 3889.25t for feature B6 \n",
            "F-score: 18971.14t for feature DL \n",
            "F-score: 3440.60t for feature EV \n",
            "F-score: 3611.07t for feature F9 \n",
            "F-score: 536.52t for feature G4 \n",
            "F-score: 1004.60t for feature HA \n",
            "F-score: 1531.41t for feature MQ \n",
            "F-score: 262.89t for feature NK \n",
            "F-score: 181.11t for feature OH \n",
            "F-score: 864.99t for feature OO \n",
            "F-score: 1515.96t for feature UA \n",
            "F-score: 195.35t for feature WN \n",
            "F-score: 475.14t for feature YV \n",
            "F-score: 335.89t for feature YX \n",
            "F-score: 554662.59t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 320045.93t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 256745.66t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 76375.63t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 50190.70t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 1674.70t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 552913.66t for feature WHEELS_OFF_HOUR \n",
            "F-score: 50012.38t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 1256744.03t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 1256744.03t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 1256744.03t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 1256744.03t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 1256744.03t for feature WEATHER_DELAY_is_missing \n",
            "Index(['DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'AIR_TIME',\n",
            "       'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
            "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iZMAvNE7E9NS",
        "outputId": "6ae502d0-e85b-44d6-eaa0-10d5653ca6f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=50)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 12687.81t for feature MONTH \n",
            "F-score: 2205.69t for feature DAY \n",
            "F-score: 122.17t for feature DAY_OF_WEEK \n",
            "F-score: 435.39t for feature ORIGIN_AIRPORT \n",
            "F-score: 226.24t for feature DESTINATION_AIRPORT \n",
            "F-score: 1327368.86t for feature DEPARTURE_DELAY \n",
            "F-score: 4407569.09t for feature TAXI_OUT \n",
            "F-score: 309078.92t for feature SCHEDULED_TIME \n",
            "F-score: 3370311.08t for feature DISTANCE \n",
            "F-score: 1340195.89t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 40941610.88t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 188996.54t for feature SECURITY_DELAY \n",
            "F-score: 53716042.04t for feature AIRLINE_DELAY \n",
            "F-score: 70264629.79t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 9365045.34t for feature WEATHER_DELAY \n",
            "F-score: 3265.55t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 51.39t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 230403.82t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 3811.94t for feature 9E \n",
            "F-score: 5344.71t for feature AA \n",
            "F-score: 41.74t for feature AS \n",
            "F-score: 3889.25t for feature B6 \n",
            "F-score: 18971.14t for feature DL \n",
            "F-score: 3440.60t for feature EV \n",
            "F-score: 3611.07t for feature F9 \n",
            "F-score: 536.52t for feature G4 \n",
            "F-score: 1004.60t for feature HA \n",
            "F-score: 1531.41t for feature MQ \n",
            "F-score: 262.89t for feature NK \n",
            "F-score: 181.11t for feature OH \n",
            "F-score: 864.99t for feature OO \n",
            "F-score: 1515.96t for feature UA \n",
            "F-score: 195.35t for feature WN \n",
            "F-score: 475.14t for feature YV \n",
            "F-score: 335.89t for feature YX \n",
            "F-score: 554662.59t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 320045.93t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 256745.66t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 76375.63t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 50190.70t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 1674.70t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 552913.66t for feature WHEELS_OFF_HOUR \n",
            "F-score: 50012.38t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 1256744.03t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 1256744.03t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 1256744.03t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 1256744.03t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 1256744.03t for feature WEATHER_DELAY_is_missing \n",
            "Index(['MONTH', 'DEPARTURE_DELAY', 'TAXI_OUT', 'SCHEDULED_TIME', 'DISTANCE',\n",
            "       'AIR_TIME', 'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY',\n",
            "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY',\n",
            "       'ORIGIN_AIRPORT_DESTINATION_AIRPORT', 'DL', 'DEPARTURE_TIME_HOUR',\n",
            "       'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR',\n",
            "       'DEPARTURE_TIME_MINUTE', 'SCHEDULED_DEPARTURE_MINUTE',\n",
            "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
            "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5E3V06WmE_4l",
        "outputId": "b897ead0-26c7-4264-b9bf-60d6a2b899bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "Selector_f = SelectPercentile(chi2, percentile=75)\n",
        "Selector_f.fit(X_train,Y_train)\n",
        "for n,s in zip(X_train.columns,Selector_f.scores_):\n",
        " print('F-score: %3.2ft for feature %s ' % (s,n))\n",
        "print(X_train.columns[Selector_f.get_support(True)])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-score: 0.00t for feature YEAR \n",
            "F-score: 12687.81t for feature MONTH \n",
            "F-score: 2205.69t for feature DAY \n",
            "F-score: 122.17t for feature DAY_OF_WEEK \n",
            "F-score: 435.39t for feature ORIGIN_AIRPORT \n",
            "F-score: 226.24t for feature DESTINATION_AIRPORT \n",
            "F-score: 1327368.86t for feature DEPARTURE_DELAY \n",
            "F-score: 4407569.09t for feature TAXI_OUT \n",
            "F-score: 309078.92t for feature SCHEDULED_TIME \n",
            "F-score: 3370311.08t for feature DISTANCE \n",
            "F-score: 1340195.89t for feature AIR_TIME \n",
            "F-score: nant for feature DIVERTED \n",
            "F-score: 40941610.88t for feature AIR_SYSTEM_DELAY \n",
            "F-score: 188996.54t for feature SECURITY_DELAY \n",
            "F-score: 53716042.04t for feature AIRLINE_DELAY \n",
            "F-score: 70264629.79t for feature LATE_AIRCRAFT_DELAY \n",
            "F-score: 9365045.34t for feature WEATHER_DELAY \n",
            "F-score: 3265.55t for feature AIRLINE_ORIGIN_AIRPORT \n",
            "F-score: 51.39t for feature AIRLINE_DESTINATION_AIRPORT \n",
            "F-score: 230403.82t for feature ORIGIN_AIRPORT_DESTINATION_AIRPORT \n",
            "F-score: 3811.94t for feature 9E \n",
            "F-score: 5344.71t for feature AA \n",
            "F-score: 41.74t for feature AS \n",
            "F-score: 3889.25t for feature B6 \n",
            "F-score: 18971.14t for feature DL \n",
            "F-score: 3440.60t for feature EV \n",
            "F-score: 3611.07t for feature F9 \n",
            "F-score: 536.52t for feature G4 \n",
            "F-score: 1004.60t for feature HA \n",
            "F-score: 1531.41t for feature MQ \n",
            "F-score: 262.89t for feature NK \n",
            "F-score: 181.11t for feature OH \n",
            "F-score: 864.99t for feature OO \n",
            "F-score: 1515.96t for feature UA \n",
            "F-score: 195.35t for feature WN \n",
            "F-score: 475.14t for feature YV \n",
            "F-score: 335.89t for feature YX \n",
            "F-score: 554662.59t for feature DEPARTURE_TIME_HOUR \n",
            "F-score: 320045.93t for feature SCHEDULED_DEPARTURE_HOUR \n",
            "F-score: 256745.66t for feature SCHEDULED_ARRIVAL_HOUR \n",
            "F-score: 76375.63t for feature DEPARTURE_TIME_MINUTE \n",
            "F-score: 50190.70t for feature SCHEDULED_DEPARTURE_MINUTE \n",
            "F-score: 1674.70t for feature SCHEDULED_ARRIVAL_MINUTE \n",
            "F-score: 552913.66t for feature WHEELS_OFF_HOUR \n",
            "F-score: 50012.38t for feature WHEELS_OFF_MINUTE \n",
            "F-score: 1256744.03t for feature AIR_SYSTEM_DELAY_is_missing \n",
            "F-score: 1256744.03t for feature SECURITY_DELAY_is_missing \n",
            "F-score: 1256744.03t for feature AIRLINE_DELAY_is_missing \n",
            "F-score: 1256744.03t for feature LATE_AIRCRAFT_DELAY_is_missing \n",
            "F-score: 1256744.03t for feature WEATHER_DELAY_is_missing \n",
            "Index(['MONTH', 'DAY', 'DEPARTURE_DELAY', 'TAXI_OUT', 'SCHEDULED_TIME',\n",
            "       'DISTANCE', 'AIR_TIME', 'AIR_SYSTEM_DELAY', 'SECURITY_DELAY',\n",
            "       'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY',\n",
            "       'AIRLINE_ORIGIN_AIRPORT', 'ORIGIN_AIRPORT_DESTINATION_AIRPORT', '9E',\n",
            "       'AA', 'B6', 'DL', 'EV', 'F9', 'HA', 'MQ', 'OO', 'UA',\n",
            "       'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR',\n",
            "       'SCHEDULED_ARRIVAL_HOUR', 'DEPARTURE_TIME_MINUTE',\n",
            "       'SCHEDULED_DEPARTURE_MINUTE', 'SCHEDULED_ARRIVAL_MINUTE',\n",
            "       'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing',\n",
            "       'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing',\n",
            "       'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nnPzt_pvDJs6",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "val_df, test_df = train_test_split(test_data, test_size=0.333, random_state=0)\n",
        "\n",
        "#Y_train=pd.DataFrame(train_data['OUTCOME'])\n",
        "#X_train=train_data.drop(\"OUTCOME\",axis=1)\n",
        "\n",
        "Y_test=pd.DataFrame(test_df['OUTCOME'])\n",
        "X_test=test_df.drop(\"OUTCOME\",axis=1)\n",
        "\n",
        "Y_valid=pd.DataFrame(val_df['OUTCOME'])\n",
        "X_valid=val_df.drop(\"OUTCOME\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s_vLx-nobFzs",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer,accuracy_score,roc_auc_score\n",
        "from sklearn import metrics\n",
        "\n",
        "def cross_validation(model,X,y):\n",
        "  scores = cross_validate(model, X, y, scoring={'accuracy':make_scorer(accuracy_score),'roc_auc':make_scorer(roc_auc_score)},cv=5)\n",
        "  print(\"Cross-validated scores:\", scores)\n",
        "  print(\"cross for accuracy\",scores['test_accuracy'])\n",
        "  print(\"cross for roc-auc\",scores['test_roc_auc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZIBZy8h6bUmh",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "def report(Y_test,pred):\n",
        "  score1=metrics.roc_auc_score(Y_test,pred)\n",
        "  score2=metrics.accuracy_score(Y_test,pred)\n",
        "\n",
        "  print(f\"Test ROC AUC score: {score1}\")\n",
        "  print(f\"Test accuracy score: {score2}\")\n",
        "  print(\"Confusion matrix is \",metrics.confusion_matrix(Y_test,pred))\n",
        "  print(\"Classification report is \\n\",metrics.classification_report(Y_test,pred))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "REAFrlKudcHT",
        "colab": {}
      },
      "source": [
        "from math import log\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def calculate_aic(n, mse, num_params):\n",
        "\taic = n * log(mse) + 2 * num_params\n",
        "\treturn aic\n",
        "\n",
        "def calculate_bic(n, mse, num_params):\n",
        "\tbic = n * log(mse) + num_params * log(n)\n",
        "\treturn bic\n",
        "  \n",
        "def aic_and_bic(Y_test,pred,num_params):\n",
        "  mse=mean_squared_error(Y_test,pred)\n",
        "  print(pred)\n",
        "  print('Number of parameters: %d' % (num_params))\n",
        "  aic=calculate_aic(len(Y_train), mse, num_params)\n",
        "  print('AIC: %.3f' % aic)\n",
        "  bic = calculate_bic(len(y), mse, num_params)\n",
        "  print('BIC: %.3f' % bic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0jLcuAH-cSKo",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.svm import *\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iePhsaLZ50Im",
        "colab_type": "code",
        "outputId": "cfd2b0df-26a8-4491-86f4-fe441134efd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "cols=['MONTH','ORIGIN_AIRPORT','DESTINATION_AIRPORT','DEPARTURE_DELAY','TAXI_OUT','DISTANCE','SCHEDULED_TIME',\n",
        "'AIR_SYSTEM_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY','SECURITY_DELAY','AIRLINE_ORIGIN_AIRPORT','AIRLINE_DESTINATION_AIRPORT',\n",
        "'DEPARTURE_TIME_HOUR','SCHEDULED_DEPARTURE_HOUR','SCHEDULED_ARRIVAL_HOUR','WHEELS_OFF_HOUR','WHEELS_OFF_MINUTE',\n",
        "'AIR_SYSTEM_DELAY_is_missing','SECURITY_DELAY_is_missing','AIRLINE_DELAY_is_missing','LATE_AIRCRAFT_DELAY_is_missing','WEATHER_DELAY_is_missing']\n",
        "print(cols)\n",
        "print(len(cols))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n",
            "24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Qio4-8g6aQJ",
        "outputId": "16153ae2-57cb-4902-ae7c-cdef5b7c6e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "selected_cols=cols\n",
        "selected_X_train=X_train[selected_cols]\n",
        "print(selected_X_train)\n",
        "\n",
        "lgbmclassifier=LGBMClassifier()\n",
        "selector = RFECV(estimator=lgbmclassifier, cv=5,scoring='accuracy',n_jobs=1)\n",
        "selector.fit(selected_X_train,Y_train)\n",
        "print(\"Optimal number of features: %d\" % selector.n_features_)\n",
        "print(selected_X_train.columns[selector.support_])\n",
        "print(selector.ranking_)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             MONTH  ...  WEATHER_DELAY_is_missing\n",
            "0         2.000000  ...                  1.000000\n",
            "1         9.000000  ...                  0.000000\n",
            "2         3.000000  ...                  1.000000\n",
            "3         6.000000  ...                  0.000000\n",
            "4         4.000000  ...                  1.000000\n",
            "...            ...  ...                       ...\n",
            "7803243  10.663059  ...                  1.000000\n",
            "7803244   9.000000  ...                  0.000000\n",
            "7803245   5.140977  ...                  0.859023\n",
            "7803246   1.000000  ...                  1.000000\n",
            "7803247   9.049170  ...                  0.000000\n",
            "\n",
            "[7803248 rows x 24 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimal number of features: 10\n",
            "Index(['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
            "       'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'WHEELS_OFF_HOUR', 'AIR_SYSTEM_DELAY_is_missing'],\n",
            "      dtype='object')\n",
            "[ 1  1  1  1  1  1  1  7  9 11 13 15  1  2  3  5  4  1  6  1  8 10 12 14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "raZFbf_bIrHa",
        "outputId": "a66dc381-63e1-45e0-a644-61e600fbb55c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "model = LGBMClassifier()\n",
        "model.fit(X_train,Y_train)\n",
        "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "#plot graph of feature importances for better visualization\n",
        "feat_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
        "feat_importances.nlargest(26).plot(kind='barh')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[  0  34   2 108  24  43 609 484 740   4 777   0   0   0   0   0   0  13\n",
            "  17  17   0   0   1   0   6   0   0   3  14   5   0   0   1   0   0   0\n",
            "   0  10   2   6   0   0   0  11   0  69   0   0   0   0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4npaB9g2VN7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d9627f7-e62f-42d5-d1e0-75a68668bcf2"
      },
      "source": [
        "cols_after_removing_recursive=['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
        "       'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIRLINE_ORIGIN_AIRPORT',\n",
        "       'WHEELS_OFF_HOUR', 'AIR_SYSTEM_DELAY_is_missing']\n",
        "print(len(cols_after_removing_recursive))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5pi4gQReHbqt",
        "outputId": "57928af9-a056-487d-9f0c-635e399e7389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpBernoulliNBModel():\n",
        "  model = BernoulliNB()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpBernoulliNBModel()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [0 0 0 ... 1 0 0]\n",
            "Test ROC AUC score: 0.8374636612434339\n",
            "Test accuracy score: 0.9075449658208017\n",
            "Confusion matrix is  [[1299936       0]\n",
            " [ 167954  348712]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94   1299936\n",
            "           1       1.00      0.67      0.81    516666\n",
            "\n",
            "    accuracy                           0.91   1816602\n",
            "   macro avg       0.94      0.84      0.87   1816602\n",
            "weighted avg       0.92      0.91      0.90   1816602\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([3.62052512, 2.94342589, 2.8767035 , 2.85217285, 2.85275149]), 'score_time': array([0.95175314, 0.92906833, 0.94656348, 0.92230797, 0.92284727]), 'test_accuracy': array([0.90709279, 0.90726159, 0.90757623, 0.90709845, 0.90764744]), 'test_roc_auc': array([0.83655601, 0.83685295, 0.83740648, 0.83656563, 0.83753189])}\n",
            "cross for accuracy [0.90709279 0.90726159 0.90757623 0.90709845 0.90764744]\n",
            "cross for roc-auc [0.83655601 0.83685295 0.83740648 0.83656563 0.83753189]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22ySVGOSvxFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "cbbf18e2-6c61-4a36-a4b6-ad0278610fe8"
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpLinearSVCModel():\n",
        "  model = LinearSVC()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  #cross_validation(model,X,y)\n",
        "\n",
        "runexpLinearSVCModel()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [0 1 0 ... 1 0 0]\n",
            "Test ROC AUC score: 0.8936578082280344\n",
            "Test accuracy score: 0.9036684975575278\n",
            "Confusion matrix is  [[1191879  108057]\n",
            " [  66939  449727]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.92      0.93   1299936\n",
            "           1       0.81      0.87      0.84    516666\n",
            "\n",
            "    accuracy                           0.90   1816602\n",
            "   macro avg       0.88      0.89      0.88   1816602\n",
            "weighted avg       0.91      0.90      0.90   1816602\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y5T6_ef4OO_u",
        "outputId": "e7d7df4e-eeb0-4292-dd1d-a0e92f455904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpLinearSVCModel():\n",
        "  model = LinearSVC()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpLinearSVCModel()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([3161.3004806 , 3114.96133256, 2937.30273247, 2892.04454589,\n",
            "       2889.20614862]), 'score_time': array([0.74737263, 0.62743735, 0.87725472, 0.58317566, 0.92567039]), 'test_accuracy': array([0.92016778, 0.92153698, 0.92266609, 0.91168867, 0.92267341]), 'test_roc_auc': array([0.87726153, 0.86889676, 0.88253616, 0.84522923, 0.88018774])}\n",
            "cross for accuracy [0.92016778 0.92153698 0.92266609 0.91168867 0.92267341]\n",
            "cross for roc-auc [0.87726153 0.86889676 0.88253616 0.84522923 0.88018774]\n",
            "Cross-validated scores: {'fit_time': array([3161.3004806 , 3114.96133256, 2937.30273247, 2892.04454589,\n",
            "       2889.20614862]), 'score_time': array([0.74737263, 0.62743735, 0.87725472, 0.58317566, 0.92567039]), 'test_accuracy': array([0.92016778, 0.92153698, 0.92266609, 0.91168867, 0.92267341]), 'test_roc_auc': array([0.87726153, 0.86889676, 0.88253616, 0.84522923, 0.88018774])}\n",
            "cross for accuracy [0.92016778 0.92153698 0.92266609 0.91168867 0.92267341]\n",
            "cross for roc-auc [0.87726153 0.86889676 0.88253616 0.84522923 0.88018774]\n",
            "Cross-validated scores: {'fit_time': array([3161.3004806 , 3114.96133256, 2937.30273247, 2892.04454589,\n",
            "       2889.20614862]), 'score_time': array([0.74737263, 0.62743735, 0.87725472, 0.58317566, 0.92567039]), 'test_accuracy': array([0.92016778, 0.92153698, 0.92266609, 0.91168867, 0.92267341]), 'test_roc_auc': array([0.87726153, 0.86889676, 0.88253616, 0.84522923, 0.88018774])}\n",
            "cross for accuracy [0.92016778 0.92153698 0.92266609 0.91168867 0.92267341]\n",
            "cross for roc-auc [0.87726153 0.86889676 0.88253616 0.84522923 0.88018774]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Pfvps8ZPgE2",
        "outputId": "d50da2b9-f140-4d14-eb90-1fab70bfa97b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpLGBMClassifierModel():\n",
        "  model = LGBMClassifier(random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runexpLGBMClassifierModel()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [0 0 0 ... 1 0 0]\n",
            "Test ROC AUC score: 0.8943669585572716\n",
            "Test accuracy score: 0.9284967208007038\n",
            "Confusion matrix is  [[1265517   34419]\n",
            " [  95474  421192]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95   1299936\n",
            "           1       0.92      0.82      0.87    516666\n",
            "\n",
            "    accuracy                           0.93   1816602\n",
            "   macro avg       0.93      0.89      0.91   1816602\n",
            "weighted avg       0.93      0.93      0.93   1816602\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([43.73430777, 41.98292351, 41.80735707, 42.38198566, 42.39263821]), 'score_time': array([3.88832808, 3.48781157, 3.58263969, 3.47888708, 3.54605627]), 'test_accuracy': array([0.93007337, 0.93042243, 0.93062154, 0.93000284, 0.93055101]), 'test_roc_auc': array([0.89094871, 0.89133768, 0.89178791, 0.89073059, 0.89165437])}\n",
            "cross for accuracy [0.93007337 0.93042243 0.93062154 0.93000284 0.93055101]\n",
            "cross for roc-auc [0.89094871 0.89133768 0.89178791 0.89073059 0.89165437]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W-dq1z4DYbE7",
        "outputId": "bc01c1ca-2d9b-4826-cb7a-e6c10c1d9f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpDecisionTreeModel():\n",
        "  tree = DecisionTreeClassifier(random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  tree.fit(sel_X_train, Y_train)\n",
        "  pred=tree.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(tree,X,y)\n",
        "\n",
        "runexpDecisionTreeModel()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n",
            "predictions are  [0 1 0 ... 1 0 0]\n",
            "Test ROC AUC score: 0.8818802177296695\n",
            "Test accuracy score: 0.9010823504543097\n",
            "Confusion matrix is  [[1204280   95656]\n",
            " [  84038  432628]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93   1299936\n",
            "           1       0.82      0.84      0.83    516666\n",
            "\n",
            "    accuracy                           0.90   1816602\n",
            "   macro avg       0.88      0.88      0.88   1816602\n",
            "weighted avg       0.90      0.90      0.90   1816602\n",
            "\n",
            "\n",
            "\n",
            "Cross-validated scores: {'fit_time': array([160.80574751, 158.02251744, 153.97893667, 156.4491992 ,\n",
            "       155.75046134]), 'score_time': array([1.38939834, 1.21886802, 1.34569645, 1.2256155 , 1.27826953]), 'test_accuracy': array([0.90046312, 0.90090723, 0.9011088 , 0.90070558, 0.90124801]), 'test_roc_auc': array([0.88093669, 0.88146941, 0.88163455, 0.88098942, 0.88179091])}\n",
            "cross for accuracy [0.90046312 0.90090723 0.9011088  0.90070558 0.90124801]\n",
            "cross for roc-auc [0.88093669 0.88146941 0.88163455 0.88098942 0.88179091]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1T8qD_h5S9mU",
        "outputId": "df63693e-7343-4ea8-90e9-02f480264ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runexpRandomForestModel():\n",
        "  forest = RandomForestClassifier(max_features=16,max_depth=25,min_samples_leaf=10,random_state=10)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  forest.fit(sel_X_train, Y_train)\n",
        "  pred=forest.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)                                         #91.87\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(forest,X,y)\n",
        "\n",
        "runexpRandomForestModel()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n",
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-269c9f8e2f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mrunexpRandomForestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-269c9f8e2f87>\u001b[0m in \u001b[0;36mrunexpRandomForestModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0msel_X_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0msel_X_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msel_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msel_X_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictions are \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-269c9f8e2f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mrunexpRandomForestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-269c9f8e2f87>\u001b[0m in \u001b[0;36mrunexpRandomForestModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0msel_X_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0msel_X_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msel_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msel_X_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictions are \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-269c9f8e2f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mrunexpRandomForestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-269c9f8e2f87>\u001b[0m in \u001b[0;36mrunexpRandomForestModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0msel_X_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0msel_X_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msel_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msel_X_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictions are \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "guOphXVvu15j",
        "outputId": "b6095b5e-7499-4bab-c256-0fa748a3c3ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLogisticRegressionModel():\n",
        "  lrmodel=LogisticRegression()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  lrmodel.fit(sel_X_train, Y_train)\n",
        "  pred=lrmodel.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(lrmodel,X,y)\n",
        "  num_params = len(lrmodel.coef_) + 1\n",
        "  aic_and_bic(Y_test,pred,num_params)\n",
        "\n",
        "runLogisticRegressionModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [0 1 0 ... 0 0 1]\n",
            "Test ROC AUC score: 0.8296774206409845\n",
            "Test accuracy score: 0.8885107080764145\n",
            "Confusion matrix is  [[326571   9234]\n",
            " [ 43798  96066]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92    335805\n",
            "           1       0.91      0.69      0.78    139864\n",
            "\n",
            "    accuracy                           0.89    475669\n",
            "   macro avg       0.90      0.83      0.85    475669\n",
            "weighted avg       0.89      0.89      0.88    475669\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([67.50734687, 65.93810582, 66.96874094, 66.1269958 , 65.12360954]), 'score_time': array([0.41015744, 0.42351747, 0.41843605, 0.40717268, 0.41280127]), 'test_accuracy': array([0.8936544 , 0.89500911, 0.89364285, 0.89404716, 0.8939663 ]), 'test_roc_auc': array([0.82146836, 0.82712552, 0.82564117, 0.82180698, 0.82085378])}\n",
            "cross for accuracy [0.8936544  0.89500911 0.89364285 0.89404716 0.8939663 ]\n",
            "cross for roc-auc [0.82146836 0.82712552 0.82564117 0.82180698 0.82085378]\n",
            "[0 1 0 ... 0 0 1]\n",
            "Number of parameters: 2\n",
            "AIC: -13283217.569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c89c4cf15e04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0maic_and_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrunLogisticRegressionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-c89c4cf15e04>\u001b[0m in \u001b[0;36mrunLogisticRegressionModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mnum_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0maic_and_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mrunLogisticRegressionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-15c7f88bee80>\u001b[0m in \u001b[0;36maic_and_bic\u001b[0;34m(Y_test, pred, num_params)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0maic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalculate_aic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AIC: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mbic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BIC: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBxc3eE0YXL8",
        "colab_type": "code",
        "outputId": "d218e3c2-23c8-4191-ebb4-8aa7d7f8ee2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runXGBClassifierModel():\n",
        "  model=XGBClassifier()\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runXGBClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[12:14:03] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8799539221752859\n",
            "Test accuracy score: 0.9069905175944303\n",
            "Confusion matrix is  [[953982  55036]\n",
            " [ 77822 341595]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93   1009018\n",
            "           1       0.86      0.81      0.84    419417\n",
            "\n",
            "    accuracy                           0.91   1428435\n",
            "   macro avg       0.89      0.88      0.89   1428435\n",
            "weighted avg       0.91      0.91      0.91   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[13:00:04] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[13:33:07] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[14:06:18] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[14:39:28] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[15:12:40] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
            "Cross-validated scores: {'fit_time': array([1982.48600912, 1986.70746088, 1986.53589177, 1987.457937  ,\n",
            "       1982.43312955]), 'score_time': array([3.77771521, 3.85807991, 3.84304357, 3.85526156, 3.86914086]), 'test_accuracy': array([0.91359997, 0.91408205, 0.91418706, 0.91419406, 0.91461583]), 'test_roc_auc': array([0.8665095 , 0.86698104, 0.86721075, 0.86698055, 0.86812215])}\n",
            "cross for accuracy [0.91359997 0.91408205 0.91418706 0.91419406 0.91461583]\n",
            "cross for roc-auc [0.8665095  0.86698104 0.86721075 0.86698055 0.86812215]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VEX6VSX0SbJT",
        "outputId": "66a84ce7-4e5a-4fe6-ccb9-59c504d4e133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "source": [
        "import numpy as np\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(max_bin=175,num_leaves=150,lambda_l1=2,lambda_l2=2,max_depth=100)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8800385453476021\n",
            "Test accuracy score: 0.9190337677248177\n",
            "Confusion matrix is  [[983301  25717]\n",
            " [ 89938 329479]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94   1009018\n",
            "           1       0.93      0.79      0.85    419417\n",
            "\n",
            "    accuracy                           0.92   1428435\n",
            "   macro avg       0.92      0.88      0.90   1428435\n",
            "weighted avg       0.92      0.92      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([24.3630302 , 21.44919086, 23.55398035, 21.66500092, 21.79883909]), 'score_time': array([1.08807039, 1.12044597, 1.11795592, 1.10131145, 1.07081175]), 'test_accuracy': array([0.91874966, 0.91907598, 0.9190821 , 0.91961326, 0.91984778]), 'test_roc_auc': array([0.87857381, 0.87930443, 0.87920195, 0.87997243, 0.8802891 ])}\n",
            "cross for accuracy [0.91874966 0.91907598 0.9190821  0.91961326 0.91984778]\n",
            "cross for roc-auc [0.87857381 0.87930443 0.87920195 0.87997243 0.8802891 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E9wkWA2b1USV",
        "outputId": "6e045c9d-7708-4607-b0fb-51192a66533b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import numpy as np\n",
        "sel_cols=cols\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(max_bin=150,num_leaves=150,lambda_l1=5,lambda_l2=5,max_depth=90,bagging_fraction=0.8)#decrease bagging_fraction\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'AIR_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OQQEenwR-EHf",
        "outputId": "35397c99-7f64-4768-cbbf-5e8799677d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        }
      },
      "source": [
        "import numpy as np\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(learning_rate=0.2,max_bin=150,num_leaves=250,min_data_in_leaf=300,lambda_l1=4,lambda_l2=4,max_depth=80,bagging_fraction=0.7)#decrease bagging_fraction\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  model.fit(sel_X_train, Y_train)\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.8877440288649189\n",
            "Test accuracy score: 0.9240553472856657\n",
            "Confusion matrix is  [[984515  24503]\n",
            " [ 83979 335438]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95   1009018\n",
            "           1       0.93      0.80      0.86    419417\n",
            "\n",
            "    accuracy                           0.92   1428435\n",
            "   macro avg       0.93      0.89      0.90   1428435\n",
            "weighted avg       0.92      0.92      0.92   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([129.25216079, 130.30028796, 131.82165766, 130.97301698,\n",
            "       131.62712002]), 'score_time': array([9.29587865, 9.15999746, 9.16376209, 9.16367054, 9.23544073]), 'test_accuracy': array([0.92362282, 0.92385289, 0.92412941, 0.92457219, 0.92467632]), 'test_roc_auc': array([0.88671826, 0.88728062, 0.88735556, 0.88814275, 0.88833141])}\n",
            "cross for accuracy [0.92362282 0.92385289 0.92412941 0.92457219 0.92467632]\n",
            "cross for roc-auc [0.88671826 0.88728062 0.88735556 0.88814275 0.88833141]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ixe9qVM6_pj5",
        "outputId": "b46eb36d-7db1-411c-a57e-0868a0f73355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'max_bin':(125,150),#               #'learning_rate':(0.2,0.3),\n",
        "     'feature_fraction':(0.6,0.7),\n",
        "     'num_leaves':(250,300),#\n",
        "     'min_data_in_leaf':(300,400),\n",
        "     'lambda_l1':(1,2),#--6                    #'lambda_l2':(2,4,6),     #'max_depth':(60,80,90),\n",
        "     'bagging_fraction':(0.4,0.5)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=3,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  6.0min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed:  9.1min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 17.3min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 18.5min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 19.9min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 20.7min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 21.4min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 22.5min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 24.2min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 24.3min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 25.4min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 26.6min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 27.2min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 28.5min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 29.4min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 30.6min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 32.5min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 33.0min\n",
            "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed: 34.2min\n",
            "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed: 35.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed: 36.3min\n",
            "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed: 37.0min\n",
            "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed: 38.4min\n",
            "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed: 38.7min\n",
            "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed: 40.1min\n",
            "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed: 42.0min\n",
            "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed: 42.1min\n",
            "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed: 42.3min\n",
            "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 44.9min\n",
            "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed: 45.2min\n",
            "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed: 45.3min\n",
            "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed: 47.7min\n",
            "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed: 48.5min\n",
            "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed: 48.7min\n",
            "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed: 50.5min\n",
            "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed: 51.4min\n",
            "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed: 52.0min\n",
            "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed: 53.5min\n",
            "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed: 54.7min\n",
            "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed: 54.9min\n",
            "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed: 56.2min\n",
            "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed: 57.5min\n",
            "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed: 58.1min\n",
            "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed: 59.7min\n",
            "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed: 60.4min\n",
            "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed: 61.0min\n",
            "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed: 62.6min\n",
            "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed: 63.2min\n",
            "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed: 64.2min\n",
            "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed: 65.8min\n",
            "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed: 66.5min\n",
            "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed: 67.0min\n",
            "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed: 68.6min\n",
            "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed: 69.3min\n",
            "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed: 70.0min\n",
            "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed: 71.9min\n",
            "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed: 72.5min\n",
            "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed: 73.1min\n",
            "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed: 74.3min\n",
            "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed: 75.8min\n",
            "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed: 76.3min\n",
            "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed: 77.3min\n",
            "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed: 78.9min\n",
            "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed: 79.2min\n",
            "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed: 80.2min\n",
            "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed: 82.1min\n",
            "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed: 82.4min\n",
            "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed: 83.2min\n",
            "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed: 85.2min\n",
            "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed: 85.7min\n",
            "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed: 85.9min\n",
            "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed: 88.0min\n",
            "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed: 88.7min\n",
            "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed: 89.3min\n",
            "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed: 91.3min\n",
            "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed: 92.3min\n",
            "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed: 94.2min\n",
            "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed: 94.7min\n",
            "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed: 95.5min\n",
            "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed: 97.3min\n",
            "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed: 97.6min\n",
            "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed: 98.3min\n",
            "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed: 100.2min\n",
            "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed: 100.3min\n",
            "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed: 101.7min\n",
            "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed: 103.1min\n",
            "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed: 103.3min\n",
            "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed: 104.6min\n",
            "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed: 106.1min\n",
            "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed: 106.2min\n",
            "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed: 107.7min\n",
            "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed: 108.7min\n",
            "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed: 109.5min\n",
            "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed: 110.6min\n",
            "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed: 111.6min\n",
            "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed: 112.4min\n",
            "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed: 114.1min\n",
            "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed: 114.8min\n",
            "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed: 114.9min\n",
            "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed: 116.9min\n",
            "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed: 117.6min\n",
            "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed: 117.9min\n",
            "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed: 120.0min\n",
            "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed: 120.7min\n",
            "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed: 120.9min\n",
            "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed: 122.5min\n",
            "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed: 123.8min\n",
            "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed: 123.9min\n",
            "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed: 125.4min\n",
            "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed: 126.7min\n",
            "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed: 127.1min\n",
            "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed: 127.9min\n",
            "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed: 129.5min\n",
            "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed: 130.1min\n",
            "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed: 131.0min\n",
            "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed: 132.7min\n",
            "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed: 132.8min\n",
            "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed: 133.5min\n",
            "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed: 135.6min\n",
            "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed: 136.0min\n",
            "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed: 136.8min\n",
            "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed: 139.2min\n",
            "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed: 141.7min\n",
            "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed: 142.0min\n",
            "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed: 142.2min\n",
            "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed: 145.3min\n",
            "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed: 147.5min\n",
            "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed: 148.2min\n",
            "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed: 148.8min\n",
            "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed: 150.8min\n",
            "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed: 151.2min\n",
            "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed: 151.6min\n",
            "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed: 153.7min\n",
            "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed: 154.1min\n",
            "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed: 155.1min\n",
            "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 156.8min\n",
            "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed: 156.9min\n",
            "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed: 158.3min\n",
            "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed: 159.7min\n",
            "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed: 159.9min\n",
            "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed: 161.6min\n",
            "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed: 162.8min\n",
            "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed: 163.0min\n",
            "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed: 164.7min\n",
            "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed: 165.7min\n",
            "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed: 166.1min\n",
            "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed: 168.0min\n",
            "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed: 168.9min\n",
            "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed: 169.4min\n",
            "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed: 170.8min\n",
            "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed: 171.8min\n",
            "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed: 172.5min\n",
            "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed: 174.2min\n",
            "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed: 177.0min\n",
            "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed: 177.8min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  6.0min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed:  9.1min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 17.3min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 18.5min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 19.9min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 20.7min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 21.4min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 22.5min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 24.2min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 24.3min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 25.4min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 26.6min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 27.2min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 28.5min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 29.4min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 30.6min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 32.5min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 33.0min\n",
            "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed: 34.2min\n",
            "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed: 35.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed: 36.3min\n",
            "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed: 37.0min\n",
            "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed: 38.4min\n",
            "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed: 38.7min\n",
            "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed: 40.1min\n",
            "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed: 42.0min\n",
            "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed: 42.1min\n",
            "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed: 42.3min\n",
            "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 44.9min\n",
            "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed: 45.2min\n",
            "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed: 45.3min\n",
            "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed: 47.7min\n",
            "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed: 48.5min\n",
            "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed: 48.7min\n",
            "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed: 50.5min\n",
            "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed: 51.4min\n",
            "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed: 52.0min\n",
            "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed: 53.5min\n",
            "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed: 54.7min\n",
            "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed: 54.9min\n",
            "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed: 56.2min\n",
            "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed: 57.5min\n",
            "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed: 58.1min\n",
            "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed: 59.7min\n",
            "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed: 60.4min\n",
            "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed: 61.0min\n",
            "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed: 62.6min\n",
            "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed: 63.2min\n",
            "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed: 64.2min\n",
            "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed: 65.8min\n",
            "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed: 66.5min\n",
            "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed: 67.0min\n",
            "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed: 68.6min\n",
            "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed: 69.3min\n",
            "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed: 70.0min\n",
            "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed: 71.9min\n",
            "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed: 72.5min\n",
            "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed: 73.1min\n",
            "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed: 74.3min\n",
            "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed: 75.8min\n",
            "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed: 76.3min\n",
            "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed: 77.3min\n",
            "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed: 78.9min\n",
            "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed: 79.2min\n",
            "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed: 80.2min\n",
            "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed: 82.1min\n",
            "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed: 82.4min\n",
            "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed: 83.2min\n",
            "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed: 85.2min\n",
            "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed: 85.7min\n",
            "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed: 85.9min\n",
            "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed: 88.0min\n",
            "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed: 88.7min\n",
            "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed: 89.3min\n",
            "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed: 91.3min\n",
            "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed: 92.3min\n",
            "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed: 94.2min\n",
            "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed: 94.7min\n",
            "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed: 95.5min\n",
            "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed: 97.3min\n",
            "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed: 97.6min\n",
            "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed: 98.3min\n",
            "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed: 100.2min\n",
            "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed: 100.3min\n",
            "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed: 101.7min\n",
            "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed: 103.1min\n",
            "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed: 103.3min\n",
            "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed: 104.6min\n",
            "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed: 106.1min\n",
            "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed: 106.2min\n",
            "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed: 107.7min\n",
            "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed: 108.7min\n",
            "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed: 109.5min\n",
            "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed: 110.6min\n",
            "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed: 111.6min\n",
            "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed: 112.4min\n",
            "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed: 114.1min\n",
            "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed: 114.8min\n",
            "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed: 114.9min\n",
            "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed: 116.9min\n",
            "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed: 117.6min\n",
            "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed: 117.9min\n",
            "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed: 120.0min\n",
            "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed: 120.7min\n",
            "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed: 120.9min\n",
            "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed: 122.5min\n",
            "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed: 123.8min\n",
            "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed: 123.9min\n",
            "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed: 125.4min\n",
            "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed: 126.7min\n",
            "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed: 127.1min\n",
            "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed: 127.9min\n",
            "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed: 129.5min\n",
            "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed: 130.1min\n",
            "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed: 131.0min\n",
            "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed: 132.7min\n",
            "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed: 132.8min\n",
            "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed: 133.5min\n",
            "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed: 135.6min\n",
            "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed: 136.0min\n",
            "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed: 136.8min\n",
            "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed: 138.9min\n",
            "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed: 139.2min\n",
            "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed: 141.7min\n",
            "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed: 142.0min\n",
            "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed: 142.2min\n",
            "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed: 145.3min\n",
            "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed: 147.5min\n",
            "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed: 148.2min\n",
            "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed: 148.8min\n",
            "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed: 150.8min\n",
            "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed: 151.2min\n",
            "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed: 151.6min\n",
            "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed: 153.7min\n",
            "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed: 154.1min\n",
            "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed: 155.1min\n",
            "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 156.8min\n",
            "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed: 156.9min\n",
            "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed: 158.3min\n",
            "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed: 159.7min\n",
            "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed: 159.9min\n",
            "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed: 161.6min\n",
            "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed: 162.8min\n",
            "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed: 163.0min\n",
            "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed: 164.7min\n",
            "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed: 165.7min\n",
            "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed: 166.1min\n",
            "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed: 168.0min\n",
            "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed: 168.9min\n",
            "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed: 169.4min\n",
            "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed: 170.8min\n",
            "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed: 171.8min\n",
            "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed: 172.5min\n",
            "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed: 174.2min\n",
            "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed: 175.1min\n",
            "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed: 177.0min\n",
            "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed: 177.8min\n",
            "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed: 178.6min\n",
            "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed: 178.6min\n",
            "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed: 180.3min\n",
            "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed: 180.3min\n",
            "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed: 181.1min\n",
            "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed: 181.1min\n",
            "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed: 181.4min\n",
            "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed: 181.4min\n",
            "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed: 183.1min\n",
            "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed: 183.1min\n",
            "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed: 184.1min\n",
            "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed: 184.1min\n",
            "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed: 184.5min\n",
            "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed: 184.5min\n",
            "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed: 186.1min\n",
            "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed: 186.1min\n",
            "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed: 187.2min\n",
            "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed: 187.2min\n",
            "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed: 187.5min\n",
            "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed: 187.5min\n",
            "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed: 189.1min\n",
            "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed: 189.1min\n",
            "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed: 190.1min\n",
            "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed: 190.1min\n",
            "[Parallel(n_jobs=3)]: Done 192 out of 192 | elapsed: 192.8min finished\n",
            "[Parallel(n_jobs=3)]: Done 192 out of 192 | elapsed: 192.8min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split',\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=90,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_state=None, reg_...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'bagging_fraction': (0.5, 0.6),\n",
            "                         'feature_fraction': (0.5, 0.6), 'lambda_l1': (2, 4),\n",
            "                         'max_bin': (100, 125), 'min_data_in_leaf': (200, 300),\n",
            "                         'num_leaves': (150, 250)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9267652722511871\n",
            "{'bagging_fraction': 0.5, 'feature_fraction': 0.6, 'lambda_l1': 2, 'max_bin': 125, 'min_data_in_leaf': 300, 'num_leaves': 250}\n",
            "LGBMClassifier(bagging_fraction=0.5, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.6,\n",
            "               importance_type='split', lambda_l1=2, learning_rate=0.1,\n",
            "               max_bin=125, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=300, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=90, num_leaves=250,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n",
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split',\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=90,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_state=None, reg_...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'bagging_fraction': (0.5, 0.6),\n",
            "                         'feature_fraction': (0.5, 0.6), 'lambda_l1': (2, 4),\n",
            "                         'max_bin': (100, 125), 'min_data_in_leaf': (200, 300),\n",
            "                         'num_leaves': (150, 250)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9267652722511871\n",
            "{'bagging_fraction': 0.5, 'feature_fraction': 0.6, 'lambda_l1': 2, 'max_bin': 125, 'min_data_in_leaf': 300, 'num_leaves': 250}\n",
            "LGBMClassifier(bagging_fraction=0.5, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.6,\n",
            "               importance_type='split', lambda_l1=2, learning_rate=0.1,\n",
            "               max_bin=125, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=300, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=90, num_leaves=250,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "52sUc9Uswc1x",
        "outputId": "7dfa9c3b-227e-437f-fe7a-d88372d8a4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'max_bin':(100,125),#               #'learning_rate':(0.2,0.3),\n",
        "     'feature_fraction':(0.7,0.8),\n",
        "     'num_leaves':(300,350),#\n",
        "     'min_data_in_leaf':(300),\n",
        "     'lambda_l1':(1),#                    #'lambda_l2':(2,4,6),     #'max_depth':(60,80,90),\n",
        "     'bagging_fraction':(0.3,0.4)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=3,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  7.0min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  7.3min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed: 10.3min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed: 10.9min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 13.8min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 13.9min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 14.6min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 17.0min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 17.2min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 18.2min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 20.4min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 20.9min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 21.9min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 23.5min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 24.5min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 25.2min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 26.9min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 27.8min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 29.1min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 30.4min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 32.5min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 33.5min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 34.5min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 36.2min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 36.7min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 37.8min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 39.6min\n",
            "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed: 39.8min\n",
            "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed: 41.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed: 43.1min\n",
            "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed: 43.2min\n",
            "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed: 44.4min\n",
            "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed: 46.1min\n",
            "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed: 46.7min\n",
            "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed: 48.2min\n",
            "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed: 49.6min\n",
            "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed: 49.7min\n",
            "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 51.6min\n",
            "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed: 53.0min\n",
            "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed: 53.0min\n",
            "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed: 55.0min\n",
            "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed: 56.0min\n",
            "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed: 56.6min\n",
            "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed: 58.7min\n",
            "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed: 59.6min\n",
            "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed: 60.1min\n",
            "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed: 62.7min\n",
            "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed: 62.9min\n",
            "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed: 63.6min\n",
            "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed: 66.1min\n",
            "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed: 66.4min\n",
            "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed: 67.2min\n",
            "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed: 69.8min\n",
            "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed: 70.3min\n",
            "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed: 70.5min\n",
            "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed: 73.2min\n",
            "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed: 74.1min\n",
            "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed: 74.2min\n",
            "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed: 76.9min\n",
            "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed: 77.7min\n",
            "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed: 77.8min\n",
            "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed: 80.7min\n",
            "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed: 81.0min\n",
            "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed: 81.4min\n",
            "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed: 84.1min\n",
            "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed: 84.8min\n",
            "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed: 84.9min\n",
            "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed: 87.8min\n",
            "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed: 88.4min\n",
            "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed: 88.4min\n",
            "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed: 91.6min\n",
            "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed: 92.1min\n",
            "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed: 95.0min\n",
            "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed: 95.2min\n",
            "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed: 95.9min\n",
            "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed: 98.8min\n",
            "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed: 99.0min\n",
            "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed: 99.1min\n",
            "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed: 101.9min\n",
            "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed: 102.9min\n",
            "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed: 102.9min\n",
            "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed: 105.4min\n",
            "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed: 106.4min\n",
            "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed: 106.8min\n",
            "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed: 108.6min\n",
            "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed: 110.0min\n",
            "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed: 110.4min\n",
            "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed: 112.4min\n",
            "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed: 113.3min\n",
            "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed: 114.0min\n",
            "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed: 116.0min\n",
            "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed: 116.6min\n",
            "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed: 117.3min\n",
            "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed: 119.8min\n",
            "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed: 120.2min\n",
            "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed: 120.7min\n",
            "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed: 123.3min\n",
            "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed: 123.7min\n",
            "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed: 124.0min\n",
            "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed: 127.0min\n",
            "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed: 127.2min\n",
            "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed: 127.3min\n",
            "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed: 130.6min\n",
            "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed: 130.7min\n",
            "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed: 130.7min\n",
            "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed: 133.7min\n",
            "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed: 134.3min\n",
            "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed: 134.4min\n",
            "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed: 137.1min\n",
            "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed: 137.7min\n",
            "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed: 138.1min\n",
            "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed: 140.6min\n",
            "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed: 141.1min\n",
            "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed: 141.6min\n",
            "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed: 143.9min\n",
            "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed: 144.7min\n",
            "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed: 144.9min\n",
            "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed: 147.1min\n",
            "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed: 148.3min\n",
            "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed: 148.5min\n",
            "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed: 150.6min\n",
            "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed: 151.8min\n",
            "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed: 152.1min\n",
            "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed: 154.0min\n",
            "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed: 155.4min\n",
            "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed: 155.7min\n",
            "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed: 157.4min\n",
            "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed: 158.6min\n",
            "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed: 159.3min\n",
            "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed: 160.8min\n",
            "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed: 162.2min\n",
            "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed: 162.7min\n",
            "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed: 164.2min\n",
            "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed: 165.5min\n",
            "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed: 166.0min\n",
            "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed: 168.0min\n",
            "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed: 169.1min\n",
            "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed: 169.3min\n",
            "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed: 171.4min\n",
            "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed: 172.8min\n",
            "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed: 172.9min\n",
            "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed: 175.2min\n",
            "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed: 176.4min\n",
            "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed: 176.5min\n",
            "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed: 178.7min\n",
            "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed: 179.8min\n",
            "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed: 180.1min\n",
            "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed: 182.3min\n",
            "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 183.5min\n",
            "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed: 183.7min\n",
            "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed: 185.8min\n",
            "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed: 187.2min\n",
            "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed: 187.3min\n",
            "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed: 189.6min\n",
            "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed: 190.5min\n",
            "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed: 191.1min\n",
            "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed: 192.9min\n",
            "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed: 194.2min\n",
            "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed: 194.6min\n",
            "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed: 196.8min\n",
            "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed: 197.6min\n",
            "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed: 198.0min\n",
            "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed: 200.2min\n",
            "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed: 201.1min\n",
            "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed: 201.7min\n",
            "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed: 203.9min\n",
            "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed: 204.6min\n",
            "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed: 205.2min\n",
            "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed: 207.5min\n",
            "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed: 207.9min\n",
            "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed: 208.8min\n",
            "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed: 211.4min\n",
            "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed: 212.0min\n",
            "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed: 212.0min\n",
            "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed: 215.0min\n",
            "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed: 215.6min\n",
            "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed: 215.7min\n",
            "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed: 218.4min\n",
            "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed: 219.1min\n",
            "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed: 219.3min\n",
            "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed: 222.1min\n",
            "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed: 222.6min\n",
            "[Parallel(n_jobs=3)]: Done 192 out of 192 | elapsed: 225.7min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      importance_type='split',\n",
            "                                      learning_rate=0.1, max_depth=-1,\n",
            "                                      min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_split_gain=0.0, n_estimators=100,\n",
            "                                      n_jobs=-1, num_iterations=90,\n",
            "                                      num_leaves=31, objective=None,\n",
            "                                      random_state=None, reg_...\n",
            "                                      reg_lambda=0.0, silent=True,\n",
            "                                      subsample=1.0, subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'bagging_fraction': (0.4, 0.5),\n",
            "                         'feature_fraction': (0.6, 0.7), 'lambda_l1': (1, 2),\n",
            "                         'max_bin': (125, 150), 'min_data_in_leaf': (300, 400),\n",
            "                         'num_leaves': (250, 300)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9272417521074825\n",
            "{'bagging_fraction': 0.4, 'feature_fraction': 0.7, 'lambda_l1': 1, 'max_bin': 125, 'min_data_in_leaf': 300, 'num_leaves': 300}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, learning_rate=0.1,\n",
            "               max_bin=125, max_depth=-1, min_child_samples=20,\n",
            "               min_child_weight=0.001, min_data_in_leaf=300, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_iterations=90, num_leaves=300,\n",
            "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d1qmccME6gNU",
        "outputId": "7059376d-383a-43b4-863a-17fc988b5119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'learning_rate':(0.2,0.3),\n",
        "     'lambda_l2':(2,4),     \n",
        "     'max_depth':(60,80,90)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=3,refit=\"accuracy\",pre_dispatch=4,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=1,max_bin=125,min_data_in_leaf=300,num_leaves=300)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:  6.7min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:  7.2min\n",
            "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed: 11.0min\n",
            "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed: 11.1min\n",
            "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed: 14.0min\n",
            "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed: 14.0min\n",
            "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 14.7min\n",
            "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed: 17.1min\n",
            "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed: 17.5min\n",
            "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed: 18.3min\n",
            "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed: 20.5min\n",
            "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed: 20.9min\n",
            "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed: 22.1min\n",
            "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 23.8min\n",
            "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed: 24.6min\n",
            "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed: 25.8min\n",
            "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed: 27.4min\n",
            "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed: 28.2min\n",
            "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed: 29.6min\n",
            "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed: 30.8min\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 32.3min\n",
            "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed: 33.1min\n",
            "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed: 34.0min\n",
            "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed: 35.9min\n",
            "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed: 36.7min\n",
            "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed: 37.3min\n",
            "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed: 39.3min\n",
            "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed: 40.3min\n",
            "[Parallel(n_jobs=3)]: Done  36 out of  36 | elapsed: 43.2min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.4,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      feature_fraction=0.7,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_bin=125,\n",
            "                                      max_depth=-1, min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=300, min_split_gain=0.0,\n",
            "                                      n_estimat...\n",
            "                                      num_iterations=90, num_leaves=300,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=3,\n",
            "             param_grid={'lambda_l2': (2, 4), 'learning_rate': (0.2, 0.3),\n",
            "                         'max_depth': (60, 80, 90)},\n",
            "             pre_dispatch=4, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9319399935584403\n",
            "{'lambda_l2': 4, 'learning_rate': 0.3, 'max_depth': 60}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=4,\n",
            "               learning_rate=0.3, max_bin=125, max_depth=60,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=300, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=300, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YwFiAmL4JZDO",
        "outputId": "1aac075a-8258-4c64-c232-55266ebeb34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'learning_rate':(0.4,0.5),\n",
        "     'lambda_l2':(6,8),     \n",
        "     'max_depth':(40,50)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=4,refit=\"accuracy\",pre_dispatch=5,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=1,max_bin=125,min_data_in_leaf=300,num_leaves=300)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  7.9min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:  8.1min\n",
            "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed: 11.7min\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed: 11.9min\n",
            "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed: 12.0min\n",
            "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed: 15.7min\n",
            "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed: 15.9min\n",
            "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed: 16.0min\n",
            "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed: 16.0min\n",
            "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed: 19.6min\n",
            "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed: 19.7min\n",
            "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed: 19.9min\n",
            "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed: 20.1min\n",
            "[Parallel(n_jobs=4)]: Done  21 out of  24 | elapsed: 23.6min remaining:  3.4min\n",
            "[Parallel(n_jobs=4)]: Done  22 out of  24 | elapsed: 23.7min remaining:  2.2min\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 24.0min finished\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 24.0min remaining:    0.0s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.4,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      feature_fraction=0.7,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_bin=125,\n",
            "                                      max_depth=-1, min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=300, min_split_gain=0.0,\n",
            "                                      n_estimat...\n",
            "                                      num_iterations=90, num_leaves=300,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=4,\n",
            "             param_grid={'lambda_l2': (4, 6), 'learning_rate': (0.3, 0.4),\n",
            "                         'max_depth': (50, 60)},\n",
            "             pre_dispatch=5, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9330757831179838\n",
            "{'lambda_l2': 6, 'learning_rate': 0.4, 'max_depth': 50}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=6,\n",
            "               learning_rate=0.4, max_bin=125, max_depth=50,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=300, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=300, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZdlHThqYTZSQ",
        "outputId": "fbf31d0c-2636-4028-a7b8-174f914e6c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "indices=np.array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 34])\n",
        "sel_cols=X_train.columns[indices]\n",
        "print(sel_cols)\n",
        "\n",
        "sel_X_train=X_train[sel_cols]\n",
        "sel_X_test=X_test[sel_cols]\n",
        "                                                              #right refers to that the rightmost is most optimal in the row and used in previous high score\n",
        "def hyperparameterOptimization(model):\n",
        "  param_grid = {\n",
        "     'learning_rate':(0.4,0.5),\n",
        "     'lambda_l2':(6,8),     \n",
        "     'max_depth':(40,50)\n",
        "  }\n",
        "  grid = GridSearchCV(model,param_grid ,cv=3, scoring=['accuracy','roc_auc'],n_jobs=4,refit=\"accuracy\",pre_dispatch=5,verbose=30)\n",
        "  grid.fit(sel_X_train,Y_train)\n",
        "  print(grid)\n",
        "\n",
        "  print(grid.best_score_)\n",
        "  print(grid.best_params_)\n",
        "  print(grid.best_estimator_)\n",
        "model=LGBMClassifier(extra_trees=True,num_iterations=90,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=1,max_bin=125,min_data_in_leaf=300,num_leaves=300)\n",
        "hyperparameterOptimization(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['MONTH', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
            "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
            "       'WHEELS_OFF', 'SCHEDULED_ARRIVAL', 'AIR_TIME', 'AIR_SYSTEM_DELAY',\n",
            "       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
            "       'WEATHER_DELAY', 'AIRLINE_ORIGIN_AIRPORT',\n",
            "       'AIRLINE_DESTINATION_AIRPORT', '1', '2', '3', '4', '5', '7', '8', '13'],\n",
            "      dtype='object')\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  7.7min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed: 11.5min\n",
            "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed: 11.7min\n",
            "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed: 15.2min\n",
            "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed: 15.5min\n",
            "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed: 15.5min\n",
            "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed: 15.6min\n",
            "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed: 19.2min\n",
            "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed: 19.3min\n",
            "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed: 19.5min\n",
            "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed: 19.5min\n",
            "[Parallel(n_jobs=4)]: Done  21 out of  24 | elapsed: 23.1min remaining:  3.3min\n",
            "[Parallel(n_jobs=4)]: Done  22 out of  24 | elapsed: 23.2min remaining:  2.1min\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 23.4min remaining:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 23.4min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=LGBMClassifier(bagging_fraction=0.4,\n",
            "                                      boosting_type='gbdt', class_weight=None,\n",
            "                                      colsample_bytree=1.0, extra_trees=True,\n",
            "                                      feature_fraction=0.7,\n",
            "                                      importance_type='split', lambda_l1=1,\n",
            "                                      learning_rate=0.1, max_bin=125,\n",
            "                                      max_depth=-1, min_child_samples=20,\n",
            "                                      min_child_weight=0.001,\n",
            "                                      min_data_in_leaf=300, min_split_gain=0.0,\n",
            "                                      n_estimat...\n",
            "                                      num_iterations=90, num_leaves=300,\n",
            "                                      objective=None, random_state=None,\n",
            "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
            "                                      silent=True, subsample=1.0,\n",
            "                                      subsample_for_bin=200000,\n",
            "                                      subsample_freq=0),\n",
            "             iid='deprecated', n_jobs=4,\n",
            "             param_grid={'lambda_l2': (6, 8), 'learning_rate': (0.4, 0.5),\n",
            "                         'max_depth': (40, 50)},\n",
            "             pre_dispatch=5, refit='accuracy', return_train_score=False,\n",
            "             scoring=['accuracy', 'roc_auc'], verbose=30)\n",
            "0.9337819973503855\n",
            "{'lambda_l2': 8, 'learning_rate': 0.5, 'max_depth': 40}\n",
            "LGBMClassifier(bagging_fraction=0.4, boosting_type='gbdt', class_weight=None,\n",
            "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.7,\n",
            "               importance_type='split', lambda_l1=1, lambda_l2=8,\n",
            "               learning_rate=0.5, max_bin=125, max_depth=40,\n",
            "               min_child_samples=20, min_child_weight=0.001,\n",
            "               min_data_in_leaf=300, min_split_gain=0.0, n_estimators=100,\n",
            "               n_jobs=-1, num_iterations=90, num_leaves=300, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cEBGv0t5Iixl",
        "outputId": "de06cb2a-7e47-4f22-ae8a-2027597f9abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sel_cols=cols\n",
        "print(sel_cols,Y_train.OUTCOME.mean(),Y_test.OUTCOME.mean())\n",
        "\n",
        "def runLGBMClassifierModel():\n",
        "  model=LGBMClassifier(extra_trees=True,num_iterations=100,bagging_fraction=0.4,feature_fraction=0.7,lambda_l1=3,max_bin=125,min_data_in_leaf=300,num_leaves=300,lambda_l2=8,learning_rate=0.2,max_depth=40)\n",
        "  sel_X_train=X_train[sel_cols]\n",
        "  sel_X_test=X_test[sel_cols]\n",
        "  sel_X_valid=X_valid[sel_cols]\n",
        "  eval_set = [(sel_X_test, Y_test)]\n",
        "  model.fit(sel_X_train, Y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
        "\n",
        "  print(\"Test dataset:\")\n",
        "  pred=model.predict(sel_X_test)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_test,pred)\n",
        "\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(\"Validation dataset:\")\n",
        "  pred=model.predict(sel_X_valid)\n",
        "  print(\"predictions are \",pred)\n",
        "  report(Y_valid,pred)\n",
        "\n",
        "  \n",
        "  print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "  #plot graph of feature importances for better visualization\n",
        "  feat_importances = pd.Series(model.feature_importances_, index=sel_cols)\n",
        "  feat_importances.nlargest(26).plot(kind='barh')\n",
        "  plt.show()\n",
        "\n",
        "  X=pd.concat([sel_X_train[:4285506],sel_X_test,sel_X_valid])\n",
        "  y=pd.concat([Y_train[:4285506],Y_test,Y_valid])\n",
        "  cross_validation(model,X,y)\n",
        "\n",
        "runLGBMClassifierModel()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MONTH', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'TAXI_OUT', 'DISTANCE', 'SCHEDULED_TIME', 'AIR_SYSTEM_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'AIRLINE_ORIGIN_AIRPORT', 'AIRLINE_DESTINATION_AIRPORT', 'DEPARTURE_TIME_HOUR', 'SCHEDULED_DEPARTURE_HOUR', 'SCHEDULED_ARRIVAL_HOUR', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MINUTE', 'AIR_SYSTEM_DELAY_is_missing', 'SECURITY_DELAY_is_missing', 'AIRLINE_DELAY_is_missing', 'LATE_AIRCRAFT_DELAY_is_missing', 'WEATHER_DELAY_is_missing'] 0.5 0.28402341431804395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.564089\tvalid_0's binary_logloss: 0.564089\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.477696\tvalid_0's binary_logloss: 0.477696\n",
            "[3]\tvalid_0's binary_logloss: 0.416326\tvalid_0's binary_logloss: 0.416326\n",
            "[4]\tvalid_0's binary_logloss: 0.370314\tvalid_0's binary_logloss: 0.370314\n",
            "[5]\tvalid_0's binary_logloss: 0.330874\tvalid_0's binary_logloss: 0.330874\n",
            "[6]\tvalid_0's binary_logloss: 0.305183\tvalid_0's binary_logloss: 0.305183\n",
            "[7]\tvalid_0's binary_logloss: 0.281462\tvalid_0's binary_logloss: 0.281462\n",
            "[8]\tvalid_0's binary_logloss: 0.267687\tvalid_0's binary_logloss: 0.267687\n",
            "[9]\tvalid_0's binary_logloss: 0.252254\tvalid_0's binary_logloss: 0.252254\n",
            "[10]\tvalid_0's binary_logloss: 0.240314\tvalid_0's binary_logloss: 0.240314\n",
            "[11]\tvalid_0's binary_logloss: 0.230897\tvalid_0's binary_logloss: 0.230897\n",
            "[12]\tvalid_0's binary_logloss: 0.223842\tvalid_0's binary_logloss: 0.223842\n",
            "[13]\tvalid_0's binary_logloss: 0.218212\tvalid_0's binary_logloss: 0.218212\n",
            "[14]\tvalid_0's binary_logloss: 0.214029\tvalid_0's binary_logloss: 0.214029\n",
            "[15]\tvalid_0's binary_logloss: 0.210581\tvalid_0's binary_logloss: 0.210581\n",
            "[16]\tvalid_0's binary_logloss: 0.207656\tvalid_0's binary_logloss: 0.207656\n",
            "[17]\tvalid_0's binary_logloss: 0.205164\tvalid_0's binary_logloss: 0.205164\n",
            "[18]\tvalid_0's binary_logloss: 0.20316\tvalid_0's binary_logloss: 0.20316\n",
            "[19]\tvalid_0's binary_logloss: 0.201575\tvalid_0's binary_logloss: 0.201575\n",
            "[20]\tvalid_0's binary_logloss: 0.200233\tvalid_0's binary_logloss: 0.200233\n",
            "[21]\tvalid_0's binary_logloss: 0.1991\tvalid_0's binary_logloss: 0.1991\n",
            "[22]\tvalid_0's binary_logloss: 0.198267\tvalid_0's binary_logloss: 0.198267\n",
            "[23]\tvalid_0's binary_logloss: 0.196695\tvalid_0's binary_logloss: 0.196695\n",
            "[24]\tvalid_0's binary_logloss: 0.195661\tvalid_0's binary_logloss: 0.195661\n",
            "[25]\tvalid_0's binary_logloss: 0.194948\tvalid_0's binary_logloss: 0.194948\n",
            "[26]\tvalid_0's binary_logloss: 0.19385\tvalid_0's binary_logloss: 0.19385\n",
            "[27]\tvalid_0's binary_logloss: 0.192804\tvalid_0's binary_logloss: 0.192804\n",
            "[28]\tvalid_0's binary_logloss: 0.192126\tvalid_0's binary_logloss: 0.192126\n",
            "[29]\tvalid_0's binary_logloss: 0.191347\tvalid_0's binary_logloss: 0.191347\n",
            "[30]\tvalid_0's binary_logloss: 0.190826\tvalid_0's binary_logloss: 0.190826\n",
            "[31]\tvalid_0's binary_logloss: 0.190298\tvalid_0's binary_logloss: 0.190298\n",
            "[32]\tvalid_0's binary_logloss: 0.189833\tvalid_0's binary_logloss: 0.189833\n",
            "[33]\tvalid_0's binary_logloss: 0.189371\tvalid_0's binary_logloss: 0.189371\n",
            "[34]\tvalid_0's binary_logloss: 0.188773\tvalid_0's binary_logloss: 0.188773\n",
            "[35]\tvalid_0's binary_logloss: 0.188306\tvalid_0's binary_logloss: 0.188306\n",
            "[36]\tvalid_0's binary_logloss: 0.188005\tvalid_0's binary_logloss: 0.188005\n",
            "[37]\tvalid_0's binary_logloss: 0.187746\tvalid_0's binary_logloss: 0.187746\n",
            "[38]\tvalid_0's binary_logloss: 0.187439\tvalid_0's binary_logloss: 0.187439\n",
            "[39]\tvalid_0's binary_logloss: 0.187131\tvalid_0's binary_logloss: 0.187131\n",
            "[40]\tvalid_0's binary_logloss: 0.186899\tvalid_0's binary_logloss: 0.186899\n",
            "[41]\tvalid_0's binary_logloss: 0.186685\tvalid_0's binary_logloss: 0.186685\n",
            "[42]\tvalid_0's binary_logloss: 0.186285\tvalid_0's binary_logloss: 0.186285\n",
            "[43]\tvalid_0's binary_logloss: 0.185949\tvalid_0's binary_logloss: 0.185949\n",
            "[44]\tvalid_0's binary_logloss: 0.185566\tvalid_0's binary_logloss: 0.185566\n",
            "[45]\tvalid_0's binary_logloss: 0.185285\tvalid_0's binary_logloss: 0.185285\n",
            "[46]\tvalid_0's binary_logloss: 0.185091\tvalid_0's binary_logloss: 0.185091\n",
            "[47]\tvalid_0's binary_logloss: 0.184866\tvalid_0's binary_logloss: 0.184866\n",
            "[48]\tvalid_0's binary_logloss: 0.184599\tvalid_0's binary_logloss: 0.184599\n",
            "[49]\tvalid_0's binary_logloss: 0.184359\tvalid_0's binary_logloss: 0.184359\n",
            "[50]\tvalid_0's binary_logloss: 0.184151\tvalid_0's binary_logloss: 0.184151\n",
            "[51]\tvalid_0's binary_logloss: 0.184003\tvalid_0's binary_logloss: 0.184003\n",
            "[52]\tvalid_0's binary_logloss: 0.183883\tvalid_0's binary_logloss: 0.183883\n",
            "[53]\tvalid_0's binary_logloss: 0.183735\tvalid_0's binary_logloss: 0.183735\n",
            "[54]\tvalid_0's binary_logloss: 0.183485\tvalid_0's binary_logloss: 0.183485\n",
            "[55]\tvalid_0's binary_logloss: 0.183348\tvalid_0's binary_logloss: 0.183348\n",
            "[56]\tvalid_0's binary_logloss: 0.183203\tvalid_0's binary_logloss: 0.183203\n",
            "[57]\tvalid_0's binary_logloss: 0.183012\tvalid_0's binary_logloss: 0.183012\n",
            "[58]\tvalid_0's binary_logloss: 0.182837\tvalid_0's binary_logloss: 0.182837\n",
            "[59]\tvalid_0's binary_logloss: 0.182656\tvalid_0's binary_logloss: 0.182656\n",
            "[60]\tvalid_0's binary_logloss: 0.182527\tvalid_0's binary_logloss: 0.182527\n",
            "[61]\tvalid_0's binary_logloss: 0.18233\tvalid_0's binary_logloss: 0.18233\n",
            "[62]\tvalid_0's binary_logloss: 0.182202\tvalid_0's binary_logloss: 0.182202\n",
            "[63]\tvalid_0's binary_logloss: 0.182017\tvalid_0's binary_logloss: 0.182017\n",
            "[64]\tvalid_0's binary_logloss: 0.181854\tvalid_0's binary_logloss: 0.181854\n",
            "[65]\tvalid_0's binary_logloss: 0.181694\tvalid_0's binary_logloss: 0.181694\n",
            "[66]\tvalid_0's binary_logloss: 0.181548\tvalid_0's binary_logloss: 0.181548\n",
            "[67]\tvalid_0's binary_logloss: 0.18144\tvalid_0's binary_logloss: 0.18144\n",
            "[68]\tvalid_0's binary_logloss: 0.181344\tvalid_0's binary_logloss: 0.181344\n",
            "[69]\tvalid_0's binary_logloss: 0.18121\tvalid_0's binary_logloss: 0.18121\n",
            "[70]\tvalid_0's binary_logloss: 0.181048\tvalid_0's binary_logloss: 0.181048\n",
            "[71]\tvalid_0's binary_logloss: 0.180952\tvalid_0's binary_logloss: 0.180952\n",
            "[72]\tvalid_0's binary_logloss: 0.180878\tvalid_0's binary_logloss: 0.180878\n",
            "[73]\tvalid_0's binary_logloss: 0.180764\tvalid_0's binary_logloss: 0.180764\n",
            "[74]\tvalid_0's binary_logloss: 0.18069\tvalid_0's binary_logloss: 0.18069\n",
            "[75]\tvalid_0's binary_logloss: 0.180602\tvalid_0's binary_logloss: 0.180602\n",
            "[76]\tvalid_0's binary_logloss: 0.180475\tvalid_0's binary_logloss: 0.180475\n",
            "[77]\tvalid_0's binary_logloss: 0.180412\tvalid_0's binary_logloss: 0.180412\n",
            "[78]\tvalid_0's binary_logloss: 0.180299\tvalid_0's binary_logloss: 0.180299\n",
            "[79]\tvalid_0's binary_logloss: 0.180167\tvalid_0's binary_logloss: 0.180167\n",
            "[80]\tvalid_0's binary_logloss: 0.180034\tvalid_0's binary_logloss: 0.180034\n",
            "[81]\tvalid_0's binary_logloss: 0.179941\tvalid_0's binary_logloss: 0.179941\n",
            "[82]\tvalid_0's binary_logloss: 0.179888\tvalid_0's binary_logloss: 0.179888\n",
            "[83]\tvalid_0's binary_logloss: 0.179798\tvalid_0's binary_logloss: 0.179798\n",
            "[84]\tvalid_0's binary_logloss: 0.179661\tvalid_0's binary_logloss: 0.179661\n",
            "[85]\tvalid_0's binary_logloss: 0.179597\tvalid_0's binary_logloss: 0.179597\n",
            "[86]\tvalid_0's binary_logloss: 0.179525\tvalid_0's binary_logloss: 0.179525\n",
            "[87]\tvalid_0's binary_logloss: 0.179478\tvalid_0's binary_logloss: 0.179478\n",
            "[88]\tvalid_0's binary_logloss: 0.179408\tvalid_0's binary_logloss: 0.179408\n",
            "[89]\tvalid_0's binary_logloss: 0.179324\tvalid_0's binary_logloss: 0.179324\n",
            "[90]\tvalid_0's binary_logloss: 0.179282\tvalid_0's binary_logloss: 0.179282\n",
            "[91]\tvalid_0's binary_logloss: 0.179209\tvalid_0's binary_logloss: 0.179209\n",
            "[92]\tvalid_0's binary_logloss: 0.179155\tvalid_0's binary_logloss: 0.179155\n",
            "[93]\tvalid_0's binary_logloss: 0.179047\tvalid_0's binary_logloss: 0.179047\n",
            "[94]\tvalid_0's binary_logloss: 0.178992\tvalid_0's binary_logloss: 0.178992\n",
            "[95]\tvalid_0's binary_logloss: 0.178926\tvalid_0's binary_logloss: 0.178926\n",
            "[96]\tvalid_0's binary_logloss: 0.178875\tvalid_0's binary_logloss: 0.178875\n",
            "[97]\tvalid_0's binary_logloss: 0.178797\tvalid_0's binary_logloss: 0.178797\n",
            "[98]\tvalid_0's binary_logloss: 0.178734\tvalid_0's binary_logloss: 0.178734\n",
            "[99]\tvalid_0's binary_logloss: 0.178706\tvalid_0's binary_logloss: 0.178706\n",
            "[100]\tvalid_0's binary_logloss: 0.178615\tvalid_0's binary_logloss: 0.178615\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's binary_logloss: 0.178615\tvalid_0's binary_logloss: 0.178615\n",
            "Test dataset:\n",
            "predictions are  [0 0 0 ... 0 0 1]\n",
            "Test ROC AUC score: 0.8987370865767832\n",
            "Test accuracy score: 0.9335409610053411\n",
            "Confusion matrix is  [[424154   8961]\n",
            " [ 31242 140572]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95    433115\n",
            "           1       0.94      0.82      0.87    171814\n",
            "\n",
            "    accuracy                           0.93    604929\n",
            "   macro avg       0.94      0.90      0.91    604929\n",
            "weighted avg       0.93      0.93      0.93    604929\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation dataset:\n",
            "predictions are  [0 0 0 ... 0 1 0]\n",
            "Test ROC AUC score: 0.8996638873538187\n",
            "Test accuracy score: 0.9339376217840952\n",
            "Confusion matrix is  [[848813  18008]\n",
            " [ 62038 282814]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95    866821\n",
            "           1       0.94      0.82      0.88    344852\n",
            "\n",
            "    accuracy                           0.93   1211673\n",
            "   macro avg       0.94      0.90      0.92   1211673\n",
            "weighted avg       0.93      0.93      0.93   1211673\n",
            "\n",
            "\n",
            "\n",
            "[2423 3406 2853 2124 2488 3549 4045    0    0    0    0    0 2504 1847\n",
            "  782  871 1295 1065  576   49   15    7    1    0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores: {'fit_time': array([70.00118089, 65.61604452, 66.29497695, 67.37669063, 66.78477693]), 'score_time': array([6.09124398, 5.83210969, 5.91067863, 5.98601341, 5.88637948]), 'test_accuracy': array([0.93368523, 0.93419981, 0.93417195, 0.93377285, 0.93423499]), 'test_roc_auc': array([0.8976817 , 0.89834447, 0.89831632, 0.89770791, 0.89839949])}\n",
            "cross for accuracy [0.93368523 0.93419981 0.93417195 0.93377285 0.93423499]\n",
            "cross for roc-auc [0.8976817  0.89834447 0.89831632 0.89770791 0.89839949]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSa_F5DdiZ-e",
        "colab_type": "code",
        "outputId": "a4537683-636b-49fa-875c-6ac3ef31e66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "cols[8:13]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AIRLINE_DELAY',\n",
              " 'LATE_AIRCRAFT_DELAY',\n",
              " 'WEATHER_DELAY',\n",
              " 'SECURITY_DELAY',\n",
              " 'AIRLINE_ORIGIN_AIRPORT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-CSFvCpux_B8",
        "outputId": "602e982a-44da-424e-e3a5-66927d16f678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "source": [
        "def runXGBoostModel():\n",
        "  # fit model no training data\n",
        "  model = XGBClassifier(learning_rate=0.01,  \n",
        "                      colsample_bytree = 0.4,\n",
        "                      subsample = 0.8,\n",
        "                      objective='binary:logistic', \n",
        "                      n_estimators=300, \n",
        "                      reg_alpha = 0.3,\n",
        "                      max_depth=4,\n",
        "                      n_jobs=10,\n",
        "                      gamma=10)\n",
        "  model.fit(X_train, Y_train)\n",
        "  # make predictions for test data\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"Initial predictions are \",y_pred)\n",
        "  predictions = [round(value) for value in y_pred]\n",
        "  # evaluate predictions\n",
        "  report(Y_test,predictions)\n",
        "  X=pd.concat([X_train,X_test])\n",
        "  y=pd.concat([Y_train,Y_test])\n",
        "  cross_validation(model,X,y)\n",
        "  \n",
        "runXGBoostModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[08:09:19] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
            "Initial predictions are  [1 0 0 ... 0 0 0]\n",
            "Test ROC AUC score: 0.86731179532437\n",
            "Test accuracy score: 0.9062176437849815\n",
            "Confusion matrix is  [[970241  38777]\n",
            " [ 95185 324232]]\n",
            "Classification report is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.94   1009018\n",
            "           1       0.89      0.77      0.83    419417\n",
            "\n",
            "    accuracy                           0.91   1428435\n",
            "   macro avg       0.90      0.87      0.88   1428435\n",
            "weighted avg       0.91      0.91      0.90   1428435\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c398b2e8416e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgbclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mrunXGBoostModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-c398b2e8416e>\u001b[0m in \u001b[0;36mrunXGBoostModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgbclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mrunXGBoostModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lgbclassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p2HsWMEd3adP",
        "colab": {}
      },
      "source": [
        "def runXGBoostModel():\n",
        "  # fit model no training data\n",
        "  model = XGBClassifier()\n",
        "  eval_set = [(X_test, Y_test)]\n",
        "  model.fit(X_train, Y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
        "  # make predictions for test data\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"Initial predictions are \",y_pred)\n",
        "  predictions = [round(value) for value in y_pred]\n",
        "  # evaluate predictions\n",
        "  report(Y_test,predictions)\n",
        "  X=pd.concat([X_train,X_test])\n",
        "  y=pd.concat([Y_train,Y_test])\n",
        "  cross_validation(lgbclassifier,X,y)\n",
        "  \n",
        "runXGBoostModel()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}